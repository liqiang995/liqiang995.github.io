{"meta":{"title":"blog昱东","subtitle":"","description":"久有凌云志，重上井冈山","author":"昱东","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2024-09-16T10:41:31.000Z","updated":"2024-09-16T10:41:31.614Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"friends","date":"2024-09-16T10:41:14.000Z","updated":"2024-09-16T10:41:14.146Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"","text":""},{"title":"文章分类","date":"2024-09-15T07:30:00.000Z","updated":"2024-09-17T02:07:04.574Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"文章标签","date":"2024-09-15T10:30:00.000Z","updated":"2024-09-17T02:27:13.888Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"2026-01-03更新","slug":"2026-01-03更新","date":"2026-01-30T12:28:00.000Z","updated":"2026-01-30T12:29:46.467Z","comments":true,"path":"2026/01/30/2026-01-03更新/","permalink":"http://example.com/2026/01/30/2026-01-03%E6%9B%B4%E6%96%B0/","excerpt":"","text":"基础正则表达式速查表、正则可视化工具、常用正则 ^$表示匹配从^到$ 之间的内容，即 ^123$ 必须完全匹配123。1234567正则：123输入内容：123 （匹配）输入内容：12345 （匹配）正则：^123$ 输入内容：123 （匹配）输入内容：12345 （不匹配） 范围：[] 、{} 、() []约束内容。整个[]内只匹配一个字符[abc123] 代表可以是 abc123中的 一个[a-zA-Z] 代表可以是任意一个字母； 1[^： []内的^表示取反, [^a-zA-Z] 指不可以是字母 {}约束数量。单独[]只匹配一个字符，所以{}表示修饰[]里内容的个数。123[a-zA-Z]&#123;3&#125; 指3个字母[a-zA-Z]&#123;3,5&#125; 指可以是3至5个[a-zA-Z]&#123;3,&#125; 指3至无数个 三种特殊数量的简写： ? * + (?和都是对数量的约束，不指的是任意*内容)* ()表示组，一组内容视为一个整体，可以再对组做数量约束；还可用于对正则中一部分数据分组取出；分组的目的还可以重复应用，即后面内容必须和前面相等 字符 \\d匹配任何数字 等同于0-9 ；\\D 就是\\d取反，等同^\\d 不匹配任何字符 \\w包括字母、数字、或下划线_ \\s代表 [\\r \\n \\t \\f \\v ]回车符、翻页符、空格等； \\S 就是\\s取反，等同^\\s 不匹配上述符号 .点表示可以匹配任意字符(除了换行) .{2,5} 匹配2至5个任意字符 数量 ?表示某个内容出现0至1次，等同于 {0,1} *表示某个内容出现0至无穷次，等同于{0,} +表示某个内容出现 1至无穷次，等同于{1,} 其他 \\表示转义, 如.表示任意字符，但.表示必须匹配.这个字符 举例：匹配是字符或数字开头的163邮箱 1^[a-zA-Z0-9]\\w+@163\\.com$ |表示 或 （）分组 () 表示组，一组是一个整体 可用于对正则中一部分数据分组取出；12^([a-zA-Z0-9]\\w+)@163\\.com$ 小括号里的内容会被匹配为一个组，多个组时是按索引(从1开始)，当组数量太多时不方便。^(?&lt;first&gt;[a-zA-Z0-9]\\w+)@163\\.com%$ 将邮箱@前内容取出并将分组命名为first 分组的内容，可以再被后续引用： \\k&lt; first&gt; 如匹配1212这样交替重复重现的数字： 123^\\d\\d\\d\\d$ 表示四位数字，但没有限制后两位必须于前两位相同^(\\d\\d)\\1$ \\1表示后面的内容引用前面的第一个分组 所以表示第三四位要等于第一二位^(?&lt;first&gt;\\d\\d)\\k&lt;first&gt;$ 等同于^(\\d\\d)\\1$ ,在对组取名称情况下，用\\k&lt;&gt;引用 匹配某个规则的内容，并且这个内容还要在特定字符的 前&#x2F;后，或不能出现在特定字符的 前&#x2F;后 如对于文本：foobar，fooboo。 只期望找到foobar里的foo。 12foo(?=bar)如果直接使用foobar做正则，匹配出来的是 foobar整个，foo(?=bar)匹配出来的是foo，这对于取值很关键。 要求在指定特定内容之前 12(?=str) 匹配并取出内容，且内容还要在str前的才可匹配 如:cdx(?=ohh) ，匹配cdxohh，不匹配cdxokk(?!str) 匹配并取出内容，且内容不能在str前的才可匹配 如:cdx(?!ohh) ，不匹配cdxohh，却匹配除ohh外任意字符 要求在指定特定内容之后 12(?&lt;=str) 匹配并取出内容，且内容还要在str后的才可匹配 如: cdx(?&lt;=ohh) ，匹配 ohhcdx(?&lt;!str) 匹配并取出内容，且内容不能在str后的才可匹配 如: cdx(?&lt;!ohh) ，不匹配 ohhcdx，却匹配除ohh外任意字符 最佳实践：匹配 “滔滔不绝”这样aabc格式的内容，要求前两位相同，但第三、四位不与前两位相同，且第三、四位互不相同。123456思路：^....$ ： 所有四位成语能匹配^(?&lt;A&gt;.)\\k&lt;A&gt;..$ : 满足要求前两位相同^(?&lt;A&gt;.)\\k&lt;A&gt;(?!\\k&lt;A&gt;)..$ ：满足要求前两位相同，同时要求第二位后不能是和自己相同的内容（即要求了第三位不再是\\k&lt;A&gt;）^(?&lt;A&gt;.)\\k&lt;A&gt;(?!\\k&lt;A&gt;)(?&lt;B&gt;.)(?!\\k&lt;B&gt;).$ : 满足要求第三位后不能是和自己相同的内容 （即要求了第四位不再是\\k&lt;B&gt;）^(?&lt;A&gt;.)\\k&lt;A&gt;(?!\\k&lt;A&gt;)(?&lt;B&gt;.)(?!\\k&lt;B&gt;|\\k&lt;A&gt;).$：要求第三位后不能是 和自己相同或与A相同 （即要求了第四位也不能是\\k&lt;A&gt;） 分组取出java 12345678910111213String content = &quot;请从以下段落中提取满足json格式的内容：&#123;\\&quot;name\\&quot;:\\&quot;Revali\\&quot;,\\&quot;age\\&quot;:\\&quot;25\\&quot;&#125;\\n&#123;\\&quot;name\\&quot;:\\&quot;Mipha\\&quot;,\\&quot;age\\&quot;:\\&quot;1000\\&quot;&#125;&quot;;// 取出以&#123;开头（包含&#123;），以&#125;结尾（包含&#125;），并且中间不含&#125;的内容String regex = &quot;[&#123;](?&lt;=[&#123;])[^&#125;]+(?=[&#125;])[&#125;]&quot;;Pattern pattern = Pattern.compile(regex);Matcher matcher = Pattern.matcher(content);List&lt;JSONObject&gt; jsonList = new ArrayList&lt;&gt;();while(matcher.find()) &#123; String json = matcher.group(); JSONObject jsonObject = JSONObject.parseObject(json); jsonList.add(jsonObject);&#125; python 12345678910111213# _*_ coding: utf-8 _*_import reimport jsoncontent = &#x27;请从以下段落中提取json格式的关键内容：&#123;&quot;name&quot;:&quot;Revali&quot;,&quot;age&quot;:&quot;25&quot;&#125;\\n&#123;&quot;name&quot;:&quot;Mipha&quot;,&quot;age&quot;:&quot;100&quot;&#125;&#x27;json_list = re.findall(r&quot;[&#123;](?&lt;=[&#123;])[^&#125;]+(?=[&#125;])[&#125;]&quot;, content)for json_row in json_list: json_data = json.load(json_row) print(json_data[&#x27;name&#x27;]) print(json_data[&#x27;age&#x27;])","categories":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://example.com/categories/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}],"tags":[]},{"title":"搭建Docker私有镜像源","slug":"搭建Docker私有镜像源","date":"2024-09-22T11:03:45.000Z","updated":"2024-09-22T11:04:47.041Z","comments":true,"path":"2024/09/22/搭建Docker私有镜像源/","permalink":"http://example.com/2024/09/22/%E6%90%AD%E5%BB%BADocker%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E6%BA%90/","excerpt":"","text":"参考：原作者Github开源项目：https://github.com/jonssonyan/cf-workers-proxy原作者视频教程：稳了，搭建Docker镜像源加速，简单无废话 注册国内域名，并托管到CloudFlare DNS服务如阿里云，腾讯云，按需购买。 注册&#x2F;登录 CloudFlare：https://dash.cloudflare.com/ Add Site 输入刚才注册的国内域名，并 Contine 选择Free 即可，并 Contine 找到 Your assigned Cloudflare nameservers: 将两个DNS地址分别复制 回到阿里云&#x2F;腾讯云，域名列表。在域名列表中进入”管理”选项：找到DNS管理：修改DNS服务器，分别粘贴填入两个DNS地址。 dns修改后需要等待dns生效时间。生效后会收到 CloudFlare 邮件通知已激活。并且在 CloudFlare 主页列表内，也会看到状态为 Active CloudFlare 创建Worker，并绑定域名 左侧菜单栏中找到Workers &amp; Pages，然后 Create Worker 自己取一个名称，然后点击 Deploy 发布 等待发布成功后，点击 Edit Code 进入编辑worker.js页面，这里worker.js需要一段js代码，我们从Github中获取 找到Github开源项目：https://github.com/jonssonyan/cf-workers-proxy 在文件中找到 docker.js 将文件中的js代码复制到上述worker.js中，保存后，点右上角 Deploy 发布，稍等片刻后提示 版本已保存，再退出页面就好。 创建好这个worker后，CloudFlare 会为我们分配一个国外域名，仍然不能直接用于镜像仓库，需要添加自定义域名。 找到 Settings， 在 Domains &amp; Route 一项中，去添加 Custom domain ，输入自定义域名（填二级域名，假如注册的域名为 xxx.xyz，这里可以填 docker.xxx.xyz） 点击 Add domain 完成添加，这样我们的二级域名就成了一个私有镜像源。接下来需要在 docker配置文件中添加即可。 修改daemon.json并重启docker回到 docker，配置文件默认是在 &#x2F;etc&#x2F;docker&#x2F;daemon.json 打开 daemon.json，将私有镜像仓库地址添加到 “registry-mirrors” 中，以 docker.xxx.xyz 为例：12345678910&#123; &quot;builder&quot;: &#123; &quot;gc&quot;: &#123; &quot;defaultKeepStorage&quot;: &quot;20GB&quot;, &quot;enabled&quot;: true &#125; &#125;, &quot;experimental&quot;: false, &quot;registry-mirrors&quot;: [&quot;https://docker.xxx.xyz&quot;]&#125; 保存并退后，需要重启docker1systemctl restart docker 拉取镜像试试 速度非常快！","categories":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"}],"tags":[]},{"title":"SpringBoot从创建到精通","slug":"SpringBoot从创建到精通","date":"2024-09-20T12:00:00.000Z","updated":"2024-09-20T12:45:16.718Z","comments":true,"path":"2024/09/20/SpringBoot从创建到精通/","permalink":"http://example.com/2024/09/20/SpringBoot%E4%BB%8E%E5%88%9B%E5%BB%BA%E5%88%B0%E7%B2%BE%E9%80%9A/","excerpt":"","text":"Spring Boot在 Spring 基础上提供的一套全新的开源的框架，为简化 Spring 应用的搭建和开发过程，快速使用Spring，并不是功能上的增强。 Spring Boot 提供了大量开箱即用（out-of-the-box）的依赖模块，例如 spring-boot-starter-redis、spring-boot-starter-data-mongodb 和 spring-boot-starter-data-elasticsearch 等。 spring-boot-starter-xxx：spring-boot场景启动器；帮我们导入了web模块正常运行所依赖的组件； Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器 与Spring优缺点Spring 缺点：xml配置编写繁琐；不好处理依赖。 Spring Boot: 自动配置、注解代替xml配置； 每一个spring boot版本的parent包都构建好了不同组件的版本关系，处理好了冲突。 但引入组件依赖时也可以指定版本，会overwrite。 （但其实创建后一般不随意升级spring boot版本，但后续开发中不断引入新组件，而组件中又是不同版本的依赖包，仍然会冲突，需要手动兼容和排除。默认以最短依赖路径作为第一优先级） 创建 Spring Boot 项目使用 Maven 创建 IDEA 新建 Maven 项目，pom.xml 中导入 Spring Boot 相关的依赖1234567891011121314151617&lt;project&gt; ... &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.4.5&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 创建一个名为 HelloWorldApplication 主程序，用来启动 Spring Boot 应用 12345678910import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class HelloApplication &#123; public static void main(String... args) &#123; SpringApplication.run(HelloApplication.class, args); &#125;&#125; 在默认端口就能启动了 12Tomcat initialized with port(s): 8080 (http)Starting service [Tomcat] 使用 Spring Initializr 创建 在 IntelliJ IDEA 欢迎页面左侧选择 Project ，然后在右侧选择 New Project 新建工程界面左侧，选择 Spring Initializr，选择项目的 SDK ，选择 starter service URL 为 http://start.spring.io（默认） IDEA 会连接网络，并根据 starter service URL 查询 Spring Boot 的当前可用版本和组件列表 在 dependencise 界面中，选择 Spring Boot 的版本及所依赖的 Spring Boot 组件：就会自动添加对应的spring-boot-starter-xxx 到pom文件。 启动demo创建一个 controller 包，并在该包内创建一个名为 HelloController 的 Controller，代码如下： 123456789@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping(&quot;/hello&quot;) public String hello() &#123; return &quot;Hello World!&quot;; &#125;&#125; 启动 Spring Boot 项目，然后在 http://localhost:8080/hello 就能访问。 Spring Boot配置不做任何配置时，也能启动在8080端口，但项目中一定会配置端口 配置文件语法 application.properties -传统方式，能完成配置，语法不太优美。 application.yml -推荐使用（yml 是 yaml 的缩写。） 相同位置下的 application.properties 的优先级会高于 application.yml，即优先默认使用application.properties的配置。 外部目录中会覆盖内部目录中相同配置项。 yml 语法： 一对键值 k:[空格]v 空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的 如果换行来写对象的属性和值，还是k: v的方式，注意缩进 需要区分大小写 如配置端口： 123server: port: 8081 path: /hello 行内写法：1server: &#123;port: 8081,path: /hello&#125; 如配置dispatcher servlet的监听路径：123456789101112131415server: context-path: /demo # 适用springboot2.0以下server: servlet: context-path: /demo # 适用springboot2.0以上# 对于其中在http://ip:port上服务# 如果配置了server: servlet-path: /demo # 访问路径就是http://ip:port/demo/...# 不配置或server: servlet-path: / # 访问路径就是http://ip:port/... 数组（List、Set）,用 - 表示数组中的一个元素：1234pets: - cat - dog - pig 行内写法1pets: [cat,dog,pig] 原样输出 单引号内的内容，会原样输出 双引号内的\\n，会识别为换行12msg1: &#x27;hello \\n word&#x27;msg2: &quot;hello \\n word&quot; 配置文件注入将配置文件中配置的每一个属性的值，映射到项目代码中 对于如下配置文件： 12345person: lastName: hello age: 18 boss: false birth: 2017/12/12 @ConfigurationProperties告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定prefix &#x3D; “person”：限定文件中person的下一级范围的所有属性 123456789@Component@ConfigurationProperties(prefix = &quot;person&quot;)public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth;&#125; 注意，这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能，就是这个类需要注解@Component 交给Spring容器。 导入配置文件处理器，配置文件进行绑定就会有提示12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; @Value上述可以将文件中”persion”下所有的配置项与Person类中属性一一对应，但很多时候只是期望获取一下配置文件中的某项值，就可以使用@Value来指定。 example:12345678910111213@Component@ConfigurationProperties(prefix = &quot;person&quot;)public class Person &#123; @Value(&quot;$&#123;person.lastName&#125;&quot;) private String lastName; @Value(&quot;#&#123; 54 * 2&#125;&quot;) private Integer weight; @Value(&quot;24&quot;) private Integer age;&#125; @Value(“${}”) ${property:default_value} 从外部配置文件中注入property，如果为空就取默认值default_value @Value(“#{SpEL}”) #{obj.property:default_value} 从SpEL表达式获取内容，如果为空就取默认值default_value，例如从一个bean中获取属性。 12@Value(&quot;#&#123;user.name&#125;&quot;) // user 是User类的一个beanprivate String name; 如果本该从配置文件获取，却写成了#{}： 12@Value(&quot;#&#123;person.lastName&#125;&quot;)private String lastName; 将会报错： 123org.springframework.expression.spel.SpelEvaluationException: EL1008E: Property or field ‘server’ cannot be found on object of type ‘org.springframework.beans.factory.config.BeanExpressionContext’ - maybe not public? @Value(“str”)取固定值 用法举例： 1234567891011121314151617@Value(&quot;normal&quot;)private String normal; // 注入普通字符串@Value(&quot;#&#123;systemProperties[&#x27;os.name&#x27;]&#125;&quot;)private String systemPropertiesName; // 注入操作系统属性@Value(&quot;#&#123; T(java.lang.Math).random() * 100.0 &#125;&quot;)private double randomNumber; //注入表达式结果@Value(&quot;#&#123;beanInject.another&#125;&quot;)private String fromAnotherBean; // 注入beanInject对象的属性another@Value(&quot;classpath:com/hry/spring/configinject/config.txt&quot;)private Resource resourceFile; // 注入文件资源@Value(&quot;http://www.baidu.com&quot;)private Resource testUrl; // 注入URL资源 @PropertySource@ConfigurationProperties 和 @Value 的使用都是从application.yml中注入，但配置文件可以不止application.yml，要指定从其他文件注入就要用@PropertySource 【但是不支持.yml配置】 1@PropertySource(value = &#123;classpath:persion.properties&#125;) Environment先通过@Autowird 注入一个Environment ,就可以从这个对象中，通过getProperty(String property)获取yml文件中的每个属性 12345678public class Person &#123; @Autowird private Environment env; public void method() &#123; env.getProperty(&quot;person.lastName&quot;); &#125;&#125; @SpringBootApplicationSpringBootApplication应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用。 其中最重要：@SpringBootConfiguration、@EnableAutoConfiguration 1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123;&#125; @SpringBootConfiguration标注在某个类上，表示这是一个Spring Boot的配置类；它又有一个注解@Configuration ： @Configuration 说明SpringBootApplication 也是一个配置类，可以直接在类里注册bean到容器。 @EnableAutoConfiguration开启自动配置功能；这样自动配置才能生效；EnableAutoConfiguration 有两个注解： 1234@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123;&#125; @Import @Import(AutoConfigurationImportSelector.class) @Import 可以给容器中导入一个组件，也可以委托AutoConfigurationImportSelector.class，满足这个Selector条件就都可以导入。 @AutoConfigurationPackage@AutoConfigurationPackage 按名称翻译：自动配置包，它又有一个注解：@Import(AutoConfigurationPackages.Registrar.class) @Import 委托 AutoConfigurationPackages.Registrar.class， RegistrarRegistrar 是 AutoConfigurationPackages的内部类，有两个方法： 12345678910@Overridepublic void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; register(registry, new PackageImport(metadata).getPackageName());&#125;@Overridepublic Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) &#123; return Collections.singleton(new PackageImport(metadata));&#125; 两个方法都new PackageImport(metadata)；PackageImport 也是一个内部类 1234 // new PackageImport(metadata) 就是从注解元数据（AnnotationMetadata）中获取注解所在包名PackageImport(AnnotationMetadata metadata) &#123; this.packageName = ClassUtils.getPackageName(metadata.getClassName());&#125; new PackageImport(metadata) 就是从注解元数据（AnnotationMetadata）中获取注解所在包名。而注解是打在启动类上，所以获取了启动类所在包名。 对于 registerBeanDefinitions方法，就是拿到启动类所在包名，和BeanDefinitionRegistry一起，再传入register()方法： 123456789101112131415 // register方法里有两分支public static void register(BeanDefinitionRegistry registry, String... packageNames) &#123; if (registry.containsBeanDefinition(BEAN)) &#123; BeanDefinition beanDefinition = registry.getBeanDefinition(BEAN); ConstructorArgumentValues constructorArguments = beanDefinition.getConstructorArgumentValues(); constructorArguments.addIndexedArgumentValue(0, addBasePackages(constructorArguments, packageNames)); &#125; else &#123; GenericBeanDefinition beanDefinition = new GenericBeanDefinition(); beanDefinition.setBeanClass(BasePackages.class); beanDefinition.getConstructorArgumentValues().addIndexedArgumentValue(0, packageNames); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(BEAN, beanDefinition); &#125;&#125; （更深层方法调用以后再看）BeanDefinitionRegistr按名称理解：Bean定义的注册器，那么就是和注册bean相关，也就是说拿到启动类所在包名，去注册bean。 大致猜想：@AutoConfigurationPackage 就是获取启动类所在包名，用于扫描包和子包下，用于注册bean。所以未使用@ComponentScan指定包名时，也会将启动类所在包和子包下的bean扫描到并注入。 AutoConfigurationImportSelector AutoConfigurationImportSelector 的作用：决定导入哪些组件的选择器； 从Library中有依赖包 spring-boot-autoconfigure-&lt;版本号&gt;.jar， 其下的META-INF&#x2F;spring.factories中获取EnableAutoConfiguration指定的值。 将上述所有需要导入的组件以全类名的方式返回；如果引入了这些组件starter，这些组件就会被添加到容器中。 会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件；免去了我们手动编写配置注入功能组件等的工作。 AutoConfigurationImportSelector 核心源码: 两个重载的selectImports()方法，和process()，他们最终都调用了getAutoConfigurationEntry()方法。 省略掉断言等无关代码后： 123456789101112131415161718192021222324252627282930313233343536373839@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());&#125;@Overridepublic void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) &#123; AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector) .getAutoConfigurationEntry(getAutoConfigurationMetadata(), annotationMetadata); this.autoConfigurationEntries.add(autoConfigurationEntry); for (String importClassName : autoConfigurationEntry.getConfigurations()) &#123; this.entries.putIfAbsent(importClassName, annotationMetadata); &#125;&#125; // process 方法将 getAutoConfigurationEntry() 的结果：this.autoConfigurationEntries.add(autoConfigurationEntry)@Override public Iterable&lt;Entry&gt; selectImports() &#123; // 从 this.autoConfigurationEntries 中取出 Set&lt;String&gt; processedConfigurations Set&lt;String&gt; processedConfigurations = this.autoConfigurationEntries.stream() .map(AutoConfigurationEntry::getConfigurations).flatMap(Collection::stream) .collect(Collectors.toCollection(LinkedHashSet::new)); // 再转为Iterable迭代器返回 return sortAutoConfigurations(processedConfigurations, getAutoConfigurationMetadata()).stream() .map((importClassName) -&gt; new Entry(this.entries.get(importClassName), importClassName)) .collect(Collectors.toList()); &#125; 重点关注 getAutoConfigurationEntry()，省略掉校验、获取排除项、事件相关代码后：123456789protected AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); return new AutoConfigurationEntry(configurations, exclusions); &#125; getAttributes() 获取了注解属性，但传到getCandidateConfigurations()后又没什么用，而getCandidateConfigurations(): 123456789protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot; + &quot;are using a custom packaging, make sure that file is correct.&quot;); return configurations;&#125; 通过断言已经发现了：要从 META-INF&#x2F;spring.factories 下找配置类。 查看getSpringFactoriesLoaderFactoryClass()，就是获取了 org.springframework.boot.autoconfigure包里的@EnableAutoConfiguration注解 123protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class;&#125; 而继续深入SpringFactoriesLoader.loadFactoryNames()： 传入@EnableAutoConfiguration注解这个Class后，获取里它的全限定名 接连调用了两个方法loadSpringFactories(classLoader) 和 getOrDefault() 对于loadSpringFactories(classLoader)返回了一个Map，并对这个map.getOrDefault(factoryTypeName,),就是以@EnableAutoConfiguration注解的全限定名作为key，从map中获取value 1234public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; String factoryTypeName = factoryType.getName(); return (List)loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList());&#125; 对于loadSpringFactories(classLoader)，就会发现使用classLoader，从当前包下”META-INF&#x2F;spring.factories”加载 12classLoader.getResources(&quot;META-INF/spring.factories&quot;) 当前代码是spring-boot-autoconfig-&lt;版本号&gt;.jar中，找到这个jar文件打开，里面就有META-INF&#x2F;spring.factories： 123456789101112131415....# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudServiceConnectorsAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\..... 这里等号左边，就是@EnableAutoConfiguration注解的全限定名，作为源码中map.getOrDefault(key,defaultValue)时的key 12 # Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ 而value就是所有需要被自动加载的类的全限定名，共一百多个。如 12345org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\ 找到 RedisAutoConfiguration 这个类： 1234567891011121314151617181920212223242526@Configuration(proxyBeanMethods = false)@ConditionalOnClass(RedisOperations.class)@EnableConfigurationProperties(RedisProperties.class)@Import(&#123; LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class &#125;)public class RedisAutoConfiguration &#123; @Bean @ConditionalOnMissingBean(name = &quot;redisTemplate&quot;) @ConditionalOnSingleCandidate(RedisConnectionFactory.class) public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; &#125; @Bean @ConditionalOnMissingBean @ConditionalOnSingleCandidate(RedisConnectionFactory.class) public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125; 这个RedisAutoConfiguration类下面就有一个使用@Bean注册RedisTemplate的方法，也就完成了自动向容器注册redisTemplate。那我当我们需要手动注册redisTemplate的时候，有如何让自动配置失效呢：@ConditionalOnMissingBean(name &#x3D; “redisTemplate”)。 仅当找不到名叫redisTemplate的bean时（说明没有手动注册redisTemplate），才会使用自动注册。 总结：@SpringBootApplication 使用 @EnableAutoConfiguration 开启自动配置，并提供两种方式注册bean @AutoConfigurationPackage 其实就是@Import(AutoConfigurationPackages.Registrar.class)，通过Registrar拿到启动类所在包，扫描这个包和子包下的类，使用@Import注册为bean。 负责注入项目内部编写的bean。 @Import(AutoConfigurationImportSelector.class) 通过AutoConfigurationImportSelector去到依赖包spring-boot-autoconfig-&lt;版本号&gt;.jar下”META-INF&#x2F;spring.factories”文件里，拿到需要自动注入的外部组件。 负责注入外部依赖的bean。 starter 对于Spring 项目,需要导入各种依赖，还要对各种 XML 配置文件进行配置。 但 Spring Boot 项目创建后，依靠自动何配置就能简单运行，这都要归功于 Spring Boot 的 starter 机制。 Spring Boot 将日常企业应用研发中的各种场景都抽取出来，做成一个个的 starter（启动器），starter 中整合了该场景下各种可能用到的依赖，用户只需要在 Maven 中引入 starter 依赖，SpringBoot 就能自动扫描到要加载的信息并启动相应的默认配置。 -SPI机制 123大部分 starter 由 Spring Boot 官方提供的，如上述 spring-boot-starter-xxx。也有部分 starter 是第三方技术厂商提供的，例如 druid-spring-boot-starter 和 mybatis-spring-boot-starter 等等。当然也存在，Spring Boot 官方和第三方技术厂商都没有提供 starter。 例如demo中用到 pring-boot-starter-web，它能够为提供 Web 开发场景所需要的几乎所有依赖，因此在使用 Spring Boot 开发 Web 项目时，只需要引入该 starter 依赖包即可，自动导入了 springframework、logging、jackson 以及 Tomcat 等依赖。 starter 原理以 mybatis-spring-boot-starter 为例。 1234&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 引入mybatis-spring-boot-starter，发现它又依赖了一个mybatis-spring-boot-autoconfigure这个mybatis-spring-boot-autoconfigure并不是我们当前项目里的spring-boot-autoconfigure-&lt;版本号&gt;.jar 123456789101112131415161718192021&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在这个mybatis-spring-boot-autoconfigure的jar包中： 有自动配置类 org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration1234567@Configuration@ConditionalOnClass(&#123;SqlSessionFactory.class, SqlSessionFactoryBean.class&#125;)@ConditionalOnSingleCandidate(DataSource.class)@EnableConfigurationProperties(&#123;MybatisProperties.class&#125;)@AutoConfigureAfter(&#123;DataSourceAutoConfiguration.class, MybatisLanguageDriverAutoConfiguration.class&#125;)public class MybatisAutoConfiguration implements InitializingBean &#123;&#125; mybatis-spring-boot-autoconfigure的jar里也有 META-INF&#x2F;spring.factories，其 中也指定12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration 为什么我在第三方autoconfigure依赖jar中的自动配置, spring.factories也是在第三方jar里，却能被当前spring boot识别呢。–SPI机制 自定义starterhttps://www.bilibili.com/video/BV1Lq4y1J77x?p=25 创建一个 xxx-spring-boot-autoconfigure 模块 在xxx-spring-boot-autoconfigure 模块中创建自动配置类 在xxx-spring-boot-autoconfigure 模块创建META-INF&#x2F;spring.factories文件，以org.springframework.boot.autoconfigure.EnableAutoConfiguration为key，以上述自动配置类为value。 创建一个 xxx-spring-boot-starter 模块，并依赖 xxx-spring-boot-autoconfigure模块。 在当前项目中依赖 xxx-spring-boot-starter 这个自定义starter模块，就可以使用 profile多环境支持开发场景下，开发、测试、生产可以各有一套文件：application-dev.yml、application-stg.yml、application-prd.yml 如何编写 在配置文件编写的时候，文件名可以是 application-{profile}.properties&#x2F;yml，即可标识了profile 也可以在文件中说明当前profile 12spring: profiles: dev 激活使用在主配置中指定激活特定环境下使用的配置文件 applcation.yml 123spring: profiles: active: dev 或：applcation.properties 1spring.profiles.active=dev 也可以在打包、启动时通过命令行指定激活特定文件 1java -jar spring-boot-0.0.1-SNAPSHOT.jar --spring.profiles.active=dev 也可以通过设置虚拟机参数 1-Dspring.profiles.active=dev Spring Boot单元测试导入包 spring-boot-starter-test 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&lt;/dependency&gt; 测试类 1234567891011@RunWith(SpringRunner.class)@SpringBootTest(classes = SpringBootApplication.class) //是一个Spring boot测试，classes指定main方法所在的启动类(类名自己定义的)public class SpringbootTest &#123; @Autowired private TestService testService; @Test public void test() &#123; testService.test(); &#125;&#125; 节选参考：http://c.biancheng.net/spring_boot/overview.html 在非Spring 容器管理的类中，获取spring容器中的 bean 写一个工具类，实现ApplicationContextAware接口，从spring容器中获取bean12345678910111213141516171819202122232425262728import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;@Component /* 自身必须要交给Spring管理 */public class ApplicationContextUtils implements ApplicationContextAware &#123; public static ApplicationContext context; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.context = applicationContext; &#125; //根据bean名字获取工厂中指定bean 对象 public static Object getBean(String beanName)&#123; return context.getBean(beanName); &#125; public static &lt;T&gt; T getBean(Class&lt;T&gt; clz) throws BeansException &#123; T result = (T) applicationContext.getBean(clz); return result; &#125;&#125; 使用12// 根据名字获取容器中的bean,如RedisTemplateRedisTemplate redisTemplate = (RedisTemplate) ApplicationContextUtils.getBean(&quot;redisTemplate&quot;); 按条件决定是否向容器配置bean@ConditionalOnMissBean如上文Auto Configure时提到在RedisAutoConfiguration 这个类中，就使用了 @ConditionalOnMissingBean(name &#x3D; “redisTemplate”) 在自动配置的bean上有@ConditionalOnMissBean这样一个注解，仅当没有这个bean时，才是生效配置配置，如已有自定义配置则忽略自动配置。 @Conditional@Conditional() 要求传入一个Condition的实现类，重写matches方法，若方法返回true代表这个bean需要被创建，返回false返回不需要创建。 @Conditional 就是 @ConditionalOnMissBean的底层原理 123456789101112131415161718@Configuration public class MainConfig &#123; @Bean(&quot;userDao&quot;) @Conditional(MyCondition.class) public UserDao userDao()&#123; return new UserDao(); &#125;&#125;public class MyCondition implements Condition &#123; @Override public boolean matches(ConditionContext context, Anno...) &#123; return true; &#125;&#125; @ConditionalOnSingleCandidate在上述分析 RedisAutoConfiguration 时除了 @ConditionalOnMissingBean(name &#x3D; “redisTemplate”) 还有一个 @ConditionalOnSingleCandidate(RedisConnectionFactory.class) @ConditionalOnSingleCandidate 这个注解用来判断指定类（也就是RedisConnectionFactory）在容器中是否只有一个实例 即如果存在多个RedisConnectionFactory实例，则当前注入redisTemplate这个@Bean也是失败。 （通过RedisConnectionFactory实例也能创建redisTemplate。所以判断有其他的RedisConnectionFactory实例，也说明已存在redisTemplate，那么就不需要当前的自动配置了。） @Profile 以环境作为条件@profile注解的作用是指定类或方法在特定的 Profile 环境生效，任何@Component或@Configuration注解的类都能够根据@profile标明的环境，将注入符合当前运行环境的相应的bean。 @Component或@Configuration注解的类可以使用@profile @Profile中需要指定一个字符串，约定生效的环境，如：@Profile(“dev”)、 @Profile({“dev”, “test”, “prd”}) 注解中标示了dev、test、prd等多个环境，运行时使用哪个profile由spring.profiles.active控制（见上述：多环境） 配置文件方式，如applcation.properties1spring.profiles.active=dev 切换内置服务器在没有添加spring-boot-starter-web依赖时,启动类只能运行一次，而不能启动web。 启动web默认使用tomcat，但其实提供了4种，可供选择。在依赖包的autoconfig–web–embedded 可以看到有一下四个内置： 1234JettyNettyTomcatUndertow 默认使用tomcat 是因为 在spring-boot-starter-web中依赖了 spring-boot-starter-tomcat。如果需要切换内置服务器： 首先，在spring-boot-starter-web中把spring-boot-starter-tomcat排除 然后引入期望的服务器的starter包如：spring-boot-starter-jetty。重新启动就好，不需要改其他就能使用上jetty. Springboot监听机制提供了 ApplicationRunner、 CommandLineRunner、 ApplicationContextInitializer、 SpringApplicationRunListener 可以在创建Spring容器时自动触发，完成一些操作，如redis缓存的预热。 ApplicationRunnerApplicationRunner 是一个接口，提供了run方法。 123public interface ApplicationRunner &#123; void run(ApplicationArguments args) throws Exception;&#125; 创建一个MyApplicationRunner： 12345678@Component // 注意必须要注册到容器public class MyApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println(&quot;MyApplicationRunner...run&quot;); &#125;&#125; 启动容器后，控制台会有输出： 1234567891011121314151617181920 . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.4.5)2022-11-09 21:11:44.185 INFO 13996 --- [ main] org.example.helloWorldApplication : Starting helloWorldApplication using Java 1.8.0_271 on DESKTOP-LH92210 with PID 13996 (E:\\WorkSpace\\SpringBootMaven\\target\\classes started by L in E:\\WorkSpace\\SpringBootMaven)2022-11-09 21:11:44.187 INFO 13996 --- [ main] org.example.helloWorldApplication : No active profile set, falling back to default profiles: default2022-11-09 21:11:44.949 INFO 13996 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2022-11-09 21:11:44.957 INFO 13996 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2022-11-09 21:11:44.957 INFO 13996 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.45]2022-11-09 21:11:45.002 INFO 13996 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2022-11-09 21:11:45.002 INFO 13996 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 784 ms2022-11-09 21:11:45.106 INFO 13996 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService &#x27;applicationTaskExecutor&#x27;2022-11-09 21:11:45.205 INFO 13996 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#x27;&#x27;2022-11-09 21:11:45.211 INFO 13996 --- [ main] org.example.helloWorldApplication : Started helloWorldApplication in 1.268 seconds (JVM running for 1.525)MyApplicationRunner...run run(ApplicationArguments args) 的参数，就是对启动类main方法参数的封装，所以也能从启动时指定的参数列表里获取到参数 12345678@Componentpublic class MyApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; String[] sourceArgs = args.getSourceArgs(); System.out.println(&quot;MyApplicationRunner...run&quot;); &#125;&#125; CommandLineRunnerCommandLineRunner 也是一个接口，也提供了run方法，用法&#x2F;效果和 ApplicationRunner几乎一致。 123public interface CommandLineRunner &#123; void run(String... args) throws Exception;&#125; 12345678@Componentpublic class MyCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(&quot;MyCommandLineRunner...run...&quot;); &#125;&#125; 也是在容器启动后输出： 123...MyApplicationRunner...runMyCommandLineRunner...run... ApplicationContextInitializerApplicationContextInitializer 也是一个接口，提供了 initialize方法。 123public interface ApplicationContextInitializer&lt;C extends ConfigurableApplicationContext&gt; &#123; void initialize(C var1);&#125; 12345678@Componentpublic class MyApplicationContextInitializer implements ApplicationContextInitializer &#123; @Override public void initialize(ConfigurableApplicationContext configurableApplicationContext) &#123; System.out.println(&quot;MyApplicationContextInitializer...initialize&quot;); &#125;&#125; 注意：ApplicationContextInitializer 和 SpringApplicationRunListener 需要在项目resources下创建 META-INF&#x2F;spring.factories，并进行配置。 spring.factories： 1org.springframework.context.ApplicationContextInitializer=org.example.listener.MyApplicationContextInitializer 启动key为ApplicationContextInitializer的全限定名，value为我们自己创建的类的全限定名。 启动容器,输出 ： MyApplicationContextInitializer…initialize可以看到initialize方法是在开始创建IOC容器以前开始被触发调用，可用于校验创建IOC容器所需环境\\参数是否准备完毕等。 1234567891011 . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.4.5)MyApplicationContextInitializer...initialize2022-11-09 21:38:36.927 INFO 232 --- [ main] org.example.helloWorldApplication : Starting helloWorldApplication using Java 1.8.0_271 on DESKTOP-LH92210 with PID 232 (E:\\WorkSpace\\SpringBootMaven\\target\\classes started by L in E:\\WorkSpace\\SpringBootMaven)... SpringApplicationRunListener123456789101112131415161718192021222324252627public interface SpringApplicationRunListener &#123; default void starting(ConfigurableBootstrapContext bootstrapContext) &#123; this.starting(); &#125; /** @deprecated */ @Deprecated default void starting() &#123; &#125; default void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) &#123; this.environmentPrepared(environment); &#125; /** @deprecated */ @Deprecated default void environmentPrepared(ConfigurableEnvironment environment) &#123; &#125; default void contextPrepared(ConfigurableApplicationContext context) &#123; &#125; default void contextLoaded(ConfigurableApplicationContext context) &#123; &#125; default void started(ConfigurableApplicationContext context) &#123; &#125; default void running(ConfigurableApplicationContext context) &#123; &#125; default void failed(ConfigurableApplicationContext context, Throwable exception) &#123; &#125;&#125; 实现SpringApplicationRunListener后，可以选择性覆写某部分方法 注意：ApplicationContextInitializer 和 SpringApplicationRunListener 需要在项目resources下创建 META-INF&#x2F;spring.factories，并进行配置。 spring.factories： 123org.springframework.context.ApplicationContextInitializer=org.example.listener.MyApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=org.example.listener.MySpringApplicationRunListener 注意： MySpringApplicationRunListener 需要构造器，不然会报错缺少(SpringApplication application,String[] args)。可以找到SpringApplicationRunListener的子类EventPublishingRunListener里抄一个12345678910111213141516171819202122232425262728293031323334353637383940public class MySpringApplicationRunListener implements SpringApplicationRunListener &#123; public MySpringApplicationRunListener(SpringApplication application, String[] args) &#123; &#125; public void starting() &#123; System.out.println(&quot;MySpringApplicationRunListener...starting&quot;); &#125; public void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) &#123; this.environmentPrepared(environment); System.out.println(&quot;MySpringApplicationRunListener...environmentPrepared&quot;); &#125; public void environmentPrepared(ConfigurableEnvironment environment) &#123; System.out.println(&quot;MySpringApplicationRunListener...environmentPrepared&quot;); &#125; public void contextPrepared(ConfigurableApplicationContext context) &#123; System.out.println(&quot;MySpringApplicationRunListener...contextPrepared&quot;); &#125; public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println(&quot;MySpringApplicationRunListener...contextLoaded&quot;); &#125; public void started(ConfigurableApplicationContext context) &#123; System.out.println(&quot;MySpringApplicationRunListener...started&quot;); &#125; public void running(ConfigurableApplicationContext context) &#123; System.out.println(&quot;MySpringApplicationRunListener...running&quot;); &#125; public void failed(ConfigurableApplicationContext context, Throwable exception) &#123; System.out.println(&quot;MySpringApplicationRunListener...failed&quot;); &#125;&#125; 其中 application 就是项目启动时那个时间源，可以从application中产生很多不同的生命周期相关事件，所以一定要构造对象时初始化到MySpringApplicationRunListener。 启动： 123456789101112131415161718192021222324MySpringApplicationRunListener...startingMySpringApplicationRunListener...environmentPreparedMySpringApplicationRunListener...environmentPrepared . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.4.5)MyApplicationContextInitializer...initializeMySpringApplicationRunListener...contextPrepared2022-11-09 22:29:26.565 INFO 1764 --- [ main] org.example.helloWorldApplication : Starting helloWorldApplication using Java 1.8.0_271 on DESKTOP-LH92210 with PID 1764 (E:\\WorkSpace\\SpringBootMaven\\target\\classes started by L in E:\\WorkSpace\\SpringBootMaven)2022-11-09 22:29:26.567 INFO 1764 --- [ main] org.example.helloWorldApplication : No active profile set, falling back to default profiles: defaultMySpringApplicationRunListener...contextLoaded2022-11-09 22:29:27.321 INFO 1764 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)// ...2022-11-09 22:29:27.590 INFO 1764 --- [ main] org.example.helloWorldApplication : Started helloWorldApplication in 1.261 seconds (JVM running for 1.527)MySpringApplicationRunListener...startedMyApplicationRunner...runMyCommandLineRunner...run...MySpringApplicationRunListener...running starting 和 environmentPrepared 环境对象准备创建(获取配置环境)。contextPrepared 和 MyApplicationContextInitializer的initialize一样，是在IOC容器创建(加载上下文)前。contextLoaded 就是上下文加载完成时。started 和 running就是创建完成后。 ApplicationListener12345678910111213141516171819@Component@Slf4jpublic class CustomApplicationListener implements ApplicationListener&lt;ApplicationContextEvent&gt; &#123; @Override public void onApplicationEvent(ApplicationContextEvent event) &#123; ApplicationContext applicationContext = event.getApplicationContext(); Environment environment = applicationContext.getEnvironment(); String info = &quot;==========================CustomApplicationListener=============================&quot;; String applicationName = environment.getProperty(&quot;spring.application.name&quot;); String profilesActive = environment.getProperty(&quot;spring.profiles.active&quot;); String serverPort = environment.getProperty(&quot;local.server.port&quot;); String localhost = NetUtil.getLocalhostStr(); if (log.isInfoEnabled())&#123; log.info(&quot;\\n&#123;&#125;\\n===profile:&#123;&#125;\\n===Application:&#123;&#125;\\n===Host:&#123;&#125;:&#123;&#125;\\n&#123;&#125;&quot;, info, applicationName, profilesActive, localhost, serverPort, info); &#125; &#125;&#125; 可以指定不同的事件，如 ContextClosedEvent，那么当容器关闭时，会执行onApplicationEvent方法，以实现线程池的关闭。 Spring中的事件 在spring-context-.jar的jar包中，找到子包：context &gt; event，也可以看到定义的很多事件：ContextClosedEvent、ContextRefreshedEvent、ContextStartedEvent、ContextStoppedEvent，他们继承自 ApplicationContextEvent，又继承自 ApplicationEvent，再继承自 java.util.EventObject。 SpringBoot中的事件 在spring-boot-.jar核心jar包，找到子包: context &gt; event 中可以看到定义了很多事件。如 ApplicationStartingEvent、ApplicationStartedEvent、ApplicationReadyEvent、ApplicationPreparedEvent、ApplicationFailedEvent、 ApplicationEnvironmentPreparedEvent、ApplicationContextInitializedEvent, 他们继承自 SpringApplicationEvent,再继承自 ApplicationEvent， 再继承自 java.util.EventObject。 Spring、Spring boot的事件就是对java事件java.util.EventObject 的封装。 其他包中的事件 在 spring-boot 其他包中也提供了很多 ApplicationEvent 接口的实现，如：AbstractSubProtocolEvent、BrokerAvailabilityEvent、PayloadApplicationEvent、RequestHandledEvent、TestContextEvent。 我们可以在自己的监听器 onApplicationEvent() 方法中监听上述的事件。 如，监听容器关闭时，关闭线程池 1234567891011@Configurationpublic class ThreadPoolExecutorConfig implements ApplicationListener&lt;ContextClosedEvent&gt; &#123; @Override public void onApplicationEvent(ContextClosedEvent arg) &#123; log.info(&quot;destroy threadpoolexecutor before destroyBeans&quot;); threadPoolTaskExecutor().destroy(); threadPoolTaskScheduler().destroy(); &#125;&#125; 跟随SpringBoot 启动过程，分析事件监听部分的源码SpringBoot的入口，即main 方法中： 1SpringApplication.run(MyApplication.class, args); 这个run方法声明，和调用步骤: 123public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; return run(new Class&lt;?&gt;[] &#123; primarySource &#125;, args);&#125; 123public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args);&#125; 分别查看new SpringApplication() 和 run(),其中new SpringApplication()： 123public SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources);&#125; 123456789public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 可以发现，在new SpringApplication()中，有setInitializers() 和 setListeners()。 set的内容，是通过getSpringFactoriesInstances方法，分别拿到所有ApplicationContextInitializer的子类的bean和ApplicationListener的所有子类的bean。 123456789101112131415161718// getSpringFactoriesInstances9() 最终进到这里：private &lt;T&gt; List&lt;T&gt; createSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, ClassLoader classLoader, Object[] args, Set&lt;String&gt; names) &#123; List&lt;T&gt; instances = new ArrayList&lt;&gt;(names.size()); for (String name : names) &#123; try &#123; Class&lt;?&gt; instanceClass = ClassUtils.forName(name, classLoader); Assert.isAssignable(type, instanceClass); Constructor&lt;?&gt; constructor = instanceClass.getDeclaredConstructor(parameterTypes); T instance = (T) BeanUtils.instantiateClass(constructor, args); instances.add(instance); &#125; catch (Throwable ex) &#123; throw new IllegalArgumentException(&quot;Cannot instantiate &quot; + type + &quot; : &quot; + name, ex); &#125; &#125; return instances;&#125; 即使用反射，获得ApplicationContextInitializer的所有子类或ApplicationListener的所有子类，添加并返回instances。 最后我们得出结论，new SpringApplication()的时候，就会找到项目下所有ApplicationContextInitializer子类和ApplicationListener子类，就是对应上文中提到的这两种方式。 接下来再看run() 方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); // getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args)) // 也是使用反射，获得 SpringApplicationRunListener 的所有子类 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); // 1 try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); // 2 callRunners(context, applicationArguments); // ApplicationRunner 和 CommandLineRunner的所有子类 &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); // 3 &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; 首先，getRunListeners() 获得所有 SpringApplicationRunListener的子类，并在不同的时机，分别调用： listeners.starting(); listeners.started(context); listeners.running(context); 其实还有：4. listener.environmentPrepared(environment);4. listener.contextPrepared(context);5. listener.contextLoaded(context); 对应上文中提到SpringApplicationRunListener。 题外话：在 refreshContext(context)方法里，注册了ShutdownHook 1context.registerShutdownHook(); 再看 callRunners： 1callRunners(context, applicationArguments); 1234567891011121314private void callRunners(ApplicationContext context, ApplicationArguments args) &#123; List&lt;Object&gt; runners = new ArrayList&lt;&gt;(); runners.addAll(context.getBeansOfType(ApplicationRunner.class).values()); runners.addAll(context.getBeansOfType(CommandLineRunner.class).values()); AnnotationAwareOrderComparator.sort(runners); for (Object runner : new LinkedHashSet&lt;&gt;(runners)) &#123; if (runner instanceof ApplicationRunner) &#123; callRunner((ApplicationRunner) runner, args); &#125; if (runner instanceof CommandLineRunner) &#123; callRunner((CommandLineRunner) runner, args); &#125; &#125;&#125; 其实就是 通过context.getBeansOfType()方法，拿到ApplicationRunner 和 CommandLineRunner的所有子类的bean，再循环调用这些bean的run方法。 上文提到各类事件，并通过自定义Listener对它们实施监听。实现Spring事件机制主要有4个类： ApplicationEvent：事件，每个实现类表示一类事件，可携带数据。 ApplicationListener：事件监听器，用于接收事件处理时间。 ApplicationEventMulticaster：事件管理者，用于事件监听器的注册和事件的广播。 ApplicationEventPublisher：事件发布者，委托ApplicationEventMulticaster完成事件发布。 在run方法里，伴随spring容器生命周期，也发布了很多事件，例如： 123456handleRunFailure(context, ex, exceptionReporters, listeners);--&gt;handleExitCode(context, exception);--&gt;// ApplicationContext 是继承里 ApplicationEventPublisher，所以能直接发布事件context.publishEvent(new ExitCodeEvent(context, exitCode)); ApplicationContext和ApplicationEventPublisher是接口，所以发布事件的具体实现是由子类提供，例如AbstractApplicationContext的publishEvent方法: 1org.springframework.context.support.AbstractApplicationContext#publishEvent(java.lang.Object, org.springframework.core.ResolvableType) 其中： 12// 获取事件管理者 ApplicationEventMulticaster，并调用multicastEvent方法getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); multicastEvent方法： 12345678910111213public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); Executor executor = getTaskExecutor(); // getApplicationListeners(event, type) 获取这个事件的所有Listener；遍历，invokeListener for (ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; invokeListener(listener, event); &#125; &#125;&#125; invokeListener(listener, event) 其实就是调用onApplicationEvent方法 1listener.onApplicationEvent(event); onApplicationEvent方法就是自定义Listener时必须覆写的方法，实现当监听到对应事件是需要做的处理。 Spring高手之路7——事件机制与监听器的全面探索:https://developer.aliyun.com/article/1267344 自定义事件和监听 通过继承ApplicationEvent来创建自定义的事件。创建一个 CustomApplicationEvent：12345678910111213public class CustomApplicationEvent extends ApplicationEvent &#123; private String message; public CustomApplicationEvent(Object source, String message) &#123; super(source); this.message = message; &#125; public String getMessage() &#123; return message; &#125;&#125; 创建一个监听器来监听这个 CustomApplicationEvent 事件:12345678@Componentpublic class CustomApplicationEventListener implements ApplicationListener&lt;CustomApplicationEvent&gt; &#123; @Override public void onApplicationEvent(CustomApplicationEvent event) &#123; System.out.println(&quot;Received custom event - &quot; + event.getMessage()); &#125;&#125; 应用中的某个地方发布这个CustomApplicationEvent 事件:12345678910111213141516@Componentpublic class CustomEventPublisher &#123; private final ApplicationEventPublisher publisher; // Spring自动装配，等于使用了 @AutoWired ApplicationEventPublisher publisher public CustomEventPublisher(ApplicationEventPublisher publisher) &#123; this.publisher = publisher; &#125; public void doSomethingAndPublishAnEvent(final String message) &#123; System.out.println(&quot;Publishing custom event.&quot;); CustomApplicationEvent customApplicationEvent = new CustomApplicationEvent(this, message); publisher.publishEvent(customApplicationEvent); &#125;&#125; 在主程序，当完成某个操作后，需要发布：12345@AutoWiredprivate CustomEventPublisher publisher; // ... publisher.doSomethingAndPublishAnEvent(&quot;hello world&quot;); 补充一个Spring自动装配知识点：类只有一个构造方法，那么Spring将会自动把这个构造方法当作是我们希望进行自动装配的构造方法，无需显式地添加@Autowired或@inject注解。Spring会尝试在已经创建的bean中寻找能够满足构造器参数要求的bean，并自动将这些bean注入到构造方法中，这就是所谓的自动装配。 在这个例子中，CustomEventPublisher这个类只有一个带有ApplicationEventPublisher参数的构造方法。Spring在创建CustomEventPublisher的实例时，会尝试寻找一个已经创建的ApplicationEventPublisher类型的bean来满足这个构造方法的参数要求。 所以CustomEventPublisher也一定要交给Spring管理Bean。Spring可以管理bean之间的关系。 同样，我们在SpringBoot项目中配置类里声明一写bean时，创建这个bean是需要参数的，如创建RedisTemplate需要一个redisConnectionFactory对象： 1234567@Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(connectionFactory); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(new GenericJackson2JsonRedisSerializer()); return template; 只需要保证我们容器中有这么一个RedisConnectionFactory类型的bean，Spring会自动将他装配过来。 Spring Boot 监控Spring Boot Actuatorspringboot是提供了Restful接口，返回JSON数据，通过分析这些JSON就可以得到springboot运行中的信息。 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 访问: 123# 启动时控制台会输出暴露的Endpoint的地址:# Exposing 2 endpoint(s) beneath base path &#x27;/actuator&#x27;http://localhost:port/actuator 会返回一个json 1234567891011121314151617181920&#123; &quot;_links&quot;:&#123; &quot;self&quot;:&#123; &quot;href&quot;:&quot;http://localhost:8080/actuator&quot;, &quot;templated&quot;:false &#125;, &quot;health&quot;:&#123; &quot;href&quot;:&quot;http://localhost:8080/actuator/health&quot;, # 返回当前应用简要状态:UP。详细状态需要在yml中开启management.endpoint.health.show-details=always。 开启后redis的健康信息都能返回 &quot;templated&quot;:false &#125;, &quot;health-path&quot;:&#123; &quot;href&quot;:&quot;http://localhost:8080/actuator/health/&#123;*path&#125;&quot;, &quot;templated&quot;:true &#125;, &quot;info&quot;:&#123; &quot;href&quot;:&quot;http://localhost:8080/actuator/info&quot;, # 返回配置文件中k/v &quot;templated&quot;:false &#125; &#125;&#125; 默认： Exposing 2 endpoint(s) beneath base path ‘&#x2F;actuator’。代表只暴露了两个信息(health、info)。 yml&#x2F;.properties中设置暴露所有Endpoint:1management.endpoints.web.exposure.include=* 重启后日志输出：1Exposing 13 endpoint(s) beneath base path &#x27;/actuator&#x27; 再次访问 http://localhost:port/actuator 会有更多的json内容了。1&#123;&quot;_links&quot;:&#123;&quot;self&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator&quot;,&quot;templated&quot;:false&#125;,&quot;beans&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/beans&quot;,&quot;templated&quot;:false&#125;,&quot;caches-cache&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/caches/&#123;cache&#125;&quot;,&quot;templated&quot;:true&#125;,&quot;caches&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/caches&quot;,&quot;templated&quot;:false&#125;,&quot;health&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/health&quot;,&quot;templated&quot;:false&#125;,&quot;health-path&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/health/&#123;*path&#125;&quot;,&quot;templated&quot;:true&#125;,&quot;info&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/info&quot;,&quot;templated&quot;:false&#125;,&quot;conditions&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/conditions&quot;,&quot;templated&quot;:false&#125;,&quot;configprops&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/configprops&quot;,&quot;templated&quot;:false&#125;,&quot;env&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/env&quot;,&quot;templated&quot;:false&#125;,&quot;env-toMatch&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/env/&#123;toMatch&#125;&quot;,&quot;templated&quot;:true&#125;,&quot;loggers&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/loggers&quot;,&quot;templated&quot;:false&#125;,&quot;loggers-name&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/loggers/&#123;name&#125;&quot;,&quot;templated&quot;:true&#125;,&quot;heapdump&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/heapdump&quot;,&quot;templated&quot;:false&#125;,&quot;threaddump&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/threaddump&quot;,&quot;templated&quot;:false&#125;,&quot;metrics-requiredMetricName&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/metrics/&#123;requiredMetricName&#125;&quot;,&quot;templated&quot;:true&#125;,&quot;metrics&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/metrics&quot;,&quot;templated&quot;:false&#125;,&quot;scheduledtasks&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/scheduledtasks&quot;,&quot;templated&quot;:false&#125;,&quot;mappings&quot;:&#123;&quot;href&quot;:&quot;http://localhost:9000/actuator/mappings&quot;,&quot;templated&quot;:false&#125;&#125;&#125; 如： http://localhost:9000/actuator/beans 可以查看容器中多少个bean。 http://localhost:9000/actuator/env http://localhost:9000/actuator/heapdump 可以下载堆栈信息 http://localhost:9000/actuator/threaddump 线程信息 http://localhost:9000/actuator/mappings 所有URL路径 注： 分布式配置文件动态刷新，也需要引入依赖Spring Boot Actuator @ConfigurationProperties + &#x2F;actuator&#x2F;refresh @Value + @RefreshScope + &#x2F;actuator&#x2F;refresh 在使用@ConfigurationProperties或@Value + @RefreshScope后，当配置变更： http://localhost:9000/actuator/refresh 手动刷新 Spring Boot AdminJson信息其实不便于查看，于是出现了Spring Boot Admin社区开源框架，对这些json状态信息做了图形化界面的封装。Spring Boot Admin分为 admin-server 和 admin-client。 admin-server 模块，需要单独创建。 创建 admin-server (web项目)，可以同时监控多个client. 导入依赖坐标：admin-starter-server 在引导类上加上注解@EableAdminServer 配置 server.port&#x3D;9000 admin-client 模块：需要被监控的我们业务项目服务就是client 导入依赖坐标：admin-starter-client 配置相关信息(application.yml&#x2F;.properties)：admin-server 地址等 123# admin-server的地址spring.boot.admin.client.url=http://localhost:9000 启动server和client服务 登录admin-server :http://localhost:9000,就能看到所有client的信息：client的配置文件、容器内有多少个bean、有多少请求、JVM信息、正在运行的线程等等… 其实IDEA也有提供一部分监控信息： console旁边有Endpoints – Beans、Health、Mappings Spring Boot 部署Jar包部署使用内置Tomcat，直接打jar包就能部署，也是官方推荐。 使用IDEA中maven打包，在没有修改pom.xml文件时，默认打Jar包。可以使用maven窗口中lifecycle-package就能一键打包(会执行mvn package 命令)，打包后的jar文件会放在当前项目target下(打包成功日志会提示) War包部署不使用内置Tomcat，打成war包后再用外部的tomcat运行。 修改pom.xml文件中package标签为war。12345678910# 这个标签为空时默认jar&lt;package&gt;war&lt;/package&gt;# 指定打包后的文件名&lt;build&gt; &lt;fileName&gt;springboot-1.0.1&lt;/fileName&gt; &lt;plugins&gt; # ... &lt;/plugins&gt;&lt;/build&gt; 引导类继承 SpringBootServletInitializer，重写configure方法，并返回当前引导类字节码文件。 123456789101112@SpringBootApplicationpublic class helloWorldApplication extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; SpringApplication.run(helloWorldApplication.class, args); &#125; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(helloWorldApplication.class); &#125;&#125; 再使用IDEA中maven打包,就能打成war包，也是放在和jar相同的目录下。 war包放到tomcat目录webapps目录下，启动tomcat: bin&#x2F;startup.sh 使用外置tomcat启动时，我们在application.yml中配置的server.port就不会起作用了(是对内置tomcat的配置)，指定端口需要在外置tomcat中指定。 SprinBoot 版本升级引发的问题与JDK版本从Spring6以及SprinBoot3.0开始最低支持JDK17，如果JDK还在用8，会出现报错： 1234java: 无法访问org.springframework.boot.SpringApplication 错误的类文件: /C:/Maven/Repository/org/springframework/boot/spring-boot/3.2.2/spring-boot-3.2.2.jar!/org/springframework/boot/SpringApplication.class 类文件具有错误的版本 61.0, 应为 52.0 请删除该文件或确保该文件位于正确的类路径子目录中。 使用SpringBoot 2.x。 使用JDK17。 12jdk17无论从GC，或者特性等各方面都超过了Java8，且加上JDK17是一个 Oracle官宣可以免费商用的LTS版本。Long Term Support，官方长期支持的版本。JDK 17 最多可以支持到 2029 年 9 月份。免费商用 8 年。不过JDK 8 可以延长支持到 2030 年 12 月。 循环依赖Spring 原本使用三级缓存解决循环依赖，但在后续版本中，不再解决循环依赖。 SpringBoot 从 2.6.0 开始默认不允许出现 Bean 循环引用。启动容器会失败，提示循环依赖： 1234567891011121314***************************APPLICATION FAILED TO START***************************Description:The dependencies of some of the beans in the application context form a cycle:┌─────┐| a_user (field private org.example.circular.dependencies.B_user org.example.circular.dependencies.A_user.buser)↑ ↓| b_user (field private org.example.circular.dependencies.A_user org.example.circular.dependencies.B_user.auser)└─────┘Action:Relying upon circular references is discouraged and they are prohibited by default.Update your application to remove the dependency cycle between beans.As a last resort, it may be possible to break the cycle automatically by setting spring.main.allow-circular-references to true. 解决方案 使用 @Lazy 在导致循环依赖的Bean上添加@Lazy注解 Spring会延迟初始化这些Bean,先完成非Lazy的Bean初始化 然后再通过setter注入完成Lazy Bean的初始化 合并类 将互相依赖的类合并为一个类,避免相互依赖 如果是Spring Boot 可以开启支持 使用SpringApplicationBuilder来启动Spring Boot应用，并通过allowCircularReferences(true)方法开启了循环依赖支持。 123public static void main(String[] args) &#123; new SpringApplicationBuilder(DemoApplication.class).allowCircularReferences(true).run(args);&#125; Spring Boot 2.7及以上版本,可以通过spring.main.allow-circular-references&#x3D;true配置属性明确开启循环依赖支持。 123spring: main: allow-circular-references:true","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"Spring Boot","slug":"Spring/Spring-Boot","permalink":"http://example.com/categories/Spring/Spring-Boot/"}],"tags":[]},{"title":"Hive支持处理LZO压缩格式","slug":"Hive支持处理LZO压缩格式","date":"2024-09-17T04:46:10.000Z","updated":"2024-09-17T04:47:27.053Z","comments":true,"path":"2024/09/17/Hive支持处理LZO压缩格式/","permalink":"http://example.com/2024/09/17/Hive%E6%94%AF%E6%8C%81%E5%A4%84%E7%90%86LZO%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F/","excerpt":"","text":"hadoop支持lzo ，见上一篇博文：https://blog.csdn.net/qq_45494908/article/details/122518940?spm=1001.2014.3001.5501 参考：https://blog.csdn.net/TomAndersen/article/details/106892522 1.在core-site.xml文件的io.compression.codecs参数中添加lzo、lzop压缩对应的编解码器类，并配置io.compression.codec.lzo.class参数&lt;!-- 声明可用的压缩算法的编/解码器 --&gt; &lt;property&gt; &lt;name&gt;io.compression.codecs&lt;/name&gt; &lt;value&gt; org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.DeflateCodec, org.apache.hadoop.io.compress.BZip2Codec, org.apache.hadoop.io.compress.SnappyCodec, org.apache.hadoop.io.compress.Lz4Codec, com.hadoop.compression.lzo.LzoCodec, com.hadoop.compression.lzo.LzopCodec &lt;/value&gt; &lt;description&gt; A comma-separated list of the compression codec classes that can be used for compression/decompression. In addition to any classes specified with this property (which take precedence), codec classes on the classpath are discovered using a Java ServiceLoader. &lt;/description&gt; &lt;/property&gt; &lt;!-- 配置lzo编解码器相关参数 --&gt; &lt;property&gt; &lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt; &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt; &lt;/property&gt; 2.在mapred-site.xml文件中设置MR Job执行时使用的压缩方式&lt;!-- map输出是否压缩 --&gt; &lt;!-- 默认值:false --&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.output.compress&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt; Should the outputs of the maps be compressed before being sent across the network. Uses SequenceFile compression. &lt;/description&gt; &lt;/property&gt; &lt;!-- 设置map输出压缩所使用的对应压缩算法的编解码器,此处设置为LzoCodec,生成的文件后缀为.lzo_deflate --&gt; &lt;!-- 默认值:org.apache.hadoop.io.compress.DefaultCodec --&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.output.compress.codec&lt;/name&gt; &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt; &lt;description&gt; If the map outputs are compressed, how should they be compressed? &lt;/description&gt; &lt;/property&gt; &lt;!-- 设置MR job最终输出文件是否压缩 --&gt; &lt;!-- 默认值:false --&gt; &lt;property&gt; &lt;name&gt;mapreduce.output.fileoutputformat.compress&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;Should the job outputs be compressed? &lt;/description&gt; &lt;/property&gt; &lt;!-- 设置MR job最终输出文件所使用的压缩算法对应的编解码器,此处设置为LzoCodec,生成的文件后缀为.lzo_deflate --&gt; &lt;!-- 默认值:org.apache.hadoop.io.compress.DefaultCodec --&gt; &lt;property&gt; &lt;name&gt;mapreduce.output.fileoutputformat.compress.codec&lt;/name&gt; &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt; &lt;description&gt;If the job outputs are compressed, how should they be compressed? &lt;/description&gt; &lt;/property&gt; &lt;!-- 设置序列文件的压缩格式 --&gt; &lt;!-- 默认值:RECORD --&gt; &lt;property&gt; &lt;name&gt;mapreduce.output.fileoutputformat.compress.type&lt;/name&gt; &lt;value&gt;BLOCK&lt;/value&gt; &lt;description&gt;If the job outputs are to compressed as SequenceFiles, how should they be compressed? Should be one of NONE, RECORD or BLOCK. &lt;/description&gt; &lt;/property&gt; 配置Hive在$HIVE_HOME&#x2F;conf&#x2F;hive-site.xml文件中设置如下参数，使得Hive进行查询时使用压缩功能，具体使用的压缩算法默认与Hadoop中的配置相同 &lt;!-- 设置hive语句执行输出文件是否开启压缩,具体的压缩算法和压缩格式取决于hadoop中 设置的相关参数 --&gt; &lt;!-- 默认值:false --&gt; &lt;property&gt; &lt;name&gt;hive.exec.compress.output&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt; This controls whether the final outputs of a query (to a local/HDFS file or a Hive table) is compressed. The compression codec and other options are determined from Hadoop config variables mapred.output.compress* &lt;/description&gt; &lt;/property&gt; &lt;!-- 控制多个MR Job的中间结果文件是否启用压缩,具体的压缩算法和压缩格式取决于hadoop中 设置的相关参数 --&gt; &lt;!-- 默认值:false --&gt; &lt;property&gt; &lt;name&gt;hive.exec.compress.intermediate&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt; This controls whether intermediate files produced by Hive between multiple map-reduce jobs are compressed. The compression codec and other options are determined from Hadoop config variables mapred.output.compress* &lt;/description&gt; &lt;/property&gt; 建立支持lzo压缩数据，写入Hive表[liqiang@Gargantua data]$ lzop emp.txt # 启动hive hive (default)&gt; CREATE TABLE emp_lzo like emp_hive &gt; STORED AS &gt; INPUTFORMAT &quot;com.hadoop.mapred.DeprecatedLzoTextInputFormat&quot; &gt; OUTPUTFORMAT &quot;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&quot;; OK hive (default)&gt; LOAD DATA LOCAL INPATH &#39;/home/liqiang/data/emp.txt.lzo&#39; INTO TABLE emp_lzo; 准备一份lzo格式的数据，并loadhive (default)&gt; LOAD DATA LOCAL INPATH &#39;/home/liqiang/data/emp.txt.lzo&#39; INTO TABLE emp_lzo; 查询 hive (default)&gt; select * from emp_lzo; OK emp_lzo.empno emp_lzo.ename emp_lzo.job emp_lzo.mgr emp_lzo.hiredate emp_lzo.sal emp_lzo.comm emp_lzo.deptno 7369 SMITH CLERK 7902 NULL 800 NULL 20 7499 ALLEN SALESMAN 7698 NULL 1600 300 30 7521 WARD SALESMAN 7698 NULL 1250 500 30 7566 JONES MANAGER 7839 NULL 2975 NULL 20 7654 MARTIN SALESMAN 7698 NULL 1250 1400 30 7698 BLAKE MANAGER 7839 NULL 2850 NULL 30","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"大数据/Hive","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"Hadoop支持LZO压缩配置","slug":"Hadoop支持LZO压缩配置","date":"2024-09-17T04:43:37.000Z","updated":"2024-09-17T04:45:39.381Z","comments":true,"path":"2024/09/17/Hadoop支持LZO压缩配置/","permalink":"http://example.com/2024/09/17/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9%E9%85%8D%E7%BD%AE/","excerpt":"","text":"环境准备准备lzo格式压缩文件#检查是否有lzop命令 [hadoop@Gargantua software]$ which lzop /bin/lzop #若没有执行如下安装命令 [root@Gargantua ~]# yum install -y svn ncurses-devel [root@Gargantua ~]# yum install -y gcc gcc-c++ make cmake [root@Gargantua ~]# yum install -y openssl openssl-devel svn ncurses-devel zlib-devel libtool [root@Gargantua ~]# yum install -y snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop autoconf automake cmake lzo压缩：lzop -v filenamelzo解压：lzop -dv filename 下载、安装并编译LZOwget http://www.oberhumer.com/opensource/lzo/download/lzo-2.10.tar.gz tar -zxvf lzo-2.10.tar.gz cd lzo-2.10 .&#x2F;configure -prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;lzo&#x2F; make make install 编译hadoop-lzo源码2.1 下载hadoop-lzo的源码，下载地址：https://github.com/twitter/hadoop-lzo/archive/master.zip2.2 解压之后，修改pom.xml &lt;hadoop.current.version&gt;3.2.2&lt;&#x2F;hadoop.current.version&gt;2.3 声明两个临时环境变量 export C_INCLUDE_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;lzo&#x2F;include export LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;lzo&#x2F;lib2.4 编译 进入hadoop-lzo-master，执行maven编译命令 mvn package -Dmaven.test.skip&#x3D;true2.5 进入target，hadoop-lzo-0.4.21-SNAPSHOT.jar 即编译成功的hadoop-lzo组件 配置hadoop关联jar将编译好后的 hadoop-lzo-0.4.21-SNAPSHOT.jar 放入 $HADOOP_HOME&#x2F;share&#x2F;hadoop&#x2F;common&#x2F; core-site.xml增加配置支持LZO压缩12345678910111213141516&lt;property&gt; &lt;name&gt;io.compression.codecs&lt;/name&gt; &lt;value&gt; org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.BZip2Codec, org.apache.hadoop.io.compress.SnappyCodec, com.hadoop.compression.lzo.LzoCodec, com.hadoop.compression.lzo.LzopCodec &lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt; &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;&lt;/property&gt; &#x2F;&#x2F; 将一个大于128M的文件lzo压缩wc.data.lzo，并上传到hdfs [liqiang@Gargantua data]$lzop wc.data [liqiang@Gargantua data]$ hdfs dfs -put wc.data.lzo /input/wc.data.lzo 执行wc hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount -Dmapreduce.output.fileoutputformat.compress=true -Dmapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec /input/wc.data.lzo /output/wc2 对lzo文件建立索引hadoop jar $HADOOP_HOME/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar com.hadoop.compression.lzo.DistributedLzoIndexer /input/wc.data.lzo hdfs dfs -rm -r &#x2F;output&#x2F;wc2&#x2F;&#x2F; 再次执行wc 发现还是不行。。。单纯的做了索引还是不行的，在运行程序的时候还要对要运行的程序进行相应的更改。把inputformat设置成LzoTextInputFormat，不然还是会把索引文件也当做是输入文件，还是只运行一个map来处理。命令中增加： -Dmapreduce.job.inputformat.class=com.hadoop.mapreduce.LzoTextInputFormat 参考：https://blog.csdn.net/qq_43081842/article/details/105455070 hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount \\ -Dmapreduce.job.inputformat.class=com.hadoop.mapreduce.LzoTextInputFormat /input/wc.data.lzo /output/wc7 出现 number of splits:2 参考博文：https://www.cnblogs.com/xuziyu/p/10729992.htmlhttps://blog.csdn.net/zmzdmx/article/details/113655883https://blog.csdn.net/qq_31405633/article/details/89353295 编译Hadoop（native code），以支持snappy 、bzip2…1需要下载Protoco1Buffer 2.5.0进行交装 安装依赖 1234[root@Gargantua ~]# yum install -y svn ncurses-devel[root@Gargantua ~]# yum install -y gcc gcc-c++ make cmake[root@Gargantua ~]# yum install -y openssl openssl-devel svn ncurses-devel zlib-devel libtool[root@Gargantua ~]# yum install -y snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop autoconf automake cmake 1mvn clean package -Pdist -Pnative -Dtar 编译好后除了将linux上etc下配置文件的其他都覆盖就行。 其他记录（暂时放在这里）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182useUnicode=true&amp;characterEncoding=UTF-8 export PROTOC_HOME=/home/hadoop/app/protobufexport PATH=$PROTOC_HOME/bin:$PATHcd $PROTOC_HOME./configure --prefix=$PROTOC_HOMEmake make installmake &amp;&amp; make install 才会在protobuf目录下使用 protoc 命令export CMAKE_HOME=/home/hadoop/app/cmakeexport PATH=$CMAKE_HOME/bin:$PATHexport DOXYGEN_HOME=/home/hadoop/app/doxygenexport PATH=$DOXYGEN_HOME/bin:$PATHexport FINDBUGS_HOME=/home/hadoop/app/findbugsexport PATH=$FINDBUGS_HOME/bin:$PATHexport NODEJS_HOME=/home/hadoop/app/nodeJsexport PATH=$NODEJS_HOME/bin:$PATHyum install -y openssl openssl-devel svn ncurses-devel zlib-devel libtoolyum install -y snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop autoconf automakemvn clean package -Pdist,native -DskipTests -Dtarcd hadoop-dist/target/ 1. 下载、安装并编译LZOwget http://www.oberhumer.com/opensource/lzo/download/lzo-2.10.tar.gztar -zxvf lzo-2.10.tar.gzcd lzo-2.10./configure -prefix=/usr/local/hadoop/lzo/makemake install2. 编译hadoop-lzo源码2.1 下载hadoop-lzo的源码，下载地址：https://github.com/twitter/hadoop-lzo/archive/master.zip2.2 解压之后，修改pom.xml &lt;hadoop.current.version&gt;3.2.2&lt;/hadoop.current.version&gt;2.3 声明两个临时环境变量 export C_INCLUDE_PATH=/usr/local/hadoop/lzo/include export LIBRARY_PATH=/usr/local/hadoop/lzo/lib 2.4 编译 进入hadoop-lzo-master，执行maven编译命令 mvn package -Dmaven.test.skip=true2.5 进入target，hadoop-lzo-0.4.21-SNAPSHOT.jar 即编译成功的hadoop-lzo组件将编译好后的 hadoop-lzo-0.4.21-SNAPSHOT.jar 放入 $HADOOP_HOME/share/hadoop/common/core-site.xml增加配置支持LZO压缩hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount -Dmapreduce.output.fileoutputformat.compress=true -Dmapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec /input/wc.data.lzo /output/wc2// 准备一个大于128M的文件，上传到/input/wordcount.datahadoop jar $HADOOP_HOME/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar com.hadoop.compression.lzo.DistributedLzoIndexer /input/wc.data.lzohdfs dfs -rm -r /output/wc2// 再次执行https://blog.csdn.net/houzhizhen/article/details/42077589","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hadoop","slug":"大数据/Hadoop","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}]},{"title":"Hadoop环境搭建过程记录","slug":"Hadoop环境搭建过程记录","date":"2024-09-17T04:41:00.000Z","updated":"2024-09-17T04:44:18.789Z","comments":true,"path":"2024/09/17/Hadoop环境搭建过程记录/","permalink":"http://example.com/2024/09/17/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/","excerpt":"","text":"常用命令[liqiang@Gargantua ~]$ cd $HADOOP_HOME;pwd /home/liqiang/app/hadoop 【启动、停止】 [liqiang@Gargantua ~]$ cd $HADOOP_HOME/sbin # 启动 hdfs 、启动 yarn start-dfs.sh start-yarn.sh start-all.sh # 关闭 stop-alll.sh stop-dfs.sh stop-yarn.sh 【操作hdfs文件】 [liqiang@Gargantua ~]$ cd $HADOOP_HOME/bin # path可以是绝对路径，也可以是相对路径。不指定path则操作当前用户工作主目录 hdfs dfs -ls # 列出工作主目录下的信息 hdfs dfs -ls / # 列出hdfs根路径下的信息 hdfs dfs -ls /input 【hadoop dfs -ls】 hdfs dfs -cat /input/wc.data 【hadoop dfs -cat】 hdfs dfs -text /input/data.lzo [可用于查看压缩文件,不会乱码] hdfs dfs -mkdir /input 【hadoop dfs -mkdir】 hdfs dfs -put wc.log /input 【hadoop dfs -put】 hdfs dfs -get /input ~/data 【hadoop dfs -get】 hdfs dfs -rm [-r] [-f] &lt;uri&gt; # 删除目录或文件，-r -f不能组合成-rf hdfs dfs -rm -r -f /test # 删除根目录下的test目录 hdfs dfs -rmdir /test # 删除目录：只能删除空目录 【运行jar】 bin/hadoop jar xxx.jar grep input output ‘dfs[a-z.]+’ [当设置环境变量后] yarn jar xxx.jar wordcount /input /output 更多命令总结：HDFS常用命令 HADOOP_HOME 下的目录bin目录下有如下可执行文件，如以上操作hdfs文件 hdfs dfs命令、yarn 命令$HADOOP_HOME/bin 【/home/liqiang/app/hadoop/bin】 -rwxr-xr-x 1 liqiang liqiang 8707 Jan 3 2021 hadoop 【cd hadoop: Not a directory】 -rwxr-xr-x 1 liqiang liqiang 11274 Jan 3 2021 hdfs -rwxr-xr-x 1 liqiang liqiang 6237 Jan 3 2021 mapred -rwxr-xr-x 1 liqiang liqiang 12112 Jan 3 2021 yarn sbin目录下启动 、停止的命令$HADOOP_HOME/sbin 【/home/liqiang/app/hadoop/sbin】 -rwxr-xr-x 1 liqiang liqiang 2756 Jan 3 2021 distribute-exclude.sh drwxr-xr-x 4 liqiang liqiang 4096 Jan 3 2021 FederationStateStore -rwxr-xr-x 1 liqiang liqiang 1983 Jan 3 2021 hadoop-daemon.sh -rwxr-xr-x 1 liqiang liqiang 2522 Jan 3 2021 hadoop-daemons.sh -rwxr-xr-x 1 liqiang liqiang 1542 Jan 3 2021 httpfs.sh -rwxr-xr-x 1 liqiang liqiang 1500 Jan 3 2021 kms.sh -rwxr-xr-x 1 liqiang liqiang 1841 Jan 3 2021 mr-jobhistory-daemon.sh -rwxr-xr-x 1 liqiang liqiang 2086 Jan 3 2021 refresh-namenodes.sh -rwxr-xr-x 1 liqiang liqiang 2221 Jan 3 2021 start-all.sh 【启动全部】 -rwxr-xr-x 1 liqiang liqiang 1880 Jan 3 2021 start-balancer.sh -rwxr-xr-x 1 liqiang liqiang 5170 Jan 3 2021 start-dfs.sh 【启动hdfs】 -rwxr-xr-x 1 liqiang liqiang 1793 Jan 3 2021 start-secure-dns.sh -rwxr-xr-x 1 liqiang liqiang 3342 Jan 3 2021 start-yarn.sh 【启动yarn】 -rwxr-xr-x 1 liqiang liqiang 2166 Jan 3 2021 stop-all.sh 【停止全部】 -rwxr-xr-x 1 liqiang liqiang 1783 Jan 3 2021 stop-balancer.sh -rwxr-xr-x 1 liqiang liqiang 3898 Jan 3 2021 stop-dfs.sh -rwxr-xr-x 1 liqiang liqiang 1756 Jan 3 2021 stop-secure-dns.sh -rwxr-xr-x 1 liqiang liqiang 3083 Jan 3 2021 stop-yarn.sh -rwxr-xr-x 1 liqiang liqiang 1982 Jan 3 2021 workers.sh -rwxr-xr-x 1 liqiang liqiang 1814 Jan 3 2021 yarn-daemon.sh -rwxr-xr-x 1 liqiang liqiang 2328 Jan 3 2021 yarn-daemons.sh etc&#x2F;hadoop 目录下是关于hadoop的配置文件$HADOOP_HOME/etc/hadoop 【/home/liqiang/app/hadoop/etc/hadoop】 # 常用： -rw-r--r-- 1 liqiang liqiang 16356 Dec 28 02:13 hadoop-env.sh 【JAVA_HOME、HADOOP_PID_DIR】 -rw-r--r-- 1 liqiang liqiang 634 Dec 31 01:20 core-site.xml 【fs.defaultFS即hdfs对外提供的ip:端口、：NN数据目录...】【按需配置(9000)而9870是web端保持默认即可】 -rw-r--r-- 1 liqiang liqiang 1881 Jan 9 20:51 hdfs-site.xml 【dfs.replication即block副本数量】 -rw-r--r-- 1 liqiang liqiang 10 Dec 28 01:09 workers 【指定DN启动的hosts (是文件 Not a directory)】 -rw-r--r-- 1 liqiang liqiang 1764 Jan 3 2021 mapred-env.sh -rw-r--r-- 1 liqiang liqiang 519 Dec 28 20:15 mapred-site.xml 【指定mr计算框架、运行时classpath目录等】 -rw-r--r-- 1 liqiang liqiang 6272 Jan 3 2021 yarn-env.sh -rw-r--r-- 1 liqiang liqiang 1456 Dec 28 20:18 yarn-site.xml 【yarn作业web界面端口默认8088(123)】 -rw-r--r-- 1 liqiang liqiang 9213 Jan 3 2021 capacity-scheduler.xml -rw-r--r-- 1 liqiang liqiang 1335 Jan 3 2021 configuration.xsl -rw-r--r-- 1 liqiang liqiang 1940 Jan 3 2021 container-executor.cfg -rw-r--r-- 1 liqiang liqiang 3321 Jan 3 2021 hadoop-metrics2.properties -rw-r--r-- 1 liqiang liqiang 11392 Jan 3 2021 hadoop-policy.xml -rw-r--r-- 1 liqiang liqiang 3414 Jan 3 2021 hadoop-user-functions.sh.example -rw-r--r-- 1 liqiang liqiang 1484 Jan 3 2021 httpfs-env.sh -rw-r--r-- 1 liqiang liqiang 1657 Jan 3 2021 httpfs-log4j.properties -rw-r--r-- 1 liqiang liqiang 21 Jan 3 2021 httpfs-signature.secret -rw-r--r-- 1 liqiang liqiang 620 Jan 3 2021 httpfs-site.xml -rw-r--r-- 1 liqiang liqiang 3518 Jan 3 2021 kms-acls.xml -rw-r--r-- 1 liqiang liqiang 1351 Jan 3 2021 kms-env.sh -rw-r--r-- 1 liqiang liqiang 1860 Jan 3 2021 kms-log4j.properties -rw-r--r-- 1 liqiang liqiang 682 Jan 3 2021 kms-site.xml -rw-r--r-- 1 liqiang liqiang 14713 Jan 3 2021 log4j.properties drwxr-xr-x 2 liqiang liqiang 4096 Jan 3 2021 shellprofile.d -rw-r--r-- 1 liqiang liqiang 2316 Jan 3 2021 ssl-client.xml.example -rw-r--r-- 1 liqiang liqiang 2697 Jan 3 2021 ssl-server.xml.example -rw-r--r-- 1 liqiang liqiang 2642 Jan 3 2021 user_ec_policies.xml.template -rw-r--r-- 1 liqiang liqiang 4113 Jan 3 2021 mapred-queues.xml.template -rw-r--r-- 1 liqiang liqiang 2591 Jan 3 2021 yarnservice-log4j.properties share&#x2F;hadoop 目录下是关于hdfs、mr、yarn… 的各种jar包drwxr-xr-x 2 liqiang liqiang 4096 Jan 3 2021 client drwxr-xr-x 6 liqiang liqiang 4096 Jan 3 2021 common drwxr-xr-x 6 liqiang liqiang 4096 Jan 3 2021 hdfs drwxr-xr-x 6 liqiang liqiang 4096 Jan 3 2021 mapreduce drwxr-xr-x 6 liqiang liqiang 4096 Jan 3 2021 tools drwxr-xr-x 8 liqiang liqiang 4096 Jan 3 2021 yarn 如下文中提到 使用 find .&#x2F; -name ‘*example*‘ 查找官方提供mr案例的jar其实就在 ~/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar logs 目录下是关于hadoop的日志如部署后namenode启动失败，可： [liqiang@Gargantua ~]$ cd $HADOOP_HOME/logs;ll -rw-rw-r-- 1 liqiang liqiang 1256356 Jan 9 21:56 hadoop-liqiang-namenode-Gargantua.log -rw-rw-r-- 1 liqiang liqiang 1294353 Jan 9 21:56 hadoop-liqiang-secondarynamenode-Gargantua.log -rw-rw-r-- 1 liqiang liqiang 623236 Jan 9 20:55 hadoop-liqiang-datanode-Gargantua.log -rw-rw-r-- 1 liqiang liqiang 731136 Jan 9 22:16 hadoop-liqiang-nodemanager-Gargantua.log -rw-rw-r-- 1 liqiang liqiang 551680 Jan 9 22:06 hadoop-liqiang-resourcemanager-Gargantua.log 查看 namenode 日志 # 全部加载并根据 ERROR过滤保留前后10行 【可以补充下针对大文件更高效的方式 less】 cat hadoop-liqiang-namenode-Gargantua.log|grep ERROR -C10 # 实时查看 tail -200f hadoop-liqiang-namenode-Gargantua.log 部署过程参考官方文档https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html 配置jdkhadoop依赖jdkjdk部署参考上篇博文：https://editor.csdn.net/md/?articleId=121432910本机JAVA_HOME：&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_121 安装&amp;配置上传hadoop 官网hadoop.apache.org下载hadoop-3.2.2.tar.gz，版本：3.2.2rz &#x2F; xftp上传到服务器&#x2F;tmp下。 [ &#x2F;tmp目录会定时清除没有使用的文件，默认30天。] 新建用户、工作目录 useradd liqiangid liqiangsu - liqiangmkdir sourcecode software app log data lib tmp 移动解压[root@Gargantua tmp]# mv /tmp/hadoop-3.2.2.tar.gz /home/liqiang/software/ [root@Gargantua tmp]# tar -zxvf /home/liqiang/software/hadoop-3.2.2.tar.gz -C /home/liqiang/app/ 【-C 解压到指定目录】 [root@Gargantua app]# ln -s hadoop-3.2.2/ hadoop 【root用户执行的解压和创建软连接，所以需要将权限修正】 [root@Gargantua app]# chown liqiang:liqiang hadoop [root@Gargantua app]# chown liqiang:liqiang hadoop/* [root@Gargantua hadoop]# chown liqiang:liqiang app/* hadoop解压后文件夹说明 bin # hadoop相关命令 etc # 配置文件 include lib # 存放Hadoop的本地库（对数据进行压缩解压缩功能） libexec sbin # hadoop服务启动停止脚本 【sbin/start-dfs.sh、sbin/start-yarn.sh】 share # 存放Hadoop的依赖jar包、文档、和官方案例 logs # 日志文件 配置ssh: 远程登录[liqiang@Gargantua ~]$ ssh ssh ssh-add ssh-agent ssh-copy-id sshd sshd-keygen ssh-keygen ssh-keyscan [liqiang@Gargantua ~]$ ssh-keygen 【ssh与keygen之间只有-没有空格】 【三次回车，得到公钥和私钥】 Your identification has been saved in /home/liqiang/.ssh/id_rsa. Your public key has been saved in /home/liqiang/.ssh/id_rsa.pub. 将公钥追加到 ~&#x2F;.ssh&#x2F;authorized_keys [liqiang@Gargantua ~]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 刷新权限，否则ssh连接时仍然会提示输入密码 [liqiang@Gargantua ~]$ chmod 0600 ~/.ssh/authorized_keys # 测试 ssh Gargantua # 第一次需要输入yes # 如果还需要输入密码，那么ssh配置或者600权限有问题。 配置伪分布式模式配置JAVA_HOMEhadoop不能识别到&#x2F;etc&#x2F;profile里的JAVA_HOME，需要在hadoop-env.sh自己配置一遍 [root@Gargantua &#x2F;]# su - liqiang[liqiang@Gargantua ~]$ cd app&#x2F;hadoop&#x2F;etc&#x2F;hadoop[liqiang@Gargantua hadoop]$ vi hadoop-env.sh # 加入以下配置 export JAVA_HOME=/usr/java/jdk1.8.0_121 export HADOOP_PID_DIR=/home/liqiang/tmp 配置HADOOP_PID_DIR 的目的： 查看 &#x2F;tmp目录下发现，hadoop好几个数据和文件都是默认存放在 &#x2F;tmp下，而 &#x2F;tmp下的内容是会被定期删除的，非常危险。假如未做HADOOP_PID_DIR(hadoop-env.sh) 和 hadoop.tmp.dir(core-site.xml)配置： [liqiang@Gargantua hadoop]$ ll &#x2F;tmp&#x2F; drwxr-xr-x 3 liqiang liqiang 4096 Dec 27 22:57 hadoop drwxrwxr-x 4 liqiang liqiang 4096 Dec 27 22:57 hadoop-liqiang 【# 默认的数据存储目录hadoop.tmp.dir，在core-site.xml改掉】 -rw-rw-r– 1 liqiang liqiang 5 Dec 28 00:27 hadoop-liqiang-datanode.pid 【# 默认pid文件的存储目录，在hadoop-env.sh改掉】 -rw-rw-r– 1 liqiang liqiang 5 Dec 28 00:27 hadoop-liqiang-namenode.pid -rw-rw-r– 1 liqiang liqiang 5 Dec 28 00:27 hadoop-liqiang-secondarynamenode.pid 以上pid文件集群中记录每个进程启动的pid编号。当执行sbin&#x2F;stop-dfs.sh或stop-all.sh等命令的时候，hadoop会根据pid文件找到每个进程的pid，然后执行kill -9 pid来关闭进程。如果 pid 文件丢失，将会导致节点在执行stop命令是并没有关闭，进而无法重启使新配置文件生效。（记得修改hadoop-env.sh前先stop-all不然stop时就已经找不到pid文件了） 配置启动节点hadoop的配置文件都在HADOOP_HOME&#x2F;etc目录下： [liqiang@Gargantua hadoop]$ pwd&#x2F;home&#x2F;liqiang&#x2F;app&#x2F;hadoop&#x2F;etc&#x2F;hadoop[liqiang@Gargantua hadoop]$ vi core-site.xml[liqiang@Gargantua hadoop]$ vi hdfs-site.xml core-site.xml1234567891011121314&lt;configuration&gt; &lt;!--配置NameNode的启动端点--&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://Gargantua:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置hadoop namenode 数据目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/liqiang/tmp/hadoop-$&#123;user.name&#125;&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 说明： fs.defaultFS 代表配置namecode以Gargantua启动，[确保 &#x2F;etc&#x2F;profile中已有Gargantua配置本机内网Ip]。而datanode需要在 ~&#x2F;app&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;workers 中将 localhost修改为Gargantua。将NN,SNN,DN节点都以同一host而不是ip启动，可以方便如果ip变更，则只需要在hosts文件中修改一次即可。 hadoop.tmp.dir 最好在hadoop第一次启动前做好配置，否则namenode 数据目录按默认目录是在 &#x2F;tmp下，而 &#x2F;tmp下的内容是会被定期删除的，非常危险。如果在没有变更配置的情况下已经启动过，再直接改配置文件的此项配置，会导致NameNode服务启动失败。hadoop的每个进程每次启动都会生成一个版本文件，确保除第一次启动外这个文件只有一个（改完配置记得把文件也复制过去）【需要1.stop-all.sh，2.修改core-site.xml，3.拷贝hadoop文件到该去的地方，4.start-all.sh】 hdfs-site.xml1234567891011121314151617181920212223&lt;configuration&gt; &lt;!--配置block副本数量，默认为3--&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;!--配置Secondary NameNode的启动端点(http协议)--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;Gargantua:9868&lt;/value&gt; &lt;/property&gt; &lt;!--配置Secondary NameNode的启动端点(https协议)--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt; &lt;value&gt;Gargantua:9869&lt;/value&gt; &lt;/property&gt; &lt;!--如果一台机器挂载了多个数据盘，那么需要做一下配置： &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/data01/dfs/dn,/data02/dfs/dn,/data03/dfs/dn&lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; 说明： 配置Secondary以Gargantua启动。 如果一台机器挂载了多块物理磁盘，需要对dfs.datanode.data.dir做配置。例如：一块磁盘的写能力30M&#x2F;s，装载10快磁盘后，就是300M&#x2F;s，写同样的数据，后者更高效。多块磁盘是为了存储空间更大，且高效率的读写IO。 肯定比单块磁盘更快。所以在生产上，DataNode的dfs.datanode.data.dir参数必须根据机器的实际情况配置。 启动写在前：若启动失败(logs)如果某个节点启动不成功，可以在尝试在$HADOOP_HOME&#x2F;logs 里找节点对应的日志文件 [liqiang@Gargantua ~]$ cd $HADOOP_HOME/logs;ll -rw-rw-r-- 1 liqiang liqiang 145676 Dec 28 02:14 hadoop-liqiang-datanode-Gargantua.log -rw-rw-r-- 1 liqiang liqiang 692 Dec 28 02:14 hadoop-liqiang-datanode-Gargantua.out -rw-rw-r-- 1 liqiang liqiang 692 Dec 28 02:06 hadoop-liqiang-datanode-Gargantua.out.1 -rw-rw-r-- 1 liqiang liqiang 183747 Dec 28 02:15 hadoop-liqiang-namenode-Gargantua.log -rw-rw-r-- 1 liqiang liqiang 692 Dec 28 02:14 hadoop-liqiang-namenode-Gargantua.out -rw-rw-r-- 1 liqiang liqiang 692 Dec 28 02:06 hadoop-liqiang-namenode-Gargantua.out.1 -rw-rw-r-- 1 liqiang liqiang 154067 Dec 28 02:15 hadoop-liqiang-secondarynamenode-Gargantua.log -rw-rw-r-- 1 liqiang liqiang 692 Dec 28 02:14 hadoop-liqiang-secondarynamenode-Gargantua.out -rw-rw-r-- 1 liqiang liqiang 692 Dec 28 02:06 hadoop-liqiang-secondarynamenode-Gargantua.out.1 如namenode启动失败： cat hadoop-liqiang-namenode-Gargantua.log|grep ERROR -C10 或 tail -200f hadoop-liqiang-namenode-Gargantua.log 1.格式化hdfs文件目录 [liqiang@Gargantua hadoop]$ pwd&#x2F;home&#x2F;liqiang&#x2F;app&#x2F;hadoop[liqiang@Gargantua hadoop]$ bin&#x2F;hdfs namenode -format 2.启动主节点和数据节点NameNode：存储的是数据的元数据，例如文件名称，路径，大小等信息。 DataNode：存储的是数据。 [liqiang@Gargantua hadoop]$ sbin/start-dfs.sh Starting namenodes on [Gargantua] Starting datanodes localhost: Warning: Permanently added &#39;localhost&#39; (ECDSA) to the list of known hosts. Starting secondary namenodes [Gargantua] 【启动成功之后，使用jps查看 、 或 ps -ef|grep hadoop】 [liqiang@Gargantua hadoop]$ jps 5425 SecondaryNameNode 5205 DataNode 5558 Jps 5087 NameNode web端访问：外网IP:9870hadoop2.x hdfs web界面 默认端口号是 50070hadoop3.x 默认端口号 9870 操作 hdfs [liqiang@Gargantua hadoop]$ pwd&#x2F;home&#x2F;liqiang&#x2F;app&#x2F;hadoop [liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -mkdir &#x2F;user[liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -ls &#x2F;drwxr-xr-x - liqiang supergroup 0 2021-12-27 22:42 &#x2F;user [liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -mkdir &#x2F;user&#x2F;liqiang[liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -mkdir input 【会默认也在liqiang目录下创建input】 [liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -ls &#x2F;user&#x2F;liqiangdrwxr-xr-x - liqiang supergroup 0 2021-12-27 22:45 &#x2F;user&#x2F;liqiang&#x2F;input 再次确认一下需要复制过去的xml文件权限 [liqiang@Gargantua hadoop]$ ll etc&#x2F;hadoop&#x2F;*.xml -rw-r--r-- 1 liqiang liqiang 9213 Jan 3 2021 etc/hadoop/capacity-scheduler.xml -rw-r--r-- 1 liqiang liqiang 884 Dec 27 22:17 etc/hadoop/core-site.xml -rw-r--r-- 1 liqiang liqiang 11392 Jan 3 2021 etc/hadoop/hadoop-policy.xml -rw-r--r-- 1 liqiang liqiang 867 Dec 27 22:24 etc/hadoop/hdfs-site.xml -rw-r--r-- 1 liqiang liqiang 620 Jan 3 2021 etc/hadoop/httpfs-site.xml -rw-r--r-- 1 liqiang liqiang 3518 Jan 3 2021 etc/hadoop/kms-acls.xml -rw-r--r-- 1 liqiang liqiang 682 Jan 3 2021 etc/hadoop/kms-site.xml -rw-r--r-- 1 liqiang liqiang 758 Jan 3 2021 etc/hadoop/mapred-site.xml -rw-r--r-- 1 liqiang liqiang 690 Jan 3 2021 etc/hadoop/yarn-site.xml 复制到hdfs [liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -put etc&#x2F;hadoop&#x2F;*.xml input[liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -ls &#x2F;user&#x2F;liqiang&#x2F;input&#x2F; 【查看input中文件】 Run some of the examples provided:尝试运行一个计算实例 bin&#x2F;hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.2.2.jar grep input output ‘dfs[a-z.]+’ 将hdfs中output的内容下载查看or 直接cat查看 [liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -get output output[liqiang@Gargantua hadoop]$ cat output&#x2F;*1 dfsadmin1 dfs.replication [liqiang@Gargantua hadoop]$ bin&#x2F;hdfs dfs -cat output&#x2F;*1 dfsadmin1 dfs.replication 启动Yern准备hadoop的配置文件都在 $HADOOP_HOME&#x2F;etc目录下： [liqiang@Gargantua hadoop]$ pwd /home/liqiang/app/hadoop/etc/hadoop [liqiang@Gargantua hadoop]$ vi core-site.xml [liqiang@Gargantua hadoop]$ vi hdfs-site.xml [liqiang@Gargantua hadoop]$ vi mapred-site.xml [liqiang@Gargantua hadoop]$ vi yarn-site.xml mapred-site.xml123456789101112&lt;configuration&gt; &lt;!--配置mr作业的计算框架--&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!--配置mr运行application的classpath目录--&gt; &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml1234567891011121314151617&lt;configuration&gt; &lt;!--NodeManager上运行的附属服务--&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!--环境变量白名单--&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt; &lt;!--yarn作业web界面，如果不配置，则采用yarn的8088端口极容易遭到8088挖矿，记得改端口--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;Gargantua:8088&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动yarn [liqiang@Gargantua hadoop]$ pwd /home/liqiang/app/hadoop [liqiang@Gargantua hadoop]$ sbin/start-yarn.sh web端访问：外网ip:8088&#x2F;cluster(8088已改8123) wordcount案例环境变量 [liqiang@Gargantua ~]$ vi .bashrc export HADOOP_HOME=/home/liqiang/app/hadoop export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH [liqiang@Gargantua ~]$ . .bashrc[liqiang@Gargantua ~]$ which hadoop~&#x2F;app&#x2F;hadoop&#x2F;bin&#x2F;hadoop 准备一个文件并上传到hdfs [liqiang@Gargantua ~]$ vi wc.log jepson ruoze xingxing a b c b a c jepson gargantua a b c [liqiang@Gargantua ~]$ hdfs dfs -mkdir &#x2F;input[liqiang@Gargantua ~]$ hdfs dfs -put wc.log &#x2F;input[liqiang@Gargantua ~]$ hdfs dfs -cat &#x2F;input&#x2F;wc.log 找到官方案例jar包 [liqiang@Gargantua ~]$ find .&#x2F; -name ‘*example*‘ ./app/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar 尝试找到命令运行此jar包[liqiang@Gargantua ~]$ hadoop –help jar &lt;jar&gt; run a jar file. NOTE: please use &quot;yarn jar&quot; to launch YARN applications, not this command. [liqiang@Gargantua ~]$ yarn jar .&#x2F;app&#x2F;hadoop-3.2.2&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.2.2.jar 【# RunJar jarFile [mainClass] args... 还需要写出这个jar的主类main】 An example program must be given as the first argument. Valid program names are: aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files. aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files. bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi. dbcount: An example job that count the pageview counts from a database. distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi. grep: A map/reduce program that counts the matches of a regex in the input. join: A job that effects a join over sorted, equally partitioned datasets multifilewc: A job that counts words from several files. pentomino: A map/reduce tile laying program to find solutions to pentomino problems. pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method. randomtextwriter: A map/reduce program that writes 10GB of random textual data per node. randomwriter: A map/reduce program that writes 10GB of random data per node. secondarysort: An example defining a secondary sort to the reduce. sort: A map/reduce program that sorts the data written by the random writer. sudoku: A sudoku solver. teragen: Generate data for the terasort terasort: Run the terasort teravalidate: Checking results of terasort wordcount: A map/reduce program that counts the words in the input files. wordmean: A map/reduce program that counts the average length of the words in the input files. wordmedian: A map/reduce program that counts the median length of the words in the input files. wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files. 运行jarwordcount &#x2F;input &#x2F;output ：指定主类 wc 和输入&#x2F;输出目录 [liqiang@Gargantua ~]$ yarn jar .&#x2F;app&#x2F;hadoop-3.2.2&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.2.2.jar wordcount &#x2F;input &#x2F;output 正常来说，接下来就会执行作业。 2021-11-26 22:43:01,129 INFO mapreduce.JobSubmitter: number of splits:1 【切片是1 规则 】 // ... File System Counters Job Counters Launched map tasks=1 【map 任务 1】 Launched reduce tasks=1 【reduce 任务 1】 Map-Reduce Framework // ... Shuffle Errors // ... 查看wc结果 [liqiang@Gargantua ~]$ hdfs dfs -cat &#x2F;output&#x2F;part-r-00000 a 3 b 3 c 3 gargantua 1 jepson 2 ruoze 2 xingxing 1 如果遇到&#x2F;bin&#x2F;bash: &#x2F;bin&#x2F;java: No such file or directory尝试建立一个软连接指向我们到JAVA_HOME（mysql时有个【mysql.sock】也是这样临时解决）ln -s &#x2F;usr&#x2F;java&#x2F;jdk1.8.0_121&#x2F;bin&#x2F;java &#x2F;bin&#x2F;java 一般是有些bug ，该读javahome的时候没有去读取系统环境变量，所以找不到java；或者某些默认配置还在&#x2F;tmp下，而不久被系统删掉所以找不到。","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hadoop","slug":"大数据/Hadoop","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}]},{"title":"Hive内置函数&自定义UDF函数","slug":"Hive内置函数与自定义UDF函数","date":"2024-09-17T03:30:05.000Z","updated":"2024-09-17T04:12:51.178Z","comments":true,"path":"2024/09/17/Hive内置函数与自定义UDF函数/","permalink":"http://example.com/2024/09/17/Hive%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%E4%B8%8E%E8%87%AA%E5%AE%9A%E4%B9%89UDF%E5%87%BD%E6%95%B0/","excerpt":"","text":"Build-in 内置函数官网 https://cwiki.apache.org/confluence/display/Hive/Home DML&#x2F;Operators and UDFs 一些常用内置UDF、UDAF函数 https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF UDTF函数，行列转换collect_list:配合group by 将多行数据收集为一个数组concat_ws 将多个拼接为一个split 将一个拆分成多个explode 栅列 函数 # name # course PK MapReduce,Hive,Spark,Flink J Hadoop,HBase,Kafka // 将以上数据，处理为： PK MapReduce PK Hive PK Spark PK Flink J Hadoop J HBase J Kafka 使用 explode + split，将course列拆分后转成多行 select name, c from teacher_course lateral view explode(split(course,&#39;,&#39;)) tmp as c; 自定义函数 UDF 一进一出。 如：upper lower substr UDAF 多进一出 。 如：sum ….. UDTF 一进多出。 如：explode 准备函数体并打jar包 创建maven工程导入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.hive&lt;/groupId&gt; &lt;artifactId&gt;hive-exec&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt;&lt;/dependency&gt; 创建 自定义UDF类继承自 UDF 12345678910111213// 自定义一个 add_random()函数，在传入的参数后增加一个随机整数public class AddRandomUDF extends org.apache.hadoop.hive.ql.exec.UDF &#123; static Random random = new Random(); // 方法名必须是evaluate，打包后hive会设别和执行 public String evaluate(String str)&#123; if (str == null)&#123; return null; &#125; str += random.nextInt(10); return str; &#125;&#125; maven package 打jar包到当前工程target下，上传此jar包至linux ~/lib/hive_demo-1.0-SNAPSHOT.jar 在hive中创建函数方式一：临时函数 add jar启动hive，并add jar [liqiang@Gargantua bin]$ hive hive &gt; add jar /home/liqiang/lib/hive_demo-1.0-SNAPSHOT.jar; 创建临时函数：【作用当前会话】 hive &gt; CREATE TEMPORARY FUNCTION add_random AS &quot;com.gargantua.udf.AddRandomUDF&quot;; 现在可以在当前会话中同使用内置函数一样使用 add_random() hive &gt; select add_random(&#39;123&#39;) from my_table; 此方式需要在使用前 add jar 并 CREATE FUNCTION。可以将这两步命令写在文件中，启动hive同时指定初始化这个文件 [liqiang@Gargantua bin]$ hive -i [这个文件] 方式二：临时函数 auxlib&#x2F;xxx.jar ${HIVE_HOME}&#x2F;auxlib目录下的jar会自动被hive关联，于是可以省掉 add jar这一步。 创建 auxlib 目录，并复制一份jar到 auxlib&#x2F; 启动hive，并创建函数 【作用当前会话】 hive &gt; CREATE TEMPORARY FUNCTION add_random AS &quot;com.gargantua.udf.AddRandomUDF&quot;; 方式三：持久函数参考： CREATE FUNCTION [db_name.]function_name AS class_name [USING JAR|FILE|ARCHIVE &#39;file_uri&#39; [, JAR|FILE|ARCHIVE &#39;file_uri&#39;] ]; jar 包不能存在本地了。需要上传hdfs。 [liqiang@Gargantua data]$ hdfs dfs -put ~/lib/hive_demo-1.0-SNAPSHOT.jar /lib/ 创建持久函数。 【作用所有会话】 hive &gt; CREATE FUNCTION add_random AS &quot;com.gargantua.udf.AddRandomUDF&quot; &gt; USING JAR &quot;hdfs://gargantua:9000/lib/hive_demo-1.0-SNAPSHOT.jar&quot;; 方式四：IDEA导入Hive源码编译并创建UDF参考下一篇：https://blog.csdn.net/qq_45494908/article/details/122379634","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"大数据/Hive","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/"}],"tags":[]},{"title":"IDEA导入Hive源码编译并创建自定义UDF函数","slug":"IDEA导入Hive源码编译并创建自定义UDF函数","date":"2024-09-17T03:24:33.000Z","updated":"2024-09-17T03:59:08.090Z","comments":true,"path":"2024/09/17/IDEA导入Hive源码编译并创建自定义UDF函数/","permalink":"http://example.com/2024/09/17/IDEA%E5%AF%BC%E5%85%A5Hive%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%B9%B6%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89UDF%E5%87%BD%E6%95%B0/","excerpt":"","text":"下载源码包下载安装包对应的源码包。本次使用 apache-hive-3.1.2-src.tar.gz 。 编译解压在当前目录后进入，打开命令行窗口，执行： 1mvn clean compile -Phadoop-2 -DskipTests 报错： java.io.IOException: Cannot run program &quot;bash&quot; (in directory &quot;D:\\xxx\\apache-hive-3.1.2-src\\common&quot;): CreateProcess error=2, 系统找不到指定的文件。 这是因为在Windows环境不能执行bash。那么需要能执行bash环境，有一个神器：Git安装git后，打开Git Bash，即可在Windows系统中执行Linux命令了！在源码包目录下 Git Bash Here，在git窗口中重新执行 1mvn clean compile -Phadoop-2 -DskipTests Two thousand years later…… 使用IDEA打开1.修改pom.xml文件经过maven编译后，理论上需要用到的依赖都已经下载，但是IDEA打开后，仍然有少部分失败。如 提示找不到在org.apache.directory.server依赖中找不到 org.apache.directory.client.ldap:ldap-client-api:0.1-SNAPSNOT 1Could not find artifact org.apache.directory.client.ldap:ldap-client-api:pom:0.1-SNAPSHOT in alimaven 而hive-service模块pom.xml中已存在： 123456&lt;dependency&gt; &lt;groupId&gt;org.apache.directory.client.ldap&lt;/groupId&gt; &lt;artifactId&gt;ldap-client-api&lt;/artifactId&gt; &lt;version&gt;$&#123;apache-directory-clientapi.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 查看maven仓库中这个jar也存在。可以大胆的将org.apache.directory.server中找不到依赖的包排除掉： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.apache.directory.server&lt;/groupId&gt; &lt;artifactId&gt;apacheds-server-integ&lt;/artifactId&gt; &lt;version&gt;$&#123;apache-directory-server.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.directory.client.ldap&lt;/groupId&gt; &lt;artifactId&gt;ldap-client-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 同样，还有部分依赖是因为指定scope为test而导致。将 &lt;scope&gt;test&lt;&#x2F;scope&gt; 注释即可。 可以参考：https://www.cnblogs.com/huangguoming/p/15779441.html 2.BuildBuild前设置一下heap内存，默认的700M在Build过程中容易OOM。 3.创建UDF函数并注册在ql模块，org.apache.hadoop.hive.ql.udf 包下创建UDF类，注意packge在org.apache.hadoop.hive.ql.exec.FunctionRegistry中注册刚才创建的 AddRandomUDF此时。已经可以将这份源码包重新打包，同样在 Git Bash 中打包 mvn clean package -Phadoop-2 -DskipTests 打包后上传至服务器重新部署hive，或替换jar的方式，生效自定义UDF函数就能使用。不做演示。加下来演示的是，在IDEA中启动Hive，并验证创建的函数。 4.添加配置文件在cli中创建resousces目录，mark为Resources，并放入相关配置文件core-site.xmlhive-site.xmlhive-site.xml配置文件从hive云主机拷贝一份过来即可忘了放入core-site.xml，则找不到hadoop相关配置会报错： org.apache.hadoop.io.nativeio.NativeIO$POSIX.stat(Ljava/lang/String;)Lorg/apache/hadoop/io/nativeio/NativeIO$POSIX$Stat 注意 hive-site.xml 要额外加上 hive.metastore.uris 和 datanucleus.schema.autocreateall 12345678910111213&lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://ip:9083&lt;/value&gt; &lt;!-- 配置hive 中metastore启动ip和端口--&gt;&lt;/property&gt; &lt;property&gt; &lt;name&gt;datanucleus.schema.autocreateall&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.metastore.local&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 5.云主机上hive保持meatastore启动监听hive --service metastore -p 9083 &amp; 6.添加VM参数-Djline.WindowsTerminal.directConsole&#x3D;false 7.启动找到 CliDriver 这个类并启动。验证创建的addrandom函数。 如果遇到报错 &#x2F;tmp 权限不足hdfs dfs -chmod 755 &#x2F;tmp","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"大数据/Hive","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/"}],"tags":[]},{"title":"Hive搭建记录","slug":"Hive搭建记录","date":"2024-09-17T03:12:35.000Z","updated":"2024-09-17T04:12:58.428Z","comments":true,"path":"2024/09/17/Hive搭建记录/","permalink":"http://example.com/2024/09/17/Hive%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/","excerpt":"","text":"Hive搭建记录默认会将 hive 数据文件 放在hdfs “&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;“ 下即 1hdfs://Gargantua:9000/user/hive/warehouse 1[liqiang@Gargantua ~]$ hdfs dfs -ls /user/hive/warehouse 安装下载、上传、解压环境变量 vi ~&#x2F;.bashrcvi ~&#x2F;app&#x2F;hive&#x2F;conf&#x2F;hive-env.sh 【HADOOP_HOME已有环境变量，可不用再在hive-env.sh 设置】 整合MySQLhive-site.xmlhive不提供，需要自己在 conf&#x2F;下添加，url、driver、user、password [liqiang@Gargantua conf]$ pwd /home/liqiang/app/hive/conf [liqiang@Gargantua conf]$ vi hive-site.xml 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=&quot;1.0&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://ip:3306/my_hive?createDatabaseIfNotExist=true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;账号&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;密码&lt;/value&gt; &lt;/property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;hive.cli.print.header&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.cli.print.current.db&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; mysql-connector-java-5.1.49.jar【hive不提供，可以在自己maven仓库里上传至 ~app&#x2F;hive&#x2F;lib&#x2F;】 初始化数据库到MySQL固定写法：.&#x2F;schematool -dbType mysql -initSchema如没做这一步init操作，不会在mysql中初始化表；Hive将元数据保存在MySQL [liqiang@Gargantua bin]$ ./schematool -dbType mysql -initSchema 报错：com.google.common.base.Preconditions.checkArgument(ZLjava&#x2F;lang&#x2F;String;Ljava&#x2F;lang&#x2F;Object;) [liqiang@Gargantua bin]$ hive which: no hbase in (/home/liqiang/app/hive/bin:/home/liqiang/app/hadoop/bin:/home/liqiang/app/hadoop/sbin:/usr/java/jdk1.8.0_121/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/liqiang/.local/bin:/home/liqiang/bin) SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/home/liqiang/app/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/home/liqiang/app/hadoop-3.2.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory] Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357) // ... at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:323) at org.apache.hadoop.util.RunJar.main(RunJar.java:236) 参考：https://www.cnblogs.com/syq816/p/12632028.html 解决。即把hadoop(hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib) 下的 guava-27.0-jre.jar 复制到hive&#x2F;lib，保持jar版本一致 [hadoop@localhost lib]$ pwd /home/hadoop/app/hive/lib [hadoop@localhost lib]$ cp ~/app/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar ./ # 重新执行初始化数据库 [liqiang@Gargantua bin]$ ./schematool -dbType mysql -initSchema hive 启动 [liqiang@Gargantua ~]$ cd ~&#x2F;app&#x2F;hive&#x2F;bin [liqiang@Gargantua bin]$ hive 成功启动，进入Hive。 关闭Hive hive&gt; quit; hiveserver2 启动前端启动 hiveserver2 【ssh终端关闭后服务就会停止】 [liqiang@Gargantua bin]$ ./hiveserver2 or [liqiang@Gargantua bin]$ hive --service hiveserver2 后端启动 hiveserver2 [liqiang@Gargantua bin]$ nohub sh hiveserver2 &amp; nohup ： 不挂断的运行，免疫session的SIGHUP信号。 no hang up（不挂断） 的缩写&amp; ：在后台运行，免疫（Ctrl + C）SIGINT信号。 hiveserver2 启动后，可以使用 beeline 联接 [liqiang@Gargantua bin]$ ./beeline beeline&gt; !connect jdbc:hive2://localhost:10000 liqiang Connecting to jdbc:hive2://localhost:10000 Enter password for jdbc:hive2://localhost:10000: 然后报错。。 21/12/31 00:43:00 [main]: WARN jdbc.HiveConnection: Failed to connect to localhost:10000 Error: Could not open client transport with JDBC Uri: jdbc:hive2://localhost:10000: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: liqiang is not allowed to impersonate hadoop (state=08S01,code=0) beeline&gt; beeline&gt; !quit; 回头检查hadoop的core-site.xml 12345678910&lt;!-- 增加以下设置,下面 beeline的账号为什么，这是的账号就是什么 --&gt;&lt;!-- hadoop.proxyuser.账号.hosts --&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.liqiang.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;!-- hadoop.proxyuser.账号.groups --&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.liqiang.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; 重启 hadoop #进入 hadoop/sbin $ ./stop-all.sh $ ./start-all.sh 重启 hiveserver2 ./hiveserver2 查看数据库在 hive hive&gt; show databases; OK default Time taken: 0.551 seconds, Fetched: 1 row(s) hive&gt; hive有一个默认数据库default，创建表，列出所有表： hive&gt; use default; hive&gt; create table my_table(id string); hive&gt; show tables; OK my_table Time taken: 0.027 seconds, Fetched: 1 row(s) hive&gt; 在 hiveserver2 下 0: jdbc:hive2://localhost:10000&gt; show databases; +----------------+ | database_name | +----------------+ | default | +----------------+ Hive数据hive数据： 默认会将 hive 数据存放在 hdfs目录 “&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;“： hdfs:&#x2F;&#x2F;Gargantua:9000&#x2F;user&#x2F;hive&#x2F;warehouse 元数据存放在MySQL TBLS:表 DBS：库 COLUMNS_V2:表的相关字段信息 数据[liqiang@Gargantua ~]$ hdfs dfs -ls /user/hive/warehouse 元数据进入MySQL查看my_hive数据库： mysql&gt; use my_hive mysql&gt; show tables; +-------------------------------+ | Tables_in_my_hive | +-------------------------------+ | aux_table | | bucketing_cols | | cds | | columns_v2 | 【COLUMNS_V2:表的相关字段信息】 | compaction_queue | | completed_compactions | | completed_txn_components | | ctlgs | | database_params | | db_privs | | dbs | 【DBS：库】 | delegation_tokens | | func_ru | | funcs | | global_privs | | hive_locks | | i_schema | | idxs | | index_params | | key_constraints | | master_keys | | materialization_rebuild_locks | | metastore_db_properties | | min_history_level | | mv_creation_metadata | | mv_tables_used | | next_compaction_queue_id | | next_lock_id | | next_txn_id | | next_write_id | | notification_log | | notification_sequence | | nucleus_tables | | part_col_privs | | part_col_stats | | part_privs | | partition_events | | partition_key_vals | | partition_keys | | partition_params | | partitions | | repl_txn_map | | role_map | | roles | | runtime_stats | | schema_version | | sd_params | | sds | | sequence_table | | serde_params | | serdes | | skewed_col_names | | skewed_col_value_loc_map | | skewed_string_list | | skewed_string_list_values | | skewed_values | | sort_cols | | tab_col_stats | | table_params | | tbl_col_privs | | tbl_privs | | tbls | 【TBLS:表】 | txn_components | | txn_to_write_id | | txns | | type_fields | | types | | version | | wm_mapping | | wm_pool | | wm_pool_to_trigger | | wm_resourceplan | | wm_trigger | | write_set | +-------------------------------+ 查看刚才在 hive 中创建的表 mysql&gt; select * from tbls where tbl_name = &#39;my_table&#39;; +--------+-------------+-------+------------------+---------+------------+-----------+-------+----------+---------------+--------------------+--------------------+--------------------+ | TBL_ID | CREATE_TIME | DB_ID | LAST_ACCESS_TIME | OWNER | OWNER_TYPE | RETENTION | SD_ID | TBL_NAME | TBL_TYPE | VIEW_EXPANDED_TEXT | VIEW_ORIGINAL_TEXT | IS_REWRITE_ENABLED | +--------+-------------+-------+------------------+---------+------------+-----------+-------+----------+---------------+--------------------+--------------------+--------------------+ | 1 | 1640862757 | 1 | 0 | liqiang | USER | 0 | 1 | my_table | MANAGED_TABLE | NULL | NULL | | +--------+-------------+-------+------------------+---------+------------+-----------+-------+----------+---------------+--------------------+--------------------+--------------------+ 1 row in set (0.00 sec) TBL_ID：表IDDB_ID：数据库ID 因此查看 my_table 这张表对应的库的信息： mysql&gt; select * from dbs where db_id = 1; mysql&gt; select * from dbs where db_id = (select db_id from tbls where tbl_name = &#39;my_table&#39;); 查看 my_table 这张表对应的表字段的信息： mysql&gt; select * from columns_v2; 【列中并没有关联这些column来自哪个表..没有TBL_ID这样的】 +-------+---------+-------------+-----------+-------------+ | CD_ID | COMMENT | COLUMN_NAME | TYPE_NAME | INTEGER_IDX | +-------+---------+-------------+-----------+-------------+ | 1 | NULL | id | string | 0 | +-------+---------+-------------+-----------+-------------+ 只有一个 CD_ID，而 tabls 中也只有 一个 SD_ID 不是关联的 而cds 表只有个cd_id，也没关联 tbl_id mysql&gt; select * from cds; +-------+ | CD_ID | +-------+ | 1 | +-------+ 接着在sds 表中： mysql&gt; select * from sds; +-------+-------+------------------------------------------+---------------+---------------------------+----------------------------------------------------+-------------+------------------------------------------------------------+----------+ | SD_ID | CD_ID | INPUT_FORMAT | IS_COMPRESSED | IS_STOREDASSUBDIRECTORIES | LOCATION | NUM_BUCKETS | OUTPUT_FORMAT | SERDE_ID | +-------+-------+------------------------------------------+---------------+---------------------------+----------------------------------------------------+-------------+------------------------------------------------------------+----------+ | 1 | 1 | org.apache.hadoop.mapred.TextInputFormat | | | hdfs://Gargantua:9000/user/hive/warehouse/my_table | -1 | org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat | 1 | +-------+-------+------------------------------------------+---------------+---------------------------+----------------------------------------------------+-------------+------------------------------------------------------------+----------+ 1 row in set (0.00 sec) 好像关联上了。 mysql&gt; select * from columns_v2 where cd_id = ( -&gt; select sds.cd_id from sds join tbls on sds.sd_id = tbls.sd_id where tbls.tbl_name = &#39;my_table&#39; -&gt; ); +-------+---------+-------------+-----------+-------------+ | CD_ID | COMMENT | COLUMN_NAME | TYPE_NAME | INTEGER_IDX | +-------+---------+-------------+-----------+-------------+ | 1 | NULL | id | string | 0 | +-------+---------+-------------+-----------+-------------+ 1 row in set (0.00 sec) Hive设置属性配置文件是全局的，但是需要重启Hive后生效。如 hive-site.xml 中加上： 123456789&lt;property&gt; &lt;name&gt;hive.cli.print.header&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.cli.print.current.db&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; hive 命令带参数启动 [liqiang@Gargantua bin]$ hive --hive.cli.print.current.db=ture 临时的，只作用于当前会话。 set查看参数 set hive.cli.print.current.db; 修改参数 set hive.cli.print.current.db=true; 临时的，只作用于当前会话。 hive 命令其他参数hive -e sql语句 【可以在hive外执行sql】 hive -e “select * from my_table”; hive -f sql文件hive -i","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"大数据/Hive","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"类加载与双亲委派机制","slug":"类加载与双亲委派机制","date":"2024-09-16T04:30:00.000Z","updated":"2024-09-17T13:55:43.093Z","comments":true,"path":"2024/09/16/类加载与双亲委派机制/","permalink":"http://example.com/2024/09/16/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E4%B8%8E%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/","excerpt":"","text":"学习参考并自行总结自：https://www.jianshu.com/p/dd39654231e0https://blog.csdn.net/every__day/article/details/125361048https://blog.csdn.net/u011490072/article/details/81560295 类加载过程 加载：将class字节码文件加载到内存中，并将这些数据转换成方法区中的运行时数据（静态变量、静态代码块、常量池等），在堆中生成一个Class类对象代表这个类（反射原理），作为方法区类数据的访问入口。 连接 a. 验证：验证字节码文件 b. 准备：为静态类变量分配内存(方法区) 和 赋予默认值(有final修饰则直接赋初始值)。 c. 解析：符号引用替换为内存中直接引用(理解为划分一个栈内存空间给这个对象名) 初始化：为对象在堆内存中创建实例，同时为类变量赋初始值。（只有真正使用类时才触发初始化） 注意，加载、连接后并不马上初始化。只有主动引用时（真正使用类）才会触发： new一个类的对象。 调用类的静态成员(除了final常量)和静态方法。（final常量在编译阶段就存入调用类的常量池中了) 启动main方法所在的类。 使用java.lang.reflect包的方法对类进行反射调用。 当初始化一个类，如果其父类没有被初始化，则先会触发父类的初始化。(通过子类引用父类的静态变量，不会导致子类初始化。) 而被动引用不会引起初始化： 调用类的 final 常量。final常量在编译阶段就存入调用类的常量池中了。 当访问一个静态域时，只有真正声明这个域的类才会被初始化。例如：通过子类引用父类的静态变量，不会导致子类初始化。 通过数组定义类引用，不会触发此类的初始化。 例如：People[] people &#x3D; new People[10]; 并不是 new People() 所以不会初始化People。 初始化顺序父类和子类一起加载、连接。此时父类的静态类变量和静态代码块执行(类级别的内容)。但并不立刻初始化。当new子类时，发现父类没有初始化，则初始化父类。父类初始化则执行父类构造方法和非静态代码块。然后才是子类构造方法和非静态代码块。 12345678910/* * 执行了父类A的静态代码块 // + 父类A的静态变量 --&gt; 类级别的静态内容，在初始化以前就执行了。 * 执行了子类B的静态代码块 // + 子类B的静态变量 * * 执行了父类A的非静态代码块 * 执行了父类A的构造方法 * * 执行了子类B的非静态代码块 * 执行了子类B的构造方法 * */ 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * @ClassName Demo01 * @Description 测试程序初始化顺序 */public class Demo01 &#123; public static void main(String[] args) &#123; B b = new B(); &#125;&#125;class A&#123; static String str1 = &quot;父类A的静态变量&quot;; String str2 = &quot;父类A的非静态变量&quot;; static &#123; System.out.println(&quot;执行了父类A的静态代码块&quot;); &#125; &#123; System.out.println(&quot;执行了父类A的非静态代码块&quot;); &#125; public A()&#123; System.out.println(&quot;执行了父类A的构造方法&quot;); &#125;&#125;class B extends A&#123; static String str1 = &quot;子类B的静态变量&quot;; String str2 = &quot;子类B的非静态变量&quot;; static &#123; System.out.println(&quot;执行了子类B的静态代码块&quot;); &#125; &#123; System.out.println(&quot;执行了子类B的非静态代码块&quot;); &#125; public B()&#123; System.out.println(&quot;执行了子类B的构造方法&quot;); &#125;&#125; 结合类加载过程，双重校验锁为何使用volatile单例模式之 doubleCheck： 1234567891011121314151617181920public class LazySingleton &#123; private LazySingleton() &#123; // 将构造函数私有化，外界不能new LazySingleton 创建，保证单例 &#125; private volatile static LazySingleton lazySingleton; // new LazySingleton() 并不是原子操作，需要volatile禁止重排序 public static LazySingleton getInstance()&#123; if (lazySingleton == null)&#123; synchronized (LazySingleton.class)&#123; if (lazySingleton == null)&#123; lazySingleton = new LazySingleton(); &#125; &#125; &#125; return lazySingleton; &#125;&#125; 当第一次调用 LazySingleton.getInstance() 静态方法，才会触发类加载的初始化。 – 懒汉模式。new LazySingleton()，底层也有分步骤的加载过程 new 创建对象步骤：堆分配空间 –&gt; 在堆中创建实例 –&gt; 堆空间的引用赋值给变量 后两步依无相互依赖，可能发生指令重排： 堆分配空间 –&gt; 堆空间的引用赋值给变量（并没有创建实例） 。恰巧此时线程切换，当另一个线程经过if (lazySingleton &#x3D;&#x3D; null) 发现对象已经赋值了引用地址，判断为对象已经创建，便 return lazySingleton。空的 lazySingleton 会引发空指针异常。 结合类加载过程，静态内部类如何保证单例123456789101112131415public class LazySingleton &#123; private LazySingleton() &#123; // 将构造函数私有化，外界不能new LazySingleton 创建，保证单例 &#125; public static LazySingleton getInstance()&#123; return InnerSingleton.instance; &#125; private static class InnerSingleton &#123; private static LazySingleton instance = new LazySingleton(); // 内部类中的 instance 只能被外部类调用，不能被外部类以外其他类调用。保证入口只有 LazySingleton.getInstance() &#125;&#125; 外部类和内部类一样，经过加载、连接后并不立刻初始化。（此时内部类的instance 只会赋默认值null） 只有当调用外部类：LazySingleton.getInstance() 并返回调用 内部类 静态instance属性时，触发内部类初始化，为instance 类变量赋初始值。这个初始值就是 new LazySingleton(); 为instance 类变量赋初始值这个过程只会发生一次，且由JVM保证这个过程是单线程的。new LazySingleton() 的过程也是instance 赋初始值的过程，而赋初始值的过程是单线程的，就保证了new 对象期间不会发生doubleCheck中那样线程上下文切换。 静态内部类的方式也实现了单例模式的懒加载，但是静态内部类有一个缺点，需要在被保证单例的资源类中编写内部类，且不便传参。所以doubleCheck 仍然是最常用的，如线程池单例模式。 参考：https://blog.csdn.net/mnb65482/article/details/80458571 类加载原理类加载器的职责: 通过类的全限定名获取类的二进制字节流，并将这些字节流数据转换成方法区中的运行时数据（静态变量、静态代码块、常量池等），然后在堆中生成一个个Class对象代表这个类（反射原理），作为方法区类数据的访问入口。 类加载器ClassLoaderClassLoader 有两个子类 ExtClassLoader 和 AppClassLoader （又都是Launcher的内部类）。而 BootstrapClassLoader 是内嵌的，C++ 实现的。 ClassLoader 中有一个成员对象 ClassLoader parent； Launcher构造时，就会分别创建ExtClassLoader 和 AppClassLoader ，并把ExtClassLoader 设置为 AppClassLoader 的parent。实现了将 ExtClassLoader 和 AppClassLoader 链的方式构建。 这三个类加载器，加载的类包是不同的： 启动类加载器 Bootrap ClassLoader : 加载 jre&#x2F; 目录下的核心库 扩展类加载器 Extension ClassLoader(Platform 在jdk1.9) : 加载 &#x2F;jre&#x2F;lib&#x2F;ext&#x2F; 目录下的扩展包 应用程序类加载器 Application ClassLoader : 加载 ClassPath 路径下的包 [ target&#x2F;classes&#x2F;jar、依赖的maven仓库jar] 不同的加载器之间没有继承关系，但都继承自URLClassLoader 。 我们自己也创建一个java.lang.String编译不会报错，但是无法运行，原因就是的类加载器里做了保护限制，防止核心内库被随意篡改。 双亲委派机制： JAVA 类加载，鼎鼎有名的 “双亲委派机制”，说起来呢，就是一个简单的 递归调用。通过最多两次递归方式，找到类的 class 文件，并放到虚拟机。 “双亲” 姑且理解为递归的两层嵌套吧。（parent.loadClass()递归两次，这种翻译叫做：忠实于原文） 效果是，优先让启动类执行加载，无法加载的内容再让扩展类加载，再让应用程序加载，再让自定义加载。 源码详解类加载器执行过程：类加载时，最先使用 AppClassLoader 调用 loadClass ，如果一个类没有被加载过（即findLoadedClass(name)为空），会被递归两次: 对AppClassLoader.loadClass()而言，如果 findLoadedClass(name) 为空，则交给parent.loadClass(name)，AppClassLoader的parent是 ExtClassLoader 对ExtClassLoader.loadClass()而言， 如果 findLoadedClass(name) 为空，则再交给parent，但parent也为空，所以交给 BootstrapClassLoader 由于是递归调用，那么执行上来说顺序就是： 交给 BootstrapClassLoader先加载试试，可以加载就加载并返回这个Class；不能被加载则返回null，继续交给 ExtClassLoader。 ExtClassLoader 加载试试，findClass(name)可以加载加载并返回这个Class；不能被加载则返回null，继续交给 AppClassLoader。 AppClassLoader 加载试试，findClass(name)可以加载就加载并结束；不能被加载就返回null。 源码： 12345678910111213141516171819202122232425262728protected Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; &#125; if (c == null) &#123; c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 从源码解读 双亲委派机制的作用： findLoadedClass(name)，先查找这个类有没有被加载过，没有被加载才加载，保证了虚拟机里相同全限定名只有一个类。 对于如果自行创建java.lang.String，首先都会让先加载试试，而BootstrapClassLoader会加载 jre&#x2F; 目录下的核心库。 也就是说，BootstrapClassLoader 拿着java.lang.String这个名字，只会去加载到核心库里的java.lang.String。 而 经过ExtClassLoader 和 AppClassLoader加载时，发现java.lang.String已经被加载过，便直接返回。 于是结果为自行创建java.lang.String时无法被加载的，这也保证了java核心内库不能被轻易篡改的。 总结：确保相同名称类只会被加载一次，进而确保Java核心内库不被篡改。即用户创建的与内置类同全限定名的类，是无法通过启动类加载器加载的，这样保证了核心内库的全局唯一。 为什么要自定义类加载器：举例： 场景1：项目中有需要同时依赖两个不同版本的jar包，而双亲委派只能对一个类加载一次。 场景2：类加密以及热更新 场景3：从数据库、网络数据源处加载，而非ClassPath下的 创建自定义加载器：使用自定义类加载器是要去加载一些不能被java自带ClassLoader加载的类，但项目的运行脱离不了java核心内库、依赖、其他应用类，所以自定义加载器也依旧要保证该双亲委派模型，所以一般不覆盖loadClass函数。 ExtClassLoader 和 AppClassLoader 其实都是使用findClass(name)加载，所以自定义类加载器重点也是覆写findClass(name)这个方法，从指定的地方获取字节码文件byte[]。 总结：继承 ClassLoader, 重写 findClass方法 （findClass不会违背双亲委派机制，而loadClass可以）。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package org.example.classLoader;import java.io.ByteArrayOutputStream;import java.io.FileInputStream;import java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.Channels;import java.nio.channels.FileChannel;import java.nio.channels.WritableByteChannel;public class CustomerClassLoader extends ClassLoader &#123; public static void main(String[] args) throws ClassNotFoundException &#123; // 在桌面有一个User.class，也可以去加载到项目里来 CustomerClassLoader customerClassLoader = new CustomerClassLoader( &quot;C:/Users/L/Desktop&quot;); customerClassLoader.loadClass(&quot;User&quot;); &#125; private String classpath; // 被加载的类字节码文件存放的路径，在构造CustomerClassLoader时指定 public CustomerClassLoader(String classpath) &#123; this.classpath = classpath; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; String fileName = getClassFile(name); byte[] classByte = null; try &#123; classByte = getClassBytes(fileName); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; //利用自身的加载器加载类 Class retClass = defineClass(null, classByte, 0, classByte.length); if (retClass != null) &#123; System.out.println(&quot;由CustomerClassLoader 加载&quot;); return retClass; &#125; //System.out.println(&quot;非我加载&quot;); //在classPath中找不到类文件，委托给父加载器加载,父类会返回null，因为可加载的话在 //委派的过程中就已经被加载了 return super.findClass(name); &#125; /*** * 获取指定类文件的字节数组 * @param name * @return 类文件的字节数组 * @throws IOException */ private byte[] getClassBytes(String name) throws IOException &#123; FileInputStream fileInput = new FileInputStream(name); FileChannel channel = fileInput.getChannel(); ByteArrayOutputStream output = new ByteArrayOutputStream(); WritableByteChannel byteChannel = Channels.newChannel(output); ByteBuffer buffer = ByteBuffer.allocate(1024); try &#123; int flag; while ((flag = channel.read(buffer)) != -1) &#123; if (flag == 0) break; //将buffer写入byteChannel buffer.flip(); byteChannel.write(buffer); buffer.clear(); &#125; &#125; catch (IOException e) &#123; System.out.println(&quot;can&#x27;t read!&quot;); throw e; &#125; fileInput.close(); channel.close(); byteChannel.close(); return output.toByteArray(); &#125; /*** * 获取当前操作系统下的类文件合法路径 * @param name * @return 合法的路径文件名 */ private String getClassFile(String name) &#123; //利用StringBuilder将包形式的类名转化为Unix形式的路径 StringBuilder sb = new StringBuilder(classpath); sb.append(&quot;/&quot;) .append(name.replace(&#x27;.&#x27;, &#x27;/&#x27;)) .append(&quot;.class&quot;); return sb.toString(); &#125;&#125; 使用自定义类加载注意只有两个类型都是由同一个加载器所加载，才能进行类型转换，否则转换时会发生异常。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"类加载","slug":"类加载","permalink":"http://example.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"},{"name":"双亲委派","slug":"双亲委派","permalink":"http://example.com/tags/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE/"}]},{"title":"java IO总结","slug":"java IO总结","date":"2024-09-16T02:50:00.000Z","updated":"2024-09-17T04:14:27.428Z","comments":true,"path":"2024/09/16/java IO总结/","permalink":"http://example.com/2024/09/16/java%20IO%E6%80%BB%E7%BB%93/","excerpt":"","text":"部分参考：https://www.cnblogs.com/oubo/archive/2012/01/06/2394638.html Java IO 学习总结Java流类图结构 Java流操作的相关类或接口 File – 文件类 RandomAccessFile – 随机存储文件类 InputStream – 字节输入流 OutputStream – 字节输出流 Reader – 字符输入流 Writer – 字符输出流 输入流 or 输出流输入 与 输出，是以程序端的角度来看流向，从文件(磁盘)中读取数据到程序就是输入in，将数据从程序写出到文件就是out。 12in &lt;-- readout --&gt; write InputStream 字节输入流但 InputStream 是抽象类，读文件的方法（read）是抽象方法。需要其实现类。 FileInputStreamInputStream 有很多的子类，其中最常用的是文件流FileInputStream了，主要用来读取文件。 12345File file = new File(&quot;MockData.txt&quot;); FileInputStream fis = new FileInputStream(file); // FileInputStream fis = new FileInputStream(&quot;MockData.txt&quot;); 有两个构造器： 12FileInputStream(File file); FileInputStream(String path); 读取的方法： 123int read();int read(byte[] b);int read(byte[] b, int off, int len); int read() 调用一次读到一个数据字节返回的int值就是读到的数据，如果已到达文件末尾，则返回 -1。 12345678FileInputStream fis = new FileInputStream(file);int i;while ((i = fis.read()) != -1)&#123; System.out.println((char)i);&#125;fis.close(); int read(byte[] b) 调用一次本方法表示可以读取多个数据。读到的内容保存传入的byte数组b中。返回的是本次调用方法读到的数据字节个数。 12345678910FileInputStream fis = new FileInputStream(file);byte[] bytes = new byte[1024]; // 长度 决定了每次循环中读取的字节长度。长度越小循环次数越多while (fis.read(bytes) != -1)&#123; String string = new String(bytes); System.out.println(string);&#125; fis.close(); 字节数组是按字节长度来拆分到每一次批次循环的，一个中文是两个数据字节，不能避免一个中文被拆到两个批次中，导致不能识别而间歇性乱码 123听说���文��乱码 需要关闭输入流 1fis.close(); 已关闭的流不能再读取到任何内容。 OutputStream 字节输出流同样 OutputStream 是抽象类，写文件的方法（write）是抽象方法。需要其实现类。 FileOutputStream构造方法: 12345FileOutputStream(File file); FileOutputStream(String name);// append 表示追加(true) or 覆盖(false)，不传时默认false-覆盖FileOutputStream(File file, boolean append); FileOutputStream(String name, boolean append); 方法: 123 void write(int b); // 调用一次写入一个数据字节void write(byte[] b); // 调用一次,可以把一个byte数组中的数据写入 void write(byte[] b, int off, int len); //调用一次,把b数组中的一部分数据写入 FileOutputStream在执行write时，如果文件不存在，会自动创建一个文件(但文件的路径必须存在的) void write(int b)123456FileOutputStream fos = new FileOutputStream(file,true);// 会自动将int 值转为char作为一个字节写入fos.write(66); // 写到文件里的是 B fos.close(); void write(byte[] b)123456FileOutputStream fos = new FileOutputStream(file,true);fos.write(&quot;66&quot;.getBytes()); // 写到文件里的才是 66 fos.close(); getBytes() 时默认编码为”UTF-8” 仍然要需要关闭输出流 InputStream 其他实现类 ObjectInputStream 反序列化，从文件中读取成一个java对象。 1234ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;test.txt&quot;));byte[] read = (byte[]) ois.readObject();String s2 = new String(read); // 再解析成对象 ObjectInputStream 只是装饰器(装饰者模式)，源码中可知只有一个public的构造器，需要借助一个已有的InputStream才能使用，如FileInputStream。 123public ObjectInputStream(InputStream in);protected ObjectInputStream(); ByteArrayInputStream 和 StringBufferInputStream ByteArrayInputStream、StringBufferInputStream、FileInputStream是三种基本的介质流，它们分别从Byte数组、StringBuffer、和本地文件中读取数据。 PipedInputStream PipedInputStream是从与其他线程共用的管道中读取数据。 FilterInputStream FilterInputStream 也是一个装饰器，只能通过构造器 1protected FilterInputStream(InputStream in) 创建对象，且必须通过子类(受protected修饰)： DataInputStream ： 使用InputStream我们只能读取byte，DataInputStream使得我们可以直接从stream中读取java中的int，String等类型。 BufferInputStream： 这个类提供了一个缓存来加速我们从字节输入流的读取。 OutputStream 其他实现类 ObjectOutputStream ObjectOutputStream和所有FileOutputStream的子类都是装饰流。 ByteArrayOutputStream ByteArrayOutputStream、FIleOutputStream是两种基本的介质，它们分别向Byte 数组，和本地文件中写入数据。 PipedOutputStream PipedOutputStream是从与其他线程共用的管道中写入数据。 字符流和字节流字节流以字节（8bit）为单位读取数据。读取中文的时候非常不方便，容易产生乱码。 字符流的由来：本质其实就是基于字节流。读取时，去查了指定的码表，而有了对字符进行高效操作的流对象。 字节流和字符流的区别： 读写单位不同：字节流以字节为单位，字符流以字符为单位，根据码表映射字符，一次可能读多个字节。 处理对象不同：字节流能处理所有类型的数据（如图片、视频等），而字符流只能处理字符类型的数据。 结论：只要是处理纯文本数据，就优先考虑使用字符流。 除此之外都使用字节流。 Reader 字符输入流InputStreamReader首先看他有唯一个子类 FileReader FileReader的构造方法就是new FileInputStream字节流，再调用父类InputStreamReader构造器得到inputStreamReader对象。 123public FileReader(String fileName) &#123; super(new FileInputStream(fileName));&#125; FileReader都是使用InputStreamReader的read方法，以char[]为单位读取，而FileInputStream的read是以byte[]为单位读取。 1234int read();read(char cbuf[], int offset, int length);//底层是 read(char[] var1, int var2, int var3); Reader reader &#x3D; new FileReader(file);等效于Reader isr &#x3D; new InputStreamReader(new FileInputStream(file)); 1234567FileReader reader = new FileReader(file); char[] cbuf = new char[3];int len;while((len = reader.read(cbuf))!=-1)&#123; System.out.println(new String(cbuf,0,len));&#125; 123456789Reader isr = new InputStreamReader(new FileInputStream(file));// 等效于 Reader reader = new FileReader(file) char[] cbuf = new char[3]; int len; while((len = isr.read(cbuf))!=-1)&#123; System.out.println(new String(cbuf,0,len)); &#125; isr.close(); 同样，我们发现InputStreamReader 的创建，也是基于一个FileInputStream，同ObjectInputStream一样，只是一个装饰器。它将字节流转变为字符流。子类FileReader的存在就是代码上可以省略了这一步。 可以说，使用字符流都离不开InputStreamReader来将字节流转为字符流。 BufferedReaderBuffer：表示缓冲区的。之前的StringBuffer，缓冲区中的内容可以更改，可以提高效率。 如果想接收任意长度的数据，而且避免中文乱码的产生，就可以使用BufferedReader。 有两个构造器(其实一个) 12345public BufferedReader(Reader in, int sz) public BufferedReader(Reader in) &#123; this(in, defaultCharBufferSize);&#125; 基于一个Reader（如InputStreamReader）创建对象，说明 BufferedReader也只是一个装饰者。 除了继承自Reader的 1read(char cbuf[]) 覆写了Reader的 12read();read(char cbuf[], int off, int len) 自己提供了 123456// 一次性从缓冲区中读取一行String readLine();String readLine(boolean ignoreLF);// 此时，没有任何长度限制，可以输入很多的内容，每次都以回车结束(只要是一行不管多长)。// 不仅可以接收键盘输入，还可以将文件中的内容读取到缓冲区之中 然后调用readLine()方法将缓冲区中的全部内容转为字符串. 需要注意的是，如果从文件中读取的话readLine一次只能读取一行的数据。可以发现：从文件中使用readLine()方法读取行内容时，会自动接着上次在流中的位置进行读取。 如果要全部读取文件的中的内容有如下两种方法： 方法一：使用StringBuffer类不停的连接readLine()从每次读取的一行内容，直至读取的为null为止。然后进行输出。 方法二：使用StringBuffer类不停的连接read()方法读取到的每一个数字转化后的字符。然后进行输出。 StringReader就是方便将代码里的字符串创建输入流。 12345String str = &quot;Hello World&quot;;StringReader sr = new StringReader(str);int sc = sr.read(); // 读取单个字符，若到流末尾则返回-1System.out.println((char) sc); 1234String str = &quot;Hello World&quot;; char[] chars = new char[1024];int num = sr.read(chars, 0, str.length()); // 读取len个字符到chars数组中，从chars数组中的下标off开始存储，返回实际存储的字符数System.out.println(new String(chars, 0, num)); CharArrayReader CharArrayReader 通过字符数组直接创建输入流。12// 构造器public CharArrayReader(char buf[]) 其他 输入流的使用总结 FileInputStream （字节输入流） FileInputStream 如果需要从文件读取图片、视频等，和简单的读取文件不用考虑中文，使用最基础的字节输入流。 12FileInputStream fis = new FileInputStream(file);fis.read(); 其他实现类： 读java对象就ObjectInputStream；从从Byte数组、StringBuffer就ByteArrayInputStream、StringBufferInputStream…；需要直接读成java类型就DataInputStream、期望带缓存的字节流就BufferedInputStream InputStreamReader （字符输入流） 如果考虑中文乱码或其他原因要使用字符流，那就绕不开 InputStreamReader。 代码简洁地读取文件，可以直接用 FileReader，它的本质也是 InputStreamReader 123Reader reader = new FileReader(file); // 等效于 Reader isr = new InputStreamReader(new FileInputStream(file),&quot;UTF-8&quot;); // 不指定编码则默认UTF8 BufferedReader 如果想接收任意长度的数据，或按整行读取，而且避免中文乱码的产生，就可以使用 BufferedReader。 12345// 套娃比较多了，但是对于读中文文件最爽Reader reader = new BufferedReader(new InputStreamReader(new FileInputStream(file))); // 当然也能指定编码// 其实写法等效于Reader reader = new BufferedReader(new FileReader(file)); 其他实现类： 直接从字符串就StringReader，从Char数组就CharArrayReader… Writer 字符输出流OutputStreamWriter同样的，它也是字节输出流与字符输出流之间的桥梁。也有唯一一个子类FileWriter，提供了更快速使用OutputStreamWriter的方式。 FileWriter 构造方法摘要: 12345678910public FileWriter(String fileName) throws IOException &#123; super(new FileOutputStream(fileName));&#125;public FileWriter(File file) throws IOException &#123; super(new FileOutputStream(file));&#125;// append 代表覆盖 or 追加 （用的就是 FileOutputStream的覆盖 or 追加）public FileWriter(File file, boolean append) throws IOException &#123; super(new FileOutputStream(file, append));&#125; OutputStreamWriter 构造方法摘要: 1234OutputStreamWriter(OutputStream out) // 支持设置编码，而FileWriter默认使用UTF8OutputStreamWriter(OutputStream out, Charset cs) OutputStreamWriter(OutputStream out, String charsetName) FileWriter 是 OutputStreamWriter子类，可快速创建出 OutputStreamWriter 123Writer writer = new FileWriter(file);// 等效于Writer writer = new OutputStreamWriter(new FileOutputStream(file)); 123Writer writer = new FileWriter(file,true);// 等效于Writer writer = new OutputStreamWriter(new FileOutputStream(file,true)); 同样有方法 12345void write(int);void write(char[]);void write(char[],int,int);void write(String,int,int);void write(String); FileWriter都是使用OutputStreamWriter的write方法，方法签名和OutputStream也相似，但以char[]为单位读取，而FileOutputStream的write是以byte[]为单位读取。 12345Writer osw = new OutputStreamWriter(new FileOutputStream(file));osw.write(&quot;宫廷玉液酒&quot;);osw.close(); 字符流对比字节流，还会有一个flush()方法，在close()中会自动flush()。 1public void flush(); 当一次写入数据很多时，可以在中途手动刷新提交数据。没有flush()，也没有close()时，数据是不会成功写到文件的。 BufferedWriterBufferedWriter通过字符数组来缓冲数据，当缓冲区满或者用户调用flush()函数时，它就会将缓冲区的数据写入到输出流中。 查看构造函数也是依赖一个字符流，装饰者。 123// 构造函数BufferedWriter(Writer out) BufferedWriter(Writer out, int sz) 1234567// 方法void close() // 关闭此流，但要先刷新它。void flush() // 刷新该流的缓冲。void newLine() // 写入一个换行符。void write(char[] cbuf, int off, int len) // 写入字符数组的某一部分。void write(int c) // 写入单个字符。void write(String s, int off, int len) // 写入字符串的某一部分。 创建BufferedWriter： 1234567891011BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file,true))); // 覆盖 or 追加-truefor (int i = 0; i &lt; 10; i++) &#123; writer.write(StringRandomTest.charRandomFromInt()); // 生成6位随机字符串 writer.newLine(); // 换行&#125;writer.flush();writer.close(); 输出流的使用总结与输入流的使用总结类似，分别考虑（字节输出流、字符输出流、带缓冲字符输出流） FileOutputStream （字节输入流） FileInputStream 如果需要写入其他格式文件，和写入简单的文件而不用考虑中文，使用最基础的字节输出流。 OutputStreamWriter （字符输出流） 如果考虑中文乱码或其他原因要使用字符流，那就绕不开 OutputStreamWriter。 代码简洁地写文件，可以直接用子类 FileWriter，它的本质也是 OutputStreamWriter 123Writer writer = new FileWriter(file);// 等效于Writer writer = new OutputStreamWriter(new FileOutputStream(file)); BufferedWriter 如果想使用缓冲，或按整行写入，而且避免中文乱码的产生，就可以使用 BufferedReader。 12345// 套娃比较多了（装饰者模式）BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file,true)));// 其实写法等效于Writer writer = new BufferedWriter(new FileWriter(file,true)); 其他实现类的用法参考对比输入流其他实现类。 总结输入流核心的类：FileIntputStream、IntputStreamReader输出流核心的类：FileOutputStream、OutputStreamWriter 整理后的IO类结构 字符流与字节流使用(装饰者模式) 字节流和字符流区别 操作的单位不一样,一个是字节,一个是字符 操作中文的时候使用字符流更方便, 字节流更广泛:文本,视频,音频,图片… 字符流中有可以直接写字符串的方法 字节输出流 : 程序 —&gt; 磁盘文件 如果不关闭流也会写入 字符输出流 : 程序 —&gt; 缓冲 —&gt; 磁盘文件 如果不关闭流或者刷新缓冲区，不会写入文件 字符输出流，关闭的时候会先刷新，关闭之后不能够在操作，刷新之后可以继续操作。 刷新 : 写入的数据比较多时，可以在中途手动刷新提交数据。 输入流DemoFileInputStream12345678910111213FileInputStream fis = new FileInputStream(file); /* int i; while ((i = fis.read()) != -1)&#123; System.out.println((char)i); &#125;*/ byte[] bytes = new byte[5]; while (fis.read(bytes) != -1)&#123; String string = new String(bytes); System.out.println(string); &#125; FileReader、InputStreamReader12345678// InputStreamReader isr = new InputStreamReader(new FileInputStream(file)); FileReader reader = new FileReader(file); char[] cbuf = new char[3]; int len; while((len = reader.read(cbuf))!=-1)&#123; System.out.println(new String(cbuf,0,len)); &#125; BufferedReader readLine 按行读取12345678// BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(file)));BufferedReader reader = new BufferedReader(new FileReader(file));String line = null;StringBuilder builder = new StringBuilder();while ((line = reader.readLine()) != null) &#123; builder.append(line);&#125; 从当前项目resource下读取文件12345678910ClassPathResource classPathResource = new ClassPathResource(&quot;application.properties&quot;);InputStream inputStream = classPathResource.getInputStream();BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream));String line = null;StringBuilder builder = new StringBuilder();while ((line = reader.readLine()) != null) &#123; builder.append(line);&#125; 输出流DemoFileOutputStream123456FileOutputStream fos = new FileOutputStream(file,true);fos.write(&quot;每次一字节写入，中文还不会乱码&quot;.getBytes());fos.write(&quot;中文会乱码&quot;.getBytes(),0,10); // 指定长度就可能乱码了fos.close(); // 不关也会写入，建议手动关 FileWriter 、OutputStreamWriter12345678// OutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream(file,true)); FileWriter writer = new FileWriter(file,true); writer.write(&quot;直接写字符&quot;); writer.write(&quot;中文不乱码&quot;,0,5);// 一定要close或flush的时候才能将内容写到磁盘 writer.flush(); writer.close(); // 兼容一次flush BufferedWriter12345678910111213// BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file,true))); BufferedWriter writer = new BufferedWriter(new FileWriter(file,true)); for (int i = 0; i &lt; 10; i++) &#123; for (int j = 0; j &lt; 2; j++) &#123; writer.write(charRandomFromInt()); // 6 位随机字符 writer.write(&quot;,&quot;); &#125; writer.write(charRandomFromInt()); writer.newLine(); // 换行 &#125; writer.flush(); writer.close(); 其他Demo文件拷贝使用输入流读到内存，再用输出流写到磁盘，就完成了文件拷贝。 12345678/*每次读取到数组中，并且从数组中写入到文件，边读边写*/ FileInputStream fis = new FileInputStream(src);FileOutputStream fos = new FileOutputStream(dest);byte[] b = new byte[1024];int len;while((len = fis.read(b)) != -1)&#123; fos.write(b,0,len);&#125; IO流操作一般都应该关闭；Java7起实现了AutoCloseable的IO流支持自动关闭（一般我们用到的IO流都是有实现此接口的） 从终端读取123456789// System.in 就是一个InputStreamInputStreamReader isr = new InputStreamReader(System.in);BufferedReader reader = new BufferedReader(isr);String line = reader.readLine();System.out.println(line);// 或者Scanner sc = new Scanner(System.in);String line = sc.nextLine();","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[]},{"title":"kill 命令","slug":"kill命令","date":"2024-09-16T02:40:00.000Z","updated":"2024-09-17T04:15:23.410Z","comments":true,"path":"2024/09/16/kill命令/","permalink":"http://example.com/2024/09/16/kill%E5%91%BD%E4%BB%A4/","excerpt":"","text":"原文参考：https://zhuanlan.zhihu.com/p/140531888 想要在Linux中终止一个进程有两种方式，前台进程可以使用Ctrl+C键进行终止；后台进程，那么需要使用kill命令来终止。（其实Ctrl+C也是kill命令，kill -2） kill命令的格式是： kill[参数][进程号] 如： kill 21121 kill -9 21121 其中[参数]是可选的，进程号可以通过jps&#x2F;ps&#x2F;pidof&#x2F;pstree&#x2F;top等命令获取。 参数有多种类型，通常使用信号。信号如果没有指定的话，默认会发出终止信号(kill -15)。常用的信号如下： HUP 1 终端断线 INT 2 中断（同 Ctrl + C） QUIT 3 退出（同 Ctrl + \\） TERM 15 终止 KILL 9 强制终止 CONT 18 继续（与STOP相反， fg/bg命令） STOP 19 暂停（同 Ctrl + Z） 比较常用的就是强制终止信号：9和终止信号：15，另外。中断信号：2其实就是Ctrl + C结束前台进程。 Kill -9 是强制杀掉，这个信号程序应该是无法捕捉的。 linux 使用 kill -9 命令杀死程序，程序是无法主动释放资源的。操作系统从进程表中直接清除该程序，而不会给程序任何通知和反应时间。 kill -15 是可以被执行、阻塞和忽略的 kill -15 只是通知对应的进程要进行”安全、干净的退出”，退出前一般会进行资源释放、临时文件清理等等，再进行程序的终止。但如果在”准备工作”进行过程中，遇到阻塞或者其他问题导致无法成功，那么应用程序可以选择忽略该终止信号。 在非必要时，不要使用kill -9命令，尤其是那些web应用、提供RPC服务、执行定时任务、包含长事务等应用中，因为kill -9没给spring容器、tomcat服务器、dubbo服务、流程引擎、状态机等足够的时间进行收尾。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"kill -9","slug":"kill-9","permalink":"http://example.com/tags/kill-9/"}]},{"title":"maven","slug":"maven","date":"2024-09-16T02:40:00.000Z","updated":"2024-09-17T13:57:36.015Z","comments":true,"path":"2024/09/16/maven/","permalink":"http://example.com/2024/09/16/maven/","excerpt":"","text":"创建 maven java项目12345mvn archetype:create \\-DgroupId=com.demo.maven.quickstart \\-DartifactId=myDemo \\-DarchetypeArtifactId=maven-archetype-quickstart \\-Dversion=0.01-snapshot 解释： 1234archetype:create # 创建项目-DgroupId # 项目的 groupId：包名、公司的域名的反写-DartifactId # 项目的 artifactId：项目名称-DarchetypeArtifactId=maven-archetype-quickstart # 写死的，表示创建的是java项目 创建的maven项目（使用命令行或idea中）都会自动构建出src&#x2F;main&#x2F;java、src&#x2F;main&#x2F;resourcessrc&#x2F;test&#x2F;target的结构，.class文件放入target目录。 创建 maven web 项目12345mvn archetype:create \\-DgroupId=com.demo.maven.webapp \\-DartifactId=myWebApp \\-DarchetypeArtifactId=maven-archetype-webapp \\-Dversion=0.0.1-snapshot 创建的webapp项目会自动构建出 web结构。 maven 操作命令在pom.xml 同级目录下执行，完成对当前项目操作 编译 src&#x2F;main12mvn compile # 将src/main/java目录下的java源码编译成.class、和src/main/resources文件编译到target目录下classes文件夹里 编译 src&#x2F;test12mvn test # 将src/test/java目录下的javaTest编译成.class文件放到target目录下test-classes文件夹里，并运行单元测试 清理12mvn clean # 删除target目录内容，也就是删除target目录下classes文件和jar/war包等等... 打包12mvn package # 生成压缩文件：java项目#jar包；web项目#war包，也是放在target目录下 安装12mvn install # 将压缩文件(jar或者war)上传到本地仓库，可供本地其他项目调用 部署|发布12mvn deploy # 将压缩文件上传私服，可供其他开发人员调用 maven项目的生命周期上述命令就是对应maven生命周期。 验证 validate 验证项目 验证项目是否正确且所有必须信息是可用的 编译 compile 对src/main/java执行编译，源代码和配置文件等 测试 test 对src/test/java执行编译 打包 package 创建JAR/WAR包，放到target中 检查 verify 对集成测试的结果进行检查，以保证质量达标 安装 install 拷贝安装打包的项目到本地仓库，以供本地其他项目使用 部署 deploy 拷贝安装打包的项目到远程仓库，以共享给其他开发人员使用 当一个阶段通过 Maven 命令调用时，例如 mvn compile，只有该阶段之前以及包括该阶段在内的所有阶段会被执行。 如使用 mvn compileMaven 将会开始处理并显示直到编译阶段的构建生命周期的 validate、compile阶段 12345678910[INFO] Scanning for projects...[INFO] ------------------------------------------------------------------[INFO] Building Unnamed - com.companyname.projectgroup:project:jar:1.0[INFO] task-segment: [compile][INFO] ------------------------------------------------------------------[INFO] [antrun:run &#123;execution: id.validate&#125;]// ...[INFO] [antrun:run &#123;execution: id.compile&#125;]// ...[INFO] BUILD SUCCESSFUL 如使用 mvn package ： 会依次执行 clean、resources、compile、test、package，并将打好的war(jar)包生成在 target下 如使用 mvn install ： 会依次执行 clean、resources、compile、test、package、install，war(jar)包生成在 target下，同时根据包名安装到本地仓库 特别注意一点。mvn test 有两部分阶段：会将src/test里的内容也编译到 target/test-calsses，同时执行单元测试里的代码。 使用 mvn package 会触发 mvn test，如果src/test里assert不通过，会导致打包失败&#39;There are test failures.&#39;。 如果期望在mvn package时忽略单元测试，可以在命令里添加 -DskipTests，也可以在idea里设置 Toggle &#39;Skip Tests&#39; Mode，则对src/test下的内容只编译，不执行test代码。（mvn test 也可以 skip tests 就只会编译） war包与jar包jar包是把类和相关的资源封装到压缩的归档文件中，对于spring boot项目会将内置tomcat一并打包。war包代表了一个Web应用程序，它可以包含 Servlet、HTML页面、Java类、图像文件，以及组成Web应用程序的其他资源。 pom文件里 &lt;packaging&gt; 标签可以是pom\\jar\\war。三者区别 pom： &lt;packaging&gt;pom&lt;&#x2F;packaging&gt;用在父级工程或聚合工程中，用来做jar包的版本控制，指明这个聚合工程的打包方式为pom。只是用来帮助其他模块构建的工具，本身并没有实质的内容。jar和war用在moudle子工程中。 jar: 默认的打包方式，如moudle子工程pom文件里没有&lt;packaging&gt;就等同于&lt;packaging&gt;jar&lt;&#x2F;packaging&gt;。jar包可以通过 java -jar 直接运行。 war: 打包成war，发布在服务器上，如网站或服务。&lt;packaging&gt;war&lt;&#x2F;packaging&gt; 打jar包时可增加明细配置：(g&#x2F;a&#x2F;v是指打包时使用maven插件的信息，mainClass 指定jar的程序运行入口) 1234567891011121314&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;com.demo.App&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; 直接执行这个jar： 12&gt; java -jar .\\demo-1.0-SNAPSHOT.jar9 包中有多个含main方法的主类而打包时没有指定mainClass，还对这个jar运行的话会报错【.\\demo-1.0-SNAPSHOT.jar中没有主清单属性】 1命令中解决：java -jar .\\demo-1.0-SNAPSHOT.jar com.demo.App // jar命令后面指定main方法所在主类即可，省去一次重新打包 补充：jdk9 后还可以打包 jmod（Java 模块化），通过 jlink 命令，可以直接将 jmod 打包为对应环境的可执行的程序，告别了安装 jdk 的步骤。 maven命令的可选参数如编译hive源码 123456mvn clean compile \\-Phadoop-2 \\mvn clean package \\-Phadoop-2 \\-DskipTests 如编译spark 源码时用到 1234567./build/mvn clean package \\-Phadoop-3.2 \\-Pyarn \\-Dhadoop.version=3.2.2 \\-Phive \\-Phive-thriftserver \\-DskipTests -P 和 -D 是命令的可选参数，使用 mvn –help 查看参数解释: -P ：activate-profiles激活配置文件，多个用逗号分隔；-D： Define a system property定义系统属性（-DskipTests 就是要跳过mvn test步骤，也就是编译、打包时忽略 src&#x2F;test 下的内容） 格式：短横线指定一项参数内容，空格作为分隔。idea里面VM options 设置jvm参数（-Djline.WindowsTerminal.directConsole&#x3D;false -XX:StringTableSize&#x3D;60013），和Program arguments设置调用主类的时传入参数args也是这个格式。 安装到本地仓库1mvn install:install-file -DgroupId=org.csource -DartifactId=fastdfs-client -Dversion=1.2 -Dpackaging=jar -Dfile=d:\\**\\**.jar 1234-DgroupId=生成到本地仓库的目录 对应 groupId-DartifactId=对应在pom.xml里导包那个artifactId-Dversion=版本号 对应version-Dpackaging=下载到本地的.jar目录（来源） 安装后可以在本地仓库找到jar包repository\\org\\csource\\fastdfs-client\\1.2需要引入到其他工程的话： 12345&lt;dependency&gt; &lt;groupId&gt;org.csource&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt;中 &lt;scope&gt; 代表的意义参考https://blog.csdn.net/keepfriend/article/details/123181254 在Maven中依赖的域有： compile、provided、runtime、system、test、import。 编译阶段 单元测试阶段 运行阶段 compile（默认） √ √ √ provided √ √ runtime √ √ test √ system √ √ provided当依赖的scope为provided的时候，在编译和测试的时候有效，在执行（mvn package）进行打包时不会加入。比如， 我们开发一个web应用，在编译时我们需要依赖servlet-api.jar，但是在运行时我们不需要该 jar包，因为这个jar 包已由web服务器提供，如果在打包时又被加入进去，那么就可能产生冲突。此时我们就可以使用 provided 进行范围修饰。 runtime当依赖的scope为runtime的时候，在测试、运行的时候有效，在编译的时候不会依赖。如JDBC驱动包只需要在运行时才需要。就可以使用 runtime 进行范围修饰。 test当依赖的scope为test的时候，只在测试时候有效，在编译与运行的时候都不会使用这个依赖。如单元测试的依赖，当然只会在单元测试时才使用。就可以使用test进行范围修饰。 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; system依赖项不会从maven仓库获取，而是从本地文件系统拿，需要配合systemPath属性使用。比如 1234567&lt;dependency&gt; &lt;groupId&gt;org.open&lt;/groupId&gt; &lt;artifactId&gt;open-core&lt;/artifactId&gt; &lt;version&gt;1.5&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/lib/open-core.jar&lt;/systemPath&gt;&lt;/dependency&gt; importimport 表示从其它的pom文件中导入dependency配置，import 只能在&lt;dependencyManagement&gt; 中使用。","categories":[{"name":"maven","slug":"maven","permalink":"http://example.com/categories/maven/"}],"tags":[]},{"title":"Linux两分类:CentOS、RedHat；Ubuntu、Debian；tar、rpm、yum、deb、apt-get","slug":"Linux补充概念-CentOS、RedHat；Ubuntu、Debian；tar、rpm、yum、deb、apt-get","date":"2024-09-16T02:00:10.000Z","updated":"2024-09-17T04:15:31.539Z","comments":true,"path":"2024/09/16/Linux补充概念-CentOS、RedHat；Ubuntu、Debian；tar、rpm、yum、deb、apt-get/","permalink":"http://example.com/2024/09/16/Linux%E8%A1%A5%E5%85%85%E6%A6%82%E5%BF%B5-CentOS%E3%80%81RedHat%EF%BC%9BUbuntu%E3%80%81Debian%EF%BC%9Btar%E3%80%81rpm%E3%80%81yum%E3%80%81deb%E3%80%81apt-get/","excerpt":"","text":"Linux系统基本上分两大类： RedHat系列：Redhat、Centos、Fedora等 Debian系列：Debian、Ubuntu等 CentOS与Red hat区别： CentOS（Community ENTerprise Operating System）基于Red Hat Enterprise Linux 开放源代码规定编译而成。有些要求高度稳定性的服务器以CentOS替代商业版的Red Hat Enterprise Linux使用。 CentOS是免费的版本，是不向用户提供任何的服务，而Redhat对某些服务是提供收费的。 CentOS与Ubuntu区别： CentOS 基于Red Hat。Ubuntu 基于Debian发行版，是一个以桌面应用为主的Linux操作系统。 两者同为目前版本中个人和小团队常用的服务级操作系统，在线提供的软件库中可以很方便的安装到很多开源的软件及库。 两者都使用bash作为基础shell，所以在很多基础命令上，ubuntu与centos的差别不是很明显，而ubuntu在桌面界面上要做的更为出色，很多人如果是从兴趣出发而学习linux的首选一般都是ubuntu。 Centos与Ubuntu的使用习惯和命令上还是有很多的不同，下面简单列举一下： centos是来自于RedHat，所以centos支持rpm格式的安装，命令是 “rpm -参数”，而ubuntu 支持deb包安装，安装deb包的命令是”dpkg -参数”。 在线安装软件中，centos使用的是yum命令，去管理rpm包；而ubuntu中使用的是apt-get命令。如yum中从软件源中搜索软件的方法：yum search + 软件名。 RedHat 系列 常见的安装包格式： rpm包，安装rpm包的命令是”rpm -参数” 包管理工具： yum 支持tar包 tar和rpm对比tar 只是一种压缩文件格式，所以，它只是把文件压缩打包而已。rpm 相当于windows中的安装文件，它会自动处理软件包之间的依赖关系。rpm一般都是预先编译好的文件。tar一般包括源码、编译脚本，你可以编译，所以具有通用性。如果你的包不想开放源代码，你可以制作成rpm，如果开源，用tar更方便了。 rpm操作1234567891011121314安装：rpm -ivh *.rpm卸载：rpm -e packgenamerpm -q nginx 查看是否已经安装升级：rpm -Uvh xxx查询：查询所有安装的包： rpm -qa查询某个包：rpm -qa | grep xxxrpm -qi xxx查询软件的安装路径：rpm -qi xxxrpm -qc xxx查询某个文件是那个rpm包产生：rpm -qf /etc/yum.confrpm -qpi xxxrpm -qa|grep php 查看已安装的RMP包 yum管理rpm包 yum的配置文件是&#x2F;etc&#x2F;yum.confyum &#x3D; Yellow dog Updater, Modified主要功能是更方便的添加&#x2F;删除&#x2F;更新RPM包.它能自动解决包的倚赖性问题.它能便于管理大量系统的更新问题 yum特点可以同时配置多个资源库(Repository)简洁的配置文件(&#x2F;etc&#x2F;yum.conf自动解决增加或删除rpm包时遇到的倚赖性问题使用方便保持与RPM数据库的一致性 设置yum仓库 1234#中央仓库yum-config-manager --add-repo http://download.docker.com/linux/centos/docker-ce.repo#阿里仓库yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum 包管理 12345678910111213141516yum -y update # 升级所有包同时也升级软件和系统内核；​yum -y upgrade # 只升级所有包，不升级软件和系统内核yum search &lt;package_name&gt; # 搜寻某个包yum list &lt;package_name&gt; # 列出所有可安装的软件包， # eg: yum list php* # eg: yum list docker-ce --showduplicates | sort -ryum install &lt;package_name&gt; # 安装某个包yum remove &lt;package_name&gt; # 移除某个包yum clean all # 清除已经安装过的档案（/var/cache/yum/）yum list updates # 列出所有可更新的软件包yum list installed # 列出所有已安装的软件包yum list extras # 列出所有已安装但不在 Yum Repository 內的软件包yum info &lt;package_name&gt; # 查询档案讯息 yum-utils是yum的工具包集合，使yum使用起来更加方便和强大，也需要安装 1yum -y install yum-utils Debian系列 常见的安装包格式： deb包，安装deb包的命令是”dpkg -参数” 包管理工具： apt-get 支持tar包 Ubuntu中包管理工具apt-get配置文件&#x2F;etc&#x2F;apt&#x2F;sources.list常用的APT命令参数： 1234567891011121314151617apt-cache search package 搜索包apt-cache show package 获取包的相关信息，如说明、大小、版本等apt-get install package 安装包apt-get install package - - reinstall重新安装包apt-get -f install修复安装&quot;-f = ——fix-missing&quot;apt-get remove package 删除包apt-get remove package - - purge 删除包，包括删除配置文件等apt-get update 更新源 ，重新获取软件包列表apt-get upgrade 更新已安装的包apt-get dist-upgrade 升级系统apt-get dselect-upgrade 依照dselect 的选择更新apt-cache depends package 了解使用依赖apt-cache rdepends package 是查看该包被哪些包依赖apt-get build-dep package 安装相关的编译环境apt-get source package 下载该包的源代码apt-get clean &amp;&amp; apt-get autoclean 清理无用的包apt-get check 检查是否有损坏的依赖","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"rpm","slug":"rpm","permalink":"http://example.com/tags/rpm/"},{"name":"yum","slug":"yum","permalink":"http://example.com/tags/yum/"}]},{"title":"shell脚本","slug":"shell脚本","date":"2024-09-16T02:00:10.000Z","updated":"2024-09-17T04:16:18.095Z","comments":true,"path":"2024/09/16/shell脚本/","permalink":"http://example.com/2024/09/16/shell%E8%84%9A%E6%9C%AC/","excerpt":"","text":"编写 shell 脚本Hello word 创建并进入编写一个 xx.sh脚本文件 1vi first.sh 1234#! /bin/bashecho &quot;Hello Word!&quot; 运行 .sh脚本 1sh first.sh 或 1./first.sh 加上 -x 可以查看脚本的运行记录 1sh -x first.sh 1234[root@shell ~]# sh -x first.sh+ echo &#x27;Hello Word!&#x27;Hello Word! 基础语法分号，换行都表示单条命令的结束。同一行内写多条命令必须用;分割。 空格。某些结构的语法要求必须有空格，如 $[ $1 -lt 10 ]中，’[‘ 后要有空格，’]’前也要空格; 如定义函数 sum() { 后必有空格或换行。如单行内定义多个变量要用空格分割。 ‘’ 表示字符串原样。&#96;&#96;表示输出其中命令的结果。如echo `seq 1 5`会输出 1 2 3 4 5。 运行和调试如果某一行语法错误，下面不关联的脚本仍然会继续执行。 使用sh 或 .都能执行shell脚本文件。 调试： -x 跟踪执行过程，将每条执行命令和结果一并输出。可以检查语法错误，尤其对于单行文本中有多条命令，-x 会将根据语法规则做详细拆分，逐次输出命令和结果。 -n 读一编脚本但不执行，可以用来事先检查语法错误。 -v 将每行命令文本和对应的结果一并输出。 在shell中使用变量 在shell中定义变量123a=1echo $a 对变量做数学运算，需要使用[]括起来，并在[]前使用$ 1234a=1b=2echo &quot;sum=$[$a+$b]&quot; 预设变量1234a=$1b=$2echo &quot;sum=$[$a+$b]&quot; 执行命令同时传入的参数，用$1、$2…对应参数顺序就可以。$0特指当前shell脚本文件名。123[root@shell ~]# sh first.sh 100 200sum=300 交互变量，shell运行过程中传入变量1234read -p &quot;请输入第一个值：&quot; xread -p &quot;请输入第二个值：&quot; yecho &quot;求和等于：$[$x+$y]&quot; 执行脚本：12345[root@shell ~]# sh first.sh 请输入第一个值：100请输入第二个值：200求和等于：300 if选择结构if 不带 else格式： 1234if 判断语句then 命令语句fi 示例： 1234if (($1 &lt; 5))then echo $1这个数小于5fi 单行内写完整个if结构要使用分号： 1if [ $y -gt 100 ];then echo $y大于100哈;fi if else格式： 123456if 判断语句then 命令语句else 命令语句fi 示例： 12345if (($1 &lt; 5)); then echo 这个数小于5else echo 这个数太大了fi if elif格式： 1234567if 判断语句; then 命令语句elif 判断语句; then 命令语句else 命令语句fi 示例： 1234567if (($1 &lt; 5)); then echo 这个数小于5elif (($1 == 5)); then echo 这个数刚好else echo $1你太大了fi -lt、-gt、-le、-ge、-eq、-ne等值的判断语句可以写在(())内，也可以写在[]内，使用[]时&lt;&gt;&#x3D;符号要用以下符号代替。 123456-lt 小于-gt 大于-le 小于或等于-ge 大于或等于-eq 等于-ne 不等于 1234567if [ $1 -lt 5 ]; then echo 这个数小于5elif [ $1 -eq 5 ]; then echo 这个数刚好else echo 这个数太大了fi &amp;&amp; 和 ||与和或。在判断语句中使用 &amp;&amp; 和 || 对多个条件的判断，和java类似。 123if [ $1 -lt 5 ] || [ $1 -gt 10 ]; then echo 这个数小于5，或大于10fi 文档相关的判断在if 判断语句中，对文档的判断，常用的有以下关键字 12345678-e 判断文件或目录是否存在-d 判断是不是目录以及是否存在-f 判断是不是文件以及是否存在-r 判断是否有读权限-w 判断是否有写权限-x 判断是否有执行权限-x 判断字符串为空返回true-s 判断文件大小不为0返回true 判断文件存在，具体格式： 123if [ -e filename ]; then 命令语句fi 123if [ -e /home/ ]; then echo &#x27;ok&#x27;fi case选择结构具体格式如下 1234567891011case 变量 invalue1) 命令语句 ;;value2) 命令语句 ;; *) 命令语句 ;;esac 示例： 12345678910111213a=$[$1%2]case $a in0) echo &quot;The number is even.&quot; ;;1) echo &quot;The numbei is odd.&quot; ;;*) echo &quot;Tt&#x27;s not a number.&quot; ;;esac for循环格式： 123for 变量名 in 循环条件; do 命令语句done 循环条件可以是一组字符串或数字（空格分割），也可以是一条命令的执行结果。示例： 123for i in 1 2 3 a b c; do echo $i;done 1234# seq 1 5 表示从1到5的一个序列for i in `seq 1 5`; do echo $i;done 123for file in `ls ~`; do echo $file;done while循环格式： 123while 条件语句; do 命令语句done 示例： 123456a=$1while [ $a -ge 1 ]; do echo $a a=$[$a-1]done 如果用冒号代替循环条件，可以死循环 123while :; do echo &#x27;呀哈哈，我被发现了&#x27;done 循环中断 break、continue、exitbreak 结束整个循环体。continue 结束本次循环，进入下一次循环。exit 退出整个脚本。 12345678for i in `seq 1 5`do if [ $i == 3 ]; then break fi echo $idone# 输出 1 2 12345678for i in `seq 1 5`do if [ $i == 3 ]; then continue fi echo $idone# 输出 1 2 4 5 数组 定义数组1a=(1 2 3 4 5) 或者1a=(`seq 1 5`) 获取数组所有元素1echo $&#123;a[@]&#125; 或者1echo $&#123;a[*]&#125; 获取数组长度1echo $&#123;#a[@]&#125; 获取指定索引的元素1echo $&#123;a[1]&#125; 修改指定索引的元素12a[1]=100 # 1 100 3 4 5 直接替换指定位置元素123# 将第3个元素设置为100. 注意，3不是索引a=($&#123;a[@]/3/100&#125;)# 1 100 100 4 5 123# 如果索引下标不存在，则添加一个元素a[5]=6# 1 100 3 4 5 6 删除指定索引的元素12unset a[5]# 1 100 3 4 5 删除整个数组1unset a 指定位置和长度截取123# 从索引第0个元素开始，截取长度3个echo $&#123;a[@]:0:3&#125; # 1 2 3 123# 从倒数第3个元素开始，截取长度2个echo $&#123;a[@]:0-3:2&#125; # 3 4 函数定义和使用定义函数必须写在调用函数之前，而且是在最前，不能出现在中间。示例： 123456789# 定义sum()函数function sum()&#123; sum=$[$1+$2] echo $sum&#125;# 调用sum $1 $2 在shell中使用日期date123#! /bin/bashdate 运行后输出： 12023年04月11日 星期二 15:11:38 CST 如果要将date执行结果赋值给变量，需要写在&#96;&#96;中，否则表示date这个字符串 12d=`date`echo $d 指定格式的日期12345678%Y 表示四位数字年份%y 表示两位数字年份%m 表示月份%d 表示日期%H 表示小时%M 表示分钟%S 表示秒%w 表示星期 示例：12date +%Y-%m-%d# 2023-04-12 示例： 12date +&#x27;%Y-%m-%d %H:%M:%S&#x27;# 2023-04-12 17:49:43 注意区分大小写，在java中输出这个样式是使用 yyyy-MM-dd HH:mm:ss 对日期加减偏移1date -d &#x27;-1 day&#x27; # 当前日期的前一天 1date -d &#x27;-1 hour&#x27; # 当前时间的前一小时 1date -d &#x27;-1 min&#x27; # 当前日期的前一分钟 偏移后的日期仍然可以指定格式输出1date -d &#x27;-1 day&#x27; +&#x27;%Y-%m-%d %H:%M:%S&#x27; 同样，赋值给变量也需要写在&#96;&#96;里12d1=`date -d &#x27;+1 hour&#x27; +&#x27;%Y-%m-%d %H:%M:%S&#x27;`echo $d1 bin&#x2F;bash 和 &#x2F;bin&#x2F;sh以&#x2F;bin&#x2F;bash声明的脚本，中间即使发生错误，依然会继续向下运行。&#x2F;bin&#x2F;sh是早期版本，脚本中间发生错误会终止脚本的运行，不再运行下面的代码。 #!&#x2F;bin&#x2F;bash –posix，脚本执行效果跟#!&#x2F;bin&#x2F;sh是一样的。 1#！/bin/bash --posix #开启便携模式，遇到错误时，停止继续运行 新版本的Linux内核中，老的sh已经被后来者bash整合了。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://example.com/tags/shell/"}]},{"title":"为什么要有Python虚拟环境","slug":"为什么要有Python虚拟环境","date":"2024-09-16T01:50:08.000Z","updated":"2024-09-17T04:18:12.492Z","comments":true,"path":"2024/09/16/为什么要有Python虚拟环境/","permalink":"http://example.com/2024/09/16/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89Python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/","excerpt":"","text":"为什么要有Python虚拟环境 当我们在开发机上安装一个 Python 程序或者库的时候，都要安装 1一些包（import非内置的包时），比如说， pip install django。这些包默认都会安装到 Python 环境的 site-packages 目录下面。 不同的项目可能会用到相同包，的不同版本，或依赖的其他包，这样就没法区分当前项目使用哪个版本，即版本不兼容。 简而言之，虚拟环境就是 Python 环境的一个副本。 不同Python 项目的运行环境。 要得到这么一个副本，首先： 要给它单独找个文件夹存起来 要给它取个名字 这个文件夹的名字也就是这个虚拟环境的名字，在这个文件夹下面有这些东西： 一个 python.exe 一个 Scripts 目录 一个 Lib 目录 在期望的路径下，使用下面的命令来快速创建一个虚拟环境： python -m venv venvdemo 会在当前路径下生成一个venvdemo的文件夹，并包含以下内容： Include Lib Scripts pyvenv.cfg 其中 Include 基本不用管，Lib 目录下也没什么特别的，主要就是 Scripts 目录：其中多出了 activate 和 deactivate 用来 激活 和 去激活 虚拟环境。 .&#x2F;activate 激活之后，我们就进入了虚拟环境，这时候不管是执行 python 还是 pip 针对的都是虚拟环境里面的。 (其实激活就是把当前虚拟环境下Scripts 目录临时添加到了 PATH 环境变量的第一位，这样也解释了，为啥要把 python.exe 也放到了 Scripts 目录下。这样后续执行python也是首选的当前环境下的python.exe ) 同样也注意，不是只有激活才能进入虚拟环境，当我们直接使用当前环境下Scripts 里的python.exe时，启动 python 也是在虚拟环境中了。 大多数的 Python 开发工具都支持虚拟环境的相关操作。指定以虚拟环境中 python.exe 来运行，一旦确定了它的位置，就确定了环境的位置。也就不用每次都去激活。","categories":[{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"Junit 单元测试，并整合 Spring Boot","slug":"Junit单元测试，并整合Spring Boot","date":"2024-09-15T09:15:00.000Z","updated":"2024-09-15T09:15:00.000Z","comments":true,"path":"2024/09/15/Junit单元测试，并整合Spring Boot/","permalink":"http://example.com/2024/09/15/Junit%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%EF%BC%8C%E5%B9%B6%E6%95%B4%E5%90%88Spring%20Boot/","excerpt":"","text":"Junit4pom文件中引入junit依赖，如12345678&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 src&#x2F;test&#x2F; 下创建包和测试类。要求： 测试方法上必须使用@Test 测试方法必须使用 public void进行修饰 测试类的包应该和被测试类的包一样 测试单元中的每个方法一定要能够独立测试，其方法不能有任何依赖 123456789import org.junit.Test;public class GargantuaTest &#123; @Test public void test1()&#123; assert(1 == 0); &#125;&#125; 其他注解： @BeforeClass：修饰的方法会在所有方法被调用前执行，且该方法是静态的，当测试类被加载后就接着运行它，且在内存中只会存在一份实例。针对所有测试，只执行一次（他比较适合加载配置文件，建立数据库连接等 ） @AfterClass：所修饰的方法会在所有测试结束后执行，针对当前运行的所有测试，只执行一次 。（通常用来对资源管理，如关闭数据库连接，关闭流） @Before和@After 会在每个测试方法前后各自动执行一次 @Ignore：忽略的测试方法 测试结果中 Failure和error Failure 一般由测试单元使用断言方法判断失败引起的，这个报错，说明测试点发现了问题，即程序输出的结果和我们预期的不一样 error 是由代码异常引起的，它可以产生代码本身的错误，也可以是测试代码中的一个隐藏bug Spring Boot 整合 Junit4pom文件中引入junit依赖，如123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 其中依赖了 Junit 4.13.2 在 src&#x2F;test&#x2F; 下创建包和测试类。通常一个项目中会写很多很多测试类，而测试类上面是需要以下几个注解的。避免每建一个类都去补注解，可以创建一个基类，在这个基类中加上注解，作为BaseTest，其他测试类直接继承这个类就好了。 12345678910111213141516171819202122232425import org.junit.After;import org.junit.Before;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.test.context.web.WebAppConfiguration;/** * 单元测试基类 */@RunWith(SpringRunner.class)@SpringBootTest(classes = Application.class)@WebAppConfiguration //对于Web项目，Junit需要模拟ServletContext，因此我们需要给我们的测试类加上public class BaseTest&#123; @BeforeClass public void init() &#123; System.out.println(&quot;获取数据库连接----------------&quot;); &#125; @AfterClass public void destory() &#123; System.out.println(&quot;关闭连接----------------&quot;); &#125;&#125; 12345678910111213/** * 测试类，基础基类，也就继承了基类上的注解 */public class GargantuaTest extends BaseTest &#123; @Autowired private MyService myService; @Test public void test1()&#123; assert(1 == myService.count()); &#125;&#125; @SpringBootTest的作用@SpringBootTest(classes &#x3D; 启动类名称.class)1)如果注解@SpringBootTest(classes &#x3D; 启动类名称.class)中配置了项目启动类，则该测试类可以放在test.java下任何包中2)如果注解@SpringBootTest没有配置里面的参数classes &#x3D; Application.class，则需要确保test.java下的测试类包与启动类所在的包一致 Junit4 与 Junit5使用 junit 41234567891011import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class BuserTest &#123;&#125; junit 4 必须使用 @RunWith(SpringRunner.class)，才能获取到spring容器里的bean，否则会NPE异常。junit 4 方法上使用的@Test 来自org.junit.Test；junit 5 方法上使用的@Test 来自org.junit.jupiter.api.Test；打开@Test的源码也看到是不一样的。 使用 junit 5123456789import org.junit.jupiter.api.Test;import org.springframework.boot.test.context.SpringBootTest;@SpringBootTestpublic class BuserTest &#123;&#125; Junit5 其他注解 @BeforeAll和 @AfterAll 修饰的方法会在所有方法被调用之前&#x2F;后执行，针对所有测试，只执行一次。主要用于在测试过程中所需要的全局数据和外部资源的初始化和清理。 @BeforeEach 和 @AfterEach 所标注的方法会在每个测试方法开始前和结束时都会执行一次。 @Disabled 用在测试方法上时，该方法不会被 JUnit 执行。也可以用在测试类上，标记类下所有的测试方法不被执行。 @Nested 内嵌测试类。标记测试类中的内部类。 @RepeatedTest 允许让测试方法进行重复运行。当要运行一个测试方法多次时，可以使用 @RepeatedTest 标记它：123@RepeatedTest(value = 3)public void repeated_test() &#123;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"Spring Boot","slug":"Spring/Spring-Boot","permalink":"http://example.com/categories/Spring/Spring-Boot/"}],"tags":[{"name":"Junit","slug":"Junit","permalink":"http://example.com/tags/Junit/"}]},{"title":"ASCII 、Unicode、UTF-8编码关系","slug":"ASCII、Unicode、UTF-8编码关系","date":"2024-09-15T07:40:10.000Z","updated":"2024-09-17T04:13:36.889Z","comments":true,"path":"2024/09/15/ASCII、Unicode、UTF-8编码关系/","permalink":"http://example.com/2024/09/15/ASCII%E3%80%81Unicode%E3%80%81UTF-8%E7%BC%96%E7%A0%81%E5%85%B3%E7%B3%BB/","excerpt":"","text":"参考：https://www.cnblogs.com/tsingke/p/10853936.html 为什么会出现乱码一份文件，根据编码A的规则将文件转换为二进制存储起来。被使用另一种编码B打开，根据编码B的规则将二进制解析。就解析出不一样的文件，甚至是乱码。 所以，要想打开一个文件，就必须提前知道它的编码方式，或者约定，所有文件的读写都使用统一的编码。 字符编码的作用计算机内部，所有信息最终都是一个二进制值。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出 256 种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从 00000000 到 11111111。 为了让计算机中的0、1与日常使用的符号互相识别，上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间，做了固定的一一对应。这被称为 ASCII 码，一直沿用至今。 ASCIIASCII 码一共规定了128个字符的编码，比如空格SPACE是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位（2^7&#x3D;128），但是计算机都用字节（byte）作为一个单元，所以将最前面的一位统一规定为0，补齐8位作为 1 byte。 英语用128个符号编码就够了，但是用来表示其他语言，256个符号还是不够的。尤其对于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。256种符号是远远不够的。 Unicode为了实现全球统一编码。如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是 Unicode，就像它的名字都表示的，这是一种所有符号的编码。Unicode 当然是一个很大的集合，现在的规模可以容纳100多万个符号。 Unicode 的问题需要注意的是，Unicode 只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。 比如，汉字 严 的 Unicode 是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。 这里就有两个严重的问题第一个问题是，如何才能区别 Unicode 和 ASCII ？计算机拿到一串24位（3 Byte）二进制数，怎么知道三个字节表示一个符号，而不是三个字节分别表示一个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果 Unicode 为了兼容其他更大的字符，采用统一规定，如每个符号都用三个字节标识，那么每个英文字母的前两个字节前都补0组成24位，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。 UTF-8UTF-8 是 Unicode 的实现方式之一，是Unicode的一种存储、传输方式。对Unicode在传输、存储方面的补充。Unicode都既是字符集，也是编码方式，而UTF-8只是编码方式，并不是字符集。 或者通俗一点说，Unicode负责根据字符集映射成对应的二进制代码，UTF-8 负责将Unicode完成的编码，以什么样的分隔来让计算机识别。 UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 UTF-8 的编码规则很简单，只有二条： 1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。 2）对于n字节的符号（n &gt; 1），第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。 下表总结了编码规则，字母x表示可用编码的位。 1234567Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）--------------------+------------------------------------0000 0000-0000 007F | 0xxxxxxx0000 0080-0000 07FF | 110xxxxx 10xxxxxx0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 跟据上表，解读 UTF-8 编码非常简单。如果一个字节的第一位是0，则这个字节单独就是一个字符(兼容ASCII 码)；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节（如最后一条是4段，即4个字节，那么从开始有4个连续的1）。 GBKGBK 包含全部中文字符，也就是说，gbk并不是出于统一编码的目的出现，仅仅是为我们汉字编码而形成之解决方案。不能做到国际通用。 gbk编码每个字符占用2个字节，而UTF-8中出现中文那就是3个字节，所以采用gbk编码的文本，在UTF-8环境下打开必然乱码。 GBK、GB2312、GB18030 等与UTF8之间都必须通过Unicode编码才能相互转换。","categories":[{"name":"编码","slug":"编码","permalink":"http://example.com/categories/%E7%BC%96%E7%A0%81/"}],"tags":[{"name":"ASCII","slug":"ASCII","permalink":"http://example.com/tags/ASCII/"},{"name":"Unicode","slug":"Unicode","permalink":"http://example.com/tags/Unicode/"},{"name":"UTF-8","slug":"UTF-8","permalink":"http://example.com/tags/UTF-8/"}]},{"title":"【正则表达式】笔记","slug":"【正则表达式】笔记","date":"2024-09-15T07:30:10.000Z","updated":"2024-09-17T04:13:26.765Z","comments":true,"path":"2024/09/15/【正则表达式】笔记/","permalink":"http://example.com/2024/09/15/%E3%80%90%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E3%80%91%E7%AC%94%E8%AE%B0/","excerpt":"","text":"基础正则表达式速查表、正则可视化工具、常用正则 ^$表示匹配从^到$ 之间的内容，即 ^123$ 必须完全匹配123。1234567正则：123输入内容：123 （匹配）输入内容：12345 （匹配）正则：^123$ 输入内容：123 （匹配）输入内容：12345 （不匹配） 范围：[] 、{} 、() []约束内容。整个[]内只匹配一个字符[abc123] 代表可以是 abc123中的 一个[a-zA-Z] 代表可以是任意一个字母； 1[^： []内的^表示取反, [^a-zA-Z] 指不可以是字母 {}约束数量。单独[]只匹配一个字符，所以{}表示修饰[]里内容的个数。123[a-zA-Z]&#123;3&#125; 指3个字母[a-zA-Z]&#123;3,5&#125; 指可以是3至5个[a-zA-Z]&#123;3,&#125; 指3至无数个 三种特殊数量的简写： ? * + (?和都是对数量的约束，不指的是任意*内容)* ()表示组，一组内容视为一个整体，可以再对组做数量约束；还可用于对正则中一部分数据分组取出；分组的目的还可以重复应用，即后面内容必须和前面相等 字符 \\d匹配任何数字 等同于0-9 ；\\D 就是\\d取反，等同^\\d 不匹配任何字符 \\w包括字母、数字、或下划线_ \\s代表 [\\r \\n \\t \\f \\v ]回车符、翻页符、空格等； \\S 就是\\s取反，等同^\\s 不匹配上述符号 .点表示可以匹配任意字符(除了换行) .{2,5} 匹配2至5个任意字符 数量 ?表示某个内容出现0至1次，等同于 {0,1} *表示某个内容出现0至无穷次，等同于{0,} +表示某个内容出现 1至无穷次，等同于{1,} 其他 \\表示转义, 如.表示任意字符，但.表示必须匹配.这个字符 举例：匹配是字符或数字开头的163邮箱 1^[a-zA-Z0-9]\\w+@163\\.com$ |表示 或 （）分组 () 表示组，一组是一个整体 可用于对正则中一部分数据分组取出；12^([a-zA-Z0-9]\\w+)@163\\.com$ 小括号里的内容会被匹配为一个组，多个组时是按索引(从1开始)，当组数量太多时不方便。^(?&lt;first&gt;[a-zA-Z0-9]\\w+)@163\\.com%$ 将邮箱@前内容取出并将分组命名为first 分组的内容，可以再被后续引用： \\k&lt; first&gt; 如匹配1212这样交替重复重现的数字： 123^\\d\\d\\d\\d$ 表示四位数字，但没有限制后两位必须于前两位相同^(\\d\\d)\\1$ \\1表示后面的内容引用前面的第一个分组 所以表示第三四位要等于第一二位^(?&lt;first&gt;\\d\\d)\\k&lt;first&gt;$ 等同于^(\\d\\d)\\1$ ,在对组取名称情况下，用\\k&lt;&gt;引用 匹配某个规则的内容，并且这个内容还要在特定字符的 前&#x2F;后，或不能出现在特定字符的 前&#x2F;后 如对于文本：foobar，fooboo。 只期望找到foobar里的foo。 12foo(?=bar)如果直接使用foobar做正则，匹配出来的是 foobar整个，foo(?=bar)匹配出来的是foo，这对于取值很关键。 要求在指定特定内容之前 12(?=str) 匹配并取出内容，且内容还要在str前的才可匹配 如:cdx(?=ohh) ，匹配cdxohh，不匹配cdxokk(?!str) 匹配并取出内容，且内容不能在str前的才可匹配 如:cdx(?!ohh) ，不匹配cdxohh，却匹配除ohh外任意字符 要求在指定特定内容之后 12(?&lt;=str) 匹配并取出内容，且内容还要在str后的才可匹配 如: cdx(?&lt;=ohh) ，匹配 ohhcdx(?&lt;!str) 匹配并取出内容，且内容不能在str后的才可匹配 如: cdx(?&lt;!ohh) ，不匹配 ohhcdx，却匹配除ohh外任意字符 最佳实践：匹配 “滔滔不绝”这样aabc格式的内容，要求前两位相同，但第三、四位不与前两位相同，且第三、四位互不相同。123456思路：^....$ ： 所有四位成语能匹配^(?&lt;A&gt;.)\\k&lt;A&gt;..$ : 满足要求前两位相同^(?&lt;A&gt;.)\\k&lt;A&gt;(?!\\k&lt;A&gt;)..$ ：满足要求前两位相同，同时要求第二位后不能是和自己相同的内容（即要求了第三位不再是\\k&lt;A&gt;）^(?&lt;A&gt;.)\\k&lt;A&gt;(?!\\k&lt;A&gt;)(?&lt;B&gt;.)(?!\\k&lt;B&gt;).$ : 满足要求第三位后不能是和自己相同的内容 （即要求了第四位不再是\\k&lt;B&gt;）^(?&lt;A&gt;.)\\k&lt;A&gt;(?!\\k&lt;A&gt;)(?&lt;B&gt;.)(?!\\k&lt;B&gt;|\\k&lt;A&gt;).$：要求第三位后不能是 和自己相同或与A相同 （即要求了第四位也不能是\\k&lt;A&gt;） 分组取出java 12345678910111213String content = &quot;请从以下段落中提取满足json格式的内容：&#123;\\&quot;name\\&quot;:\\&quot;Revali\\&quot;,\\&quot;age\\&quot;:\\&quot;25\\&quot;&#125;\\n&#123;\\&quot;name\\&quot;:\\&quot;Mipha\\&quot;,\\&quot;age\\&quot;:\\&quot;1000\\&quot;&#125;&quot;;// 取出以&#123;开头（包含&#123;），以&#125;结尾（包含&#125;），并且中间不含&#125;的内容String regex = &quot;[&#123;](?&lt;=[&#123;])[^&#125;]+(?=[&#125;])[&#125;]&quot;;Pattern pattern = Pattern.compile(regex);Matcher matcher = Pattern.matcher(content);List&lt;JSONObject&gt; jsonList = new ArrayList&lt;&gt;();while(matcher.find()) &#123; String json = matcher.group(); JSONObject jsonObject = JSONObject.parseObject(json); jsonList.add(jsonObject);&#125; python 12345678910111213# _*_ coding: utf-8 _*_import reimport jsoncontent = &#x27;请从以下段落中提取json格式的关键内容：&#123;&quot;name&quot;:&quot;Revali&quot;,&quot;age&quot;:&quot;25&quot;&#125;\\n&#123;&quot;name&quot;:&quot;Mipha&quot;,&quot;age&quot;:&quot;100&quot;&#125;&#x27;json_list = re.findall(r&quot;[&#123;](?&lt;=[&#123;])[^&#125;]+(?=[&#125;])[&#125;]&quot;, content)for json_row in json_list: json_data = json.load(json_row) print(json_data[&#x27;name&#x27;]) print(json_data[&#x27;age&#x27;])","categories":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://example.com/categories/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}],"tags":[],"author":"昱东"},{"title":"吉他&乐理","slug":"吉他&乐理","date":"2024-09-15T07:30:10.000Z","updated":"2024-09-17T04:17:38.748Z","comments":true,"path":"2024/09/15/吉他&乐理/","permalink":"http://example.com/2024/09/15/%E5%90%89%E4%BB%96&%E4%B9%90%E7%90%86/","excerpt":"","text":"十二平均律 全全半全全全半 1234Do Re Mi Fa SoI La Si Do --唱名1 2 3 4 5 6 7 1 全 全 半 全 全 全 半 --音程（间隔）C D E F G A B C --音名 琴弦的顺序是 1234567 弦 音名 唱名 1 E 3 Mi由 2 B 7 Si细 3 G 5 Sol到 4 D 2 Re粗 5 A 6 La 6 E 3 Mi 左手可以在每弦上找到完整的Do Re Mi Fa SoI La Si Do ： 先根据空弦音按音程：全全半全全全半，找到Do ，按音程找到完整的Do Re Mi Fa SoI La Si Do。 如：5弦空弦(0品)音为A，则5弦2品(全)为B，5弦3品为C(半)，C就是Do，即从3品开始按“全全半全全全半”。 根据每根弦空弦音+”全全半全全全半”能得到音阶图： 六线谱 也是对应琴弦的顺序，由横线代表每一根弦。 数字标在哪一根弦号上，代表弹响哪一根，数字的大小代表品数。 总结：标在哪根弦就弹哪根，标的数字是几就弹几品： 和弦图 和弦图是 竖线代表每一根弦，从左到右654321弦。（粗到细） 横线代表品数，从上到下123品；而A和弦图左侧的5代表：是从5品开始，用到567品。 1234T数字代表手指，T-大拇指，1234食指从到小指。只是指法。 竖线上的××○: ×代表不要弹这根，会与和弦极不和谐。 ○ 代表弹空弦。 调音调音器就是根据震动频率找到每一根琴弦的空弦音：EBGDAE 如果已经确定部分琴弦音高是准确的前提下，可以通过琴弦之间的共振来调整剩下的不准确的弦 如：6弦的音名是E(空弦)，则6弦1品是F，6弦3品是G，6弦5品是A，而5弦的空弦也是A，则他们会共振。 55545：1234566弦 5品 与 5弦空弦 音高相同 --6弦空弦是E，则6弦1品是F，6弦3品是G，6弦5品是A，而5弦的空弦也是A，则他们会共振5弦 5品 与 4弦空弦 音高相同 --5弦空弦是A，则5弦2品是B，5弦3品是C，5弦5品是D，而4弦的空弦也是D，则他们会共振4弦 5品 与 3弦空弦 音高相同 --4弦空弦是D，则4弦2品是E，4弦3品是F，4弦5品是G，而3弦的空弦也是G，则他们会共振3弦 4品 与 2弦空弦 音高相同 --3弦空弦是G， 则3弦2品是A，3弦4品是B，而2弦的空弦也是B，则他们会共振2弦 5品 与 1弦空弦 音高相同 --2弦空弦是B，则2弦1品是C，2弦3品是D，2弦5品是E，而1弦的空弦也是E，则他们会共振","categories":[{"name":"杂记","slug":"杂记","permalink":"http://example.com/categories/%E6%9D%82%E8%AE%B0/"}],"tags":[]},{"title":"磁盘阵列 RAID[0 1 5 10]","slug":"磁盘阵列 RAID[0 1 5 10]","date":"2024-09-15T07:30:10.000Z","updated":"2024-09-17T04:16:57.178Z","comments":true,"path":"2024/09/15/磁盘阵列 RAID[0 1 5 10]/","permalink":"http://example.com/2024/09/15/%E7%A3%81%E7%9B%98%E9%98%B5%E5%88%97%20RAID[0%201%205%2010]/","excerpt":"","text":"RAID （ Redundant Array of Independent Disks ）即独立磁盘冗余阵列，简称为「磁盘阵列」，用多个独立的磁盘组成一个大的磁盘系统，目的实现比单块磁盘更好的存储性能和更高的可靠性。 RAID方案常见的可以分为： RAID0 RAID1 RAID5 RAID6 RAID10 RAID0将数据分为N份，以独立并行实现N块磁盘的读写，那么这N份数据会同时并发的写到磁盘中，因此写数据性能非常的高。RAID0的问题是，它并不提供数据校验或冗余备份，因此一旦某块磁盘损坏了，其他磁盘的数据就不完整，导致全部数据直接丢失，无法恢复。 RAID1RAID1其实与RAID0效果刚好相反。 RAID1 写数据的时候，将同一份数据无差别分别写到工作磁盘和镜像磁盘，那么它的实际空间使用率只有50%了，两块磁盘当做一块用。空间利用率不高。 数据有一个冗余备份，读数据时太繁忙可从镜像盘读取，读性能也较好；假如任何一块磁盘损坏，还可以从另外一块磁盘恢复，数据的可靠性强。 RAID5RAID5之前，先了解一下不常用的RAID3：在RAID0前提下，增加第N块磁盘用记录校验码数据。当某块数据盘坏掉，可以可以利用其它的N-1块磁盘去恢复数据。第N块磁盘是校验码磁盘，任何数据的写入都会要去更新这块磁盘，导致这块磁盘的读写是最频繁的，也就非常的容易损坏。 RAID5中，不再单独设置校验码磁盘。而把校验码信息分布到各个磁盘上。RAID5的方式，最少需要三块磁盘来组建磁盘阵列，允许最多同时坏一块磁盘。如果有两块磁盘同时损坏了，那数据就无法恢复了。这是目前用的最多的一种方式。RAID5 将 存储性能、数据安全、存储成本 兼顾。 RAID6RAID6在RAID5的基础上再次改进，引入了双重校验的概念。在两块磁盘同时损坏时，也能恢复数据。RAID6除了每块磁盘上都有同级数据XOR校验区以外，还有每个数据块的XOR校验区，相当于每个数据块有两个校验保护，数据的冗余性更高。但是RAID6的设计也带来了很高的复杂度，虽然数据冗余性好，读取的效率也比较高，但是写数据的性能就很差。因此RAID6在实际中应用的比较少。（可用于仓库数据，读多写少时） RAID10RAID10其实就是RAID1与RAID0的一个合体。首先基于RAID1模式将磁盘分为2份，写数据的时候，将同一份数据无差别的写两份到磁盘。得到一个RAID1。再将这样的N个RAID1组RAID0，以独立并行实现这N个RAID1的读写。每个RAID1中都不是完整数据。RAID10也有一半磁盘空间用于存储冗余数据的，相比与RAID1性能有提升但利用率仍然不高。","categories":[{"name":"杂记","slug":"杂记","permalink":"http://example.com/categories/%E6%9D%82%E8%AE%B0/"}],"tags":[{"name":"磁盘RAID","slug":"磁盘RAID","permalink":"http://example.com/tags/%E7%A3%81%E7%9B%98RAID/"}],"author":"昱东"},{"title":"synchronized 同步方法和同步代码块，以及synchronized 加锁 this 和 类class 的区别","slug":"synchronized 同步方法和同步代码块，以及synchronized 加锁 this 和 类class 的区别","date":"2024-09-15T07:22:00.000Z","updated":"2024-09-15T07:22:00.000Z","comments":true,"path":"2024/09/15/synchronized 同步方法和同步代码块，以及synchronized 加锁 this 和 类class 的区别/","permalink":"http://example.com/2024/09/15/synchronized%20%E5%90%8C%E6%AD%A5%E6%96%B9%E6%B3%95%E5%92%8C%E5%90%8C%E6%AD%A5%E4%BB%A3%E7%A0%81%E5%9D%97%EF%BC%8C%E4%BB%A5%E5%8F%8Asynchronized%20%E5%8A%A0%E9%94%81%20this%20%E5%92%8C%20%E7%B1%BBclass%20%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"同步方法是对整个方法中所有内容加锁；同步代码块选择只同步部分代码而不是整个方法，比同步方法要更细颗粒度，也能选择加锁 this 和 类class，还可以是变量。 同步方法的锁用的是 这个方法所在的这个对象&#x2F;类上的内置锁。 同步代码块的锁用的是 synchronized()括号里参数对象上的锁。可以是 this、类.class、变量。要具体分析参与抢锁的对象是否持有相同的对象锁（也就是this、类.class、变量…是否同一个对象） 同步方法：即有synchronized 修饰的方法。 由于java的每个对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用给方法前，要获取内置锁，否则处于阻塞状态。（不同方法都是用对象上的同一个内置锁） 注意：synchronized修饰静态方法，如果调用该静态方法，将锁住整个类。 非静态方法示例1： 不同方法，都被synchronized 修饰，但不同方法获取的都是test1 对象上的同一个内置锁。 所以会出现争抢锁。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class SynchronizedTest_1 &#123; public synchronized void method_1()&#123; System.out.println(&quot;method_1 start.&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;method_1 end.&quot;); &#125; public synchronized void method_2()&#123; System.out.println(&quot;method_2 start.&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;method_2 end.&quot;); &#125; public static void main(String[] args) &#123; SynchronizedTest_1 test1 = new SynchronizedTest_1(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_2(); // 当然这里也test1.method_1()的话也会抢锁 &#125; &#125;).start(); &#125;&#125; 输出结果：（现象：线程1执行结束后释放，线程2才获取到锁。） 1234method_1 start.method_1 end.method_2 start.method_2 end. 示例2：对比示例1，这次创建了两个对象test1、test2 ，分别在两个线程中使用。不存在抢锁，因为是两个不同对象，分别获取了自己的内置锁。 1234567891011121314151617181920public static void main(String[] args) &#123; SynchronizedTest_1 test1 = new SynchronizedTest_1(); SynchronizedTest_1 test2 = new SynchronizedTest_1(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test2.method_2(); &#125; &#125;).start(); &#125; 输出结果： 1234method_1 start.method_2 start.method_2 end.method_1 end. 静态方法 （全局锁）示例3：静态方法，被synchronized 修饰。但是创建了两个对象test1、test2 ，分别在两个线程中使用。会出现争抢锁。因为是针对类级别的锁，不同对象也会持有同一个内置锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SynchronizedTest_2 &#123; public static synchronized void method_1()&#123; System.out.println(&quot;method_1 start.&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;method_1 end.&quot;); &#125; public static synchronized void method_2()&#123; System.out.println(&quot;method_2 start.&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;method_2 end.&quot;); &#125; public static void main(String[] args) &#123; SynchronizedTest_2 test1 = new SynchronizedTest_2(); SynchronizedTest_2 test2 = new SynchronizedTest_2(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; // test2.method_1(); // 都调用method_1当然也会抢锁 test2.method_2(); &#125; &#125;).start(); &#125;&#125; 输出结果： 1234method_1 start.method_1 end.method_2 start.method_2 end. 同步代码块：探讨：synchronized 加锁 this 和 类.class 的区别；以及加锁变量、其他类对象的区别。 this示例4： synchronized 加锁 this 当前对象，两个线程中的test1是同一个对象， 会出现抢锁。 12345678910111213141516171819202122232425262728293031323334353637383940public class SynchronizedTest_3 &#123; public void method_1()&#123; System.out.println(&quot;method_1 stand by.&quot;); long start = System.currentTimeMillis(); synchronized (this) &#123; try &#123; System.out.printf(&quot;method_1 start... 【wait:%s】\\n&quot;, System.currentTimeMillis() - start); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;method_1 end.&quot;); &#125; public static void main(String[] args) &#123; SynchronizedTest_3 test1 = new SynchronizedTest_3(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(); &#125; &#125;).start(); &#125;&#125; 输出结果： 123456method_1 stand by.method_1 stand by.method_1 start... 【wait:0】method_1 end.method_1 start... 【wait:2014】method_1 end. 或 123456method_1 stand by.method_1 start... 【wait:0】method_1 stand by.method_1 end.method_1 start... 【wait:2014】method_1 end. 示例5： 对比示例4，这次创建了两个对象test1、test2 ，分别在两个线程中使用。不存在抢锁，因为是两个不同对象，但synchronized 是对两个对象各自的锁。 12345678910111213141516171819202122public static void main(String[] args) &#123; SynchronizedTest_3 test1 = new SynchronizedTest_3(); SynchronizedTest_3 test2 = new SynchronizedTest_3(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test2.method_1(); &#125; &#125;).start(); &#125; 输出结果： 123456method_1 stand by.method_1 stand by.method_1 start... 【wait:0】method_1 start... 【wait:0】method_1 end.method_1 end. 类.class （全局锁）示例6：会抢锁，synchronized 是类加锁，不同对象都拿到同一个Class对象，即也会持有同一个锁。 1234567891011121314151617181920212223242526272829303132333435363738public class SynchronizedTest_4 &#123; public void method_1()&#123; System.out.println(&quot;method_1 stand by.&quot;); long start = System.currentTimeMillis(); synchronized (SynchronizedTest_4.class) &#123; try &#123; System.out.printf(&quot;method_1 start... 【wait:%s】\\n&quot;, System.currentTimeMillis() - start); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;method_1 end.&quot;); &#125; public static void main(String[] args) &#123; SynchronizedTest_4 test1 = new SynchronizedTest_4(); SynchronizedTest_4 test2 = new SynchronizedTest_4(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test2.method_1(); &#125; &#125;).start(); &#125;&#125; 输出结果： 123456method_1 stand by.method_1 stand by.method_1 start... 【wait:0】method_1 end.method_1 start... 【wait:2023】method_1 end. 这里的类不管是相关还是不相关的类，如：Object.class，不同的对象都只会拿到相同的Object.class，所以一定是同一把锁。 123synchronized (Object.class) &#123; // ....&#125; 同步代码块使用 类.class加锁，是全局锁。不关心这个类本身。 方法变量示例7：对变量加锁，如果传到方法里变量是同一个变量对象，那么就会出现争抢锁。 123456789101112131415161718192021222324252627282930313233343536373839public class SynchronizedTest_6 &#123; public void method_1(Integer lockObject)&#123; System.out.println(&quot;method_1 stand by.&quot;); long start = System.currentTimeMillis(); synchronized (lockObject) &#123; try &#123; System.out.printf(&quot;method_1 start... 【wait:%s】\\n&quot;, System.currentTimeMillis() - start); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;method_1 end.&quot;); &#125; public static void main(String[] args) &#123; SynchronizedTest_6 test1 = new SynchronizedTest_6(); SynchronizedTest_6 test2 = new SynchronizedTest_6(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(1); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test2.method_1(1); &#125; &#125;).start(); &#125;&#125; 输出结果： 123456method_1 stand by.method_1 start... 【wait:0】method_1 stand by.method_1 end.method_1 start... 【wait:2001】method_1 end. 特别注意：Integer存在静态缓存，范围是 【-128 ~ 127】，当使用Integer A &#x3D; 127 或者 Integer A &#x3D; Integer.valueOf(127) 这样的形式，都是从此缓存拿。如果使用 Integer A &#x3D; new Integer(127)，每次都是一个新的对象。还有字符串常量池也要注意。 所以此处关注是，同步代码块传参的对象是否是同一个。 使用非缓存的值： 示例8： 123456789101112131415161718192021public static void main(String[] args) &#123; SynchronizedTest_6 test1 = new SynchronizedTest_6(); SynchronizedTest_6 test2 = new SynchronizedTest_6(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(128); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test2.method_1(128); &#125; &#125;).start(); &#125; 输出结果：因为128 不是从缓存里拿的，所以是两个不同的Integer 对象，不会抢锁。 123456method_1 stand by.method_1 stand by.method_1 start... 【wait:0】method_1 start... 【wait:0】method_1 end.method_1 end. 成员变量对成员变量加锁，就去判断每个对象拿到成员变量是否都是同一个。如test1 、test2两个对象，在创建时，也是分别创建不同object对象，那么这里不存在抢锁。 如果是public static Object lockObject &#x3D; new Object(); 又会抢锁。此时的object对象是随类加载完成的，所以对于test1 、test2两个对象是相同的对象，就会持有相同的锁。 示例9： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class SynchronizedTest_5 &#123; public Object lockObject = new Object(); // public static Object lockObject = new Object(); // 会抢锁。 示例10 // public Integer lockObject = 1; // 会抢锁。 示例11 // public Integer lockObject = 128; // 不会抢锁 public void method_1()&#123; System.out.println(&quot;method_1 stand by.&quot;); long start = System.currentTimeMillis(); synchronized (lockObject) &#123; try &#123; System.out.printf(&quot;method_1 start... 【wait:%s】\\n&quot;, System.currentTimeMillis() - start); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;method_1 end.&quot;); &#125; public static void main(String[] args) &#123; SynchronizedTest_5 test1 = new SynchronizedTest_5(); SynchronizedTest_5 test2 = new SynchronizedTest_5(); new Thread(new Runnable() &#123; @Override public void run() &#123; test1.method_1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test2.method_1(); &#125; &#125;).start(); &#125;&#125; 1234method_1 stand by.method_1 stand by.method_1 start... 【wait:0】method_1 start... 【wait:0】 示例10： 类变量以及在类加载时创建，后面不管new 多少对象，这里的lockObject 都时是同一个。 1public static Object lockObject = new Object(); 123456method_1 stand by.method_1 stand by.method_1 start... 【wait:0】method_1 end.method_1 start... 【wait:2027】method_1 end. 示例11： 1public Integer lockObject = 1; 虽然不是类变量，但是由于Integer的缓存，test1 、test2两个对象各获取一次lockObject &#x3D; 1时，拿到的也是同一个1。因此会出现抢锁。 123456method_1 stand by.method_1 stand by.method_1 start... 【wait:0】method_1 end.method_1 start... 【wait:2027】method_1 end. 示例12： 1public Integer lockObject = 128; 而128不在缓存中，test1 、test2两个对象各获取一次lockObject &#x3D; 128时，是不同的128对象。因此不会抢锁。 123456method_1 stand by.method_1 stand by.method_1 start... 【wait:0】method_1 start... 【wait:0】method_1 end.method_1 end.","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"juc","slug":"juc","permalink":"http://example.com/tags/juc/"}],"author":"昱东"},{"title":"多线程之wait、notify/notifyAll使用，并模拟生产/消费者模式","slug":"多线程之wait、notify-notifyAll使用，并模拟生产-消费者模式","date":"2024-09-15T07:20:00.000Z","updated":"2024-09-15T07:20:00.000Z","comments":true,"path":"2024/09/15/多线程之wait、notify-notifyAll使用，并模拟生产-消费者模式/","permalink":"http://example.com/2024/09/15/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8Bwait%E3%80%81notify-notifyAll%E4%BD%BF%E7%94%A8%EF%BC%8C%E5%B9%B6%E6%A8%A1%E6%8B%9F%E7%94%9F%E4%BA%A7-%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"要点总结：1、wait()、notify&#x2F;notifyAll() 方法是Object的本地final方法，无法被重写。 2、在当前线程拥有监视器锁的情况下使用，且wait()的对象和锁对象相同，否则将抛出异常IllegalMonitorStateException。一般在synchronized 同步代码块里使用 wait()、notify&#x2F;notifyAll() 方法。 3、wait() 使当前线程阻塞，并且会释放synchronized锁。被wait阻塞的线程，可以被notify&#x2F;notifyAll()唤醒，重新获取锁后，可以从上一次wait()处继续往下执行。 4、wait() 可以被中断，需要处理中断异常。如果捕获但不处理，即：e.printStackTrace();将会抛出异常到jvm并结束异常线程；如果处理了异常，将会从catch{}后继续往下执行。（”等待”状态被中断，就该就绪-运行状态了。） 5、notify() 可以唤醒一个受wait()阻塞的线程，唤醒哪一个，取决于系统，但被唤醒的线程还需要前提：能获取到synchronized锁才可以执行，因此当有多个线程wait住，使用notify() 可能出现死锁。 6、notifyAll() 可以唤醒全部受wait()阻塞的线程，被唤醒的线程还需要前提：能获取到synchronized锁才可以执行，因此notifyAll() 唤醒的线程并不是立刻都会被执行，能否执行、执行的顺序根据争抢锁的情况决定。 7、notify() &#x2F;notifyAll() 可以唤醒受wait()阻塞的线程，但notify() 不会释放synchronized锁，只有synchronized锁住的代码块都执行完才会释放，所以 notify()&#x2F;notifyAll() 一般写在代码块最后，唤醒后随即释放锁。 8、wait() 与notify()&#x2F;notifyAll() 在运行时有顺序要求，如果A线程先执行notify()&#x2F;notifyAll() 方法，B线程再执行wait方法，那么B线程是无法被唤醒的。所以使用notifyAll() 也可能出现死锁。 9、受wait()阻塞的线程被唤醒后，会从上一次wait()处继续往下执行。所以在利用共享变量进行条件判断时候，在阻塞与唤醒这期间，共享变量可能已经被其他线程修改过了，不一定再满足当前线程可执行条件，应该使用while循环判断而不是if。 wait状态的中断123456789101112131415161718192021222324Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (obj) &#123; try &#123; System.out.println(&quot;我要一直等待被唤醒...&quot;); obj.wait(); System.out.println(&quot;我被正常唤醒了...&quot;); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;我被打断了...&quot;); // e.printStackTrace(); &#125; System.out.println(&quot;我继续执行了...&quot;); &#125; &#125; &#125;); thread.start(); TimeUnit.SECONDS.sleep(1L); // 确保线程已经wait，再将他interrupt thread.interrupt(); 输出： 123我要一直等待被唤醒...我被打断了...我继续执行了... 1234567891011121314151617181920212223242526Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (obj) &#123; while (list.size() &lt;= 0) &#123; try &#123; System.out.println(&quot;我要一直等待被唤醒...&quot;); obj.wait(); System.out.println(&quot;我被正常唤醒了...&quot;); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;我被打断了...&quot;); // e.printStackTrace(); &#125; &#125; System.out.println(&quot;我继续执行了...&quot;); &#125; &#125; &#125;); thread.start(); TimeUnit.SECONDS.sleep(1L); // 确保线程已经wait，再将他interrupt thread.interrupt(); 输出： 1234我要一直等待被唤醒...我被打断了...我要一直等待被唤醒... | ----（被下一次循环wait住） 生产&#x2F;消费者模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 生产者线程Thread a = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (obj) &#123; while (list.size() &gt;= 10) &#123; // 有10个待消费的消息就暂停生产 try &#123; obj.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; list.add(&quot;A&quot;); System.out.println(&quot;生产者A 生产了一个消息....&quot;); obj.notifyAll(); &#125; &#125;&#125;, &quot;生产者A&quot;);// 消费者线程Thread c = new Thread(new Runnable() &#123; @Override public void run() &#123; while (true) &#123; // 循环是让消费者可以一直收消息 --方便测试用 synchronized (obj) &#123; while (list.size() &lt;= 0) &#123; try &#123; obj.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; String msg = list.removeFirst(); System.out.println(&quot;消费者C 消费了一个消息....&quot; + msg); obj.notifyAll(); &#125; &#125; &#125;&#125;, &quot;消费者C&quot;);c.start();TimeUnit.SECONDS.sleep(1L);a.start(); 输出： 12生产者A 生产了一个消息....消费者C 消费了一个消息....A","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"juc","slug":"juc","permalink":"http://example.com/tags/juc/"}],"author":"昱东"},{"title":"@Autowired和@Resource区别，简单测试容器中多个相同bean的情况","slug":"Autowired和Resource区别，简单测试容器中多个相同bean的情况","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/Autowired和Resource区别，简单测试容器中多个相同bean的情况/","permalink":"http://example.com/2024/09/15/Autowired%E5%92%8CResource%E5%8C%BA%E5%88%AB%EF%BC%8C%E7%AE%80%E5%8D%95%E6%B5%8B%E8%AF%95%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%A4%9A%E4%B8%AA%E7%9B%B8%E5%90%8Cbean%E7%9A%84%E6%83%85%E5%86%B5/","excerpt":"","text":"@Autowired 和 @Resource 区别 @Autowired 来自Spring， @Resource 来自java； @Autowired 默认按类型注入，容器中存在多个相同类型的 Bean，将抛出异常。 可以配合使用 @Qualifier 指定名称。 两个相同类型（都 implements Formatter）的 Bean： 123456@Component(&quot;fooFormatter&quot;)public class FooFormatter implements Formatter &#123; public String format() &#123; return &quot;foo&quot;; &#125;&#125; 123456@Component(&quot;barFormatter&quot;)public class BarFormatter implements Formatter &#123; public String format() &#123; return &quot;bar&quot;; &#125;&#125; 直接使用 @Autowired：容器启动失败： Field formatter in com.example.SpringInitialzrDemo.autowired.FooService required a single bean, but 2 were found 1234public class FooService &#123; @Autowired private Formatter formatter; // 容器启动失败： Field formatter in com.example.SpringInitialzrDemo.autowired.FooService required a single bean, but 2 were found&#125; 使用 @Autowired + @Qualifie：容器启动成功 123@Autowired@Qualifier(&quot;barFormatter&quot;)private Formatter formatter; @Resource 可以根据名称，可以根据类型。 针对上面两个相同类型的 Bean，就可以使用12@Resource(name = &quot;barFormatter&quot;) private Formatter formatter; 或：12@Resource(type = FooFormatter.class) private Formatter formatter; @Autowired 和 @Resource 的参数 @Autowired 只有一个参数 required @Autowired 里的参数 required &#x3D; true (默认) 的用途：启动容器时会校验这个Bean在容器中是否存在，不存在会阻止项目启动，并报错： 1FooService required a bean of type &#x27;xxx&#x27; that could not be found 如果使用 @Autowired(required &#x3D; false) ，则不影响项目的启动。 当然，后续使用到还是会空指针。 @Resource 参数有多个，主要就使用name 和 type，分别指定名称和类型。 向容器注入多个相同名称的bean使用@Component的方式:12public interface BeanService &#123;&#125; 123@Component(&quot;beanService&quot;)public class OneServiceImpl implements BeanService&#123;&#125; 123@Component(&quot;beanService&quot;)public class TwoServiceImpl implements BeanService&#123;&#125; 启动时报错： BeanDefinitionStoreException： 1Annotation-specified bean name &#x27;beanService&#x27; for bean class [com.example.bean.TwoServiceImpl] conflicts with existing, non-compatible bean definition of same name and class [com.example.bean.OneServiceImpl] 上诉bean有相同name且有相同类型（都是BeanService类型)， 如果时不相同的类型呢： 123@Component(&quot;beanService&quot;)public class OneServiceImpl &#123;&#125; 123@Component(&quot;beanService&quot;)public class TwoServiceImpl &#123;&#125; 启动时还是报错：BeanDefinitionStoreException。 总结：使用@Component就是不能注入同名bean的，会在容器启动时就报错，且不受类型影响。使用 @Bean方式取消@Component注解，并使用一个Appfig类来注入： 123456789101112131415161718@Configurationpublic class AppConfig &#123; @Bean(&quot;beanService&quot;) public BeanService oneServiceImpl() &#123; return new OneServiceImpl(); &#125; @Bean(&quot;beanService&quot;) public BeanService twoServiceImpl() &#123; return new TwoServiceImpl(); &#125; @Bean(&quot;beanService&quot;) public BeanService threeServiceImpl() &#123; return new ThreeServiceImpl(); &#125;&#125; @Bean注入三个bean，且名称都叫beanService。 启动容器没有报错。 在测试类中，使用 @Autowired注入BeanService 12@Autowiredprivate BeanService beanService; 并输出bean实际类型：12Class&lt;? extends BeanService&gt; aClass = beanService.getClass();System.out.println(aClass.getName()); // com.example.SpringInitialzrDemo.bean.OneServiceImpl 输出了OneServiceImpl，那么容器中到底有几个bean呢？ 使用 applicationContext.getBeanDefinitionNames() 查看，只有一个 “beanService”。 在测试类中，使用 @Resource注入BeanService，并强制指定类型为 TwoServiceImpl.class12@Resource(type = TwoServiceImpl.class)private BeanService beanService; 结果报错：1BeanNotOfRequiredTypeException: Bean named &#x27;beanService&#x27; is expected to be of type &#x27;com.example.SpringInitialzrDemo.bean.TwoServiceImpl&#x27; but was actually of type &#x27;com.example.SpringInitialzrDemo.bean.OneServiceImpl&#x27; 容器里是没有TwoServiceImpl， 是因为没有注入，还是被覆盖了？ 继续测试，增加输出： 123456789101112131415161718192021@Configurationpublic class AppConfig &#123; @Bean(&quot;beanService&quot;) public BeanService oneServiceImpl() &#123; System.out.println(&quot;我要注入：OneServiceImpl&quot;); return new OneServiceImpl(); &#125; @Bean(&quot;beanService&quot;) public BeanService twoServiceImpl() &#123; System.out.println(&quot;我要注入：TwoServiceImpl&quot;); return new TwoServiceImpl(); &#125; @Bean(&quot;beanService&quot;) public BeanService threeServiceImpl() &#123; System.out.println(&quot;我要注入：ThreeServiceImpl&quot;); return new ThreeServiceImpl(); &#125;&#125; 结果：只输出了 “我要注入：OneServiceImpl”。 总结：使用 @Configuration + @Bean 的方式，注入多个同名bean，容器正常启动，但实际只有第一个被成功注入。即便使用 @Primary 指定第二个优先。实际上还是注入的OneServiceImpl。（说明@Primary不是这么用的） 123456@Bean(&quot;beanService&quot;)@Primarypublic BeanService twoServiceImpl() &#123; System.out.println(&quot;我要注入：TwoServiceImpl&quot;); return new TwoServiceImpl();&#125; @Import的方式就暂不做测试了 上述例子是以注入多个相同名称不同类型的bean，接下来 测试注入多个相同类型的bean。 向容器注入多个相同类型的bean123456789101112131415161718192021@Configurationpublic class AppConfig &#123; @Bean public BeanService oneServiceImpl() &#123; System.out.println(&quot;我要注入：OneServiceImpl&quot;); return new BeanService(); &#125; @Bean public BeanService twoServiceImpl() &#123; System.out.println(&quot;我要注入：TwoServiceImpl&quot;); return new BeanService(); &#125; @Bean public BeanService threeServiceImpl() &#123; System.out.println(&quot;我要注入：ThreeServiceImpl&quot;); return new BeanService(); &#125;&#125; 使用@Autowired 12@Autowiredprivate BeanService beanService; 容器无法启动: 1Field beanService in ___ required a single bean, but 3 were found 使用 @Resource 12@Resourceprivate BeanService beanService; 容器无法启动: 1BeanCreationException：No qualifying bean of type &#x27;com.example.SpringInitialzrDemo.bean2.BeanService&#x27; available: expected single matching bean but found 3 使用 @Autowired + @Qualifier 并指定bean名称 123@Autowired@Qualifier(&quot;oneServiceImpl&quot;)private BeanService beanService; 容器可以正常启动。 使用 @Resource(name &#x3D; “twoServiceImpl”) 12@Resource(name = &quot;twoServiceImpl&quot;)private BeanService beanService; 容器可以正常启动。 使用@Primary 12345678910111213141516171819202122@Configurationpublic class AppConfig &#123; @Bean public BeanService oneServiceImpl() &#123; System.out.println(&quot;我要注入：OneServiceImpl&quot;); return new BeanService(); &#125; @Bean @Primary public BeanService twoServiceImpl() &#123; System.out.println(&quot;我要注入：TwoServiceImpl&quot;); return new BeanService(); &#125; @Bean public BeanService threeServiceImpl() &#123; System.out.println(&quot;我要注入：ThreeServiceImpl&quot;); return new BeanService(); &#125;&#125; 这样，使用 @Autowired 或@Resource 时不指定名称，就会默认使用@Primary的这个bean，容器也可以正常启动。 12@Resourceprivate BeanService beanService; 总结：使用 @Configuration + @Bean 相同类型但是不同名称bean时，这些同类型的bean都能被创建，但必须在注入时指定bean名称，或使用@Primary标识其中一个bean的优先级。验证，输出所有的bean： 12345ConfigurableApplicationContext applicationContext = SpringApplication.run(SpringInitialzrDemoApplication.class, args);String[] names = applicationContext.getBeanDefinitionNames();for (String name : names) &#123; System.out.println(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&quot; + name);&#125; 结果：会找到三个bean确实都是成功创建. 123&gt;&gt;&gt;&gt;&gt;&gt;oneServiceImpl&gt;&gt;&gt;&gt;&gt;&gt;twoServiceImpl&gt;&gt;&gt;&gt;&gt;&gt;threeServiceImpl","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"author":"昱东"},{"title":"HDFS常用命令","slug":"HDFS常用命令","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/HDFS常用命令/","permalink":"http://example.com/2024/09/15/HDFS%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"HDFS常用命令hdfs 命令最常用的就是： hdfs dfs -[linux的命令] 通过查看Hadoop的命令 与 hdfs 的命令并不相同，且不存在包含关系。仅仅是 hadoop fs 与 hdfs dfs 可以等价。 hadoop 常用命令查看hadoop 命令所有参数： 1hadoop 12345hadoop checknative // 检查当前版本hadoop内库支持哪些压缩。如果是false，则需要自己编译支持此压缩。如果使用CDH则都支持。hadoop classpath // 打印当前hadoop的环境hadoop jar // 等价于 yarn jar ，提交jar 包到yarn hdfs 常用命令查看hdfs 命令所有参数： 1hdfs hdfs dfsadmin 1234567891011hdfs dfsadmin -report // 报告当前集群的情况hdfs dfsadmin -safemode // 安全模式。hdfs dfsadmin -safemode leave // leave代表关闭，安全模式关闭才是读写正常的。hdfs dfsadmin -safemode enter // 进入安全模式。如正在做集群维护时，就可以手动进入安全模式，维护完再离开&gt;Safemode is On // 安全模式下，能读不能写// hdfs dfsadmin 还有其他很多参数 hdfs fsck 1hdfs fsck // 对hdfs 做检查。如发现 Target Replicas is 3 but 1 live replica(s) 代表有副本丢失。文件权限后的数据就代表当前文件本来需有多少副本 平衡 123456789// hdfs balancer // 集群平衡。DN1 与 DN2 间节点平衡。封装到脚本，每天晚上定执行hdfs balancer -policy datanode -threshold 10 // 让 每个节点磁盘使用率，减去平均磁盘使用率 &lt; 10%// hdfs diskbalancer // 磁盘平衡。DN1中 多块磁盘的平衡。需要确保参数dfs.disk.balancer.enabled=true执行命令: 先生成计划 再执行 hdfs diskbalancer -plan ruozedata001 // 生产后会创建一个同名.plan.json文件，执行它hdfs diskbalancer -execute ruozedata001.plan.json 回收站 123456789101112linux 没有回收站，可以自己搞思路:准备脚本，rm 改mv，移动到指定的目录,很多参考。hdfs 是有回收站的有参数控制是否启用:fs.trash.interval // 回收站保留时间min，如果为0，代表不启用回收站功能&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;10080&lt;/value&gt; &lt;/property&gt; 开启后的删除操作就会移动 hdfs dfs -lshadoop fs -ls 是在 &#x2F;user&#x2F;liqiang ; hadoop fs -ls &#x2F; 是在根目录 hdfs dfs -ls # 列出工作主目录-用户名路径下的内容 hdfs dfs -ls / # 列出hdfs 根目录下的内容 hdfs dfs -mkdir# path可以是绝对路径，也可以是相对路径。 hdfs dfs -mkdir [-p] &lt;path&gt; hdfs dfs -mkdir tmp # 在hdfs文件系统中/user/liqiang 目录下创建tmp目录 hdfs dfs -mkdir ./tmp # hdfs dfs -mkdir /tmp # 在hdfs文件系统的根目录下创建一个tmp目录 hdfs dfs -rm -r -fhdfs dfs -rm [-r] [-f] &lt;uri&gt; # 删除目录或文件，-r -f不能组合成-rf hdfs dfs -rm -r -f /test # 删除根目录下的test目录 hdfs dfs -rmdir /test # 删除目录：只能删除空目录 hdfs dfs -appendToFile# appendToFile命令既可以将一个或多个文件添加到HDFS中，也可以将流中的数据读取到HDFS中。最终都是在hdfs中生成一个文件。 hdfs dfs -appendToFile &lt;localSrc&gt; &lt;dst&gt; # 将本地文件exp.log上传到hdfs中/user/liqiang/tmp目录，并重命名为：exception.log hdfs dfs -appendToFile ./exp.log ./tmp/exception.log # 将本地的test目录传到hdfs中，重命名为tst文件【注意这里并不是目录】。 hdfs dfs -appendToFile ./test ./tst hdfs dfs -cathdfs dfs -cat &lt;URI&gt; # 查看/user/liqiang/tmp/exception.log 文件内容 hdfs dfs -cat ./tmp/exception.log hdfs dfs -texthdfs dfs -text # 查看文件内容，支持压缩文件的查看而不会乱码 hdfs dfs -text ./tmp/exception.log hdfs dfs -find# 从根目录下精确搜索exception.log文件 hdfs dfs -find / -name exception.log # 从/user/liqiang目录下搜索名称中包含ex字符串的文件 hdfs dfs -find /user/liqiang -name &#39;*ex*&#39; hdfs dfs -put从本地文件系统拷贝文件到hdfs中。 hdfs dfs -put [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] [ - | &lt;localsrc1&gt; .. ]. &lt;dst&gt; # -f 如果已存在就覆盖 # -p 递归拷贝 hdfs dfs -put head.png tmp/head.png # 拷贝文件 hdfs dfs -put txt/ tmp/txt # 将目录txt拷贝到hdfs中的/user/liqiang/tmp/txt hdfs dfs -get从hdfs中下载文件到本地文件系统中。 hdfs dfs -get [-ignorecrc] [-crc] [-p] [-f] &lt;src&gt; &lt;localdst&gt; # -p 保留访问权限 修改时间等信息 # -f 如果目标文件已存在，直接覆盖。 hdfs dfs -get ./tmp ./hdfs-temp-dic # 将hdfs中的tmp目录下载到本地并重命名 hdfs dfs -cphdfs dfs -cp [-f] [-p | -p[topax]] URI [URI ...] &lt;dest&gt; # -f 如果存在，直接覆盖。 hdfs dfs -cp /user/hadoop/file1 /user/hadoop/file2 hdfs dfs -cp /user/hadoop/file1 /user/hadoop/file2 /user/hadoop/dir hdfs dfs -cp tmp ./temp # 将tmp拷贝并重命名为temp hdfs dfs -count统计目录下文件夹数量 文件数量 目录下文件总字节数。 hadoop fs -count [-q] [-h] [-v] [-x] [-t [&lt;storage type&gt;]] [-u] [-e] [-s] &lt;paths&gt;\\ hdfs dfs -count /user/test # 对/user/test 目录进行统计 结果每列含义：目录数 文件数 总大小（字节） 目录名称 hdfs dfs -mvhdfs dfs -mv URI [URI ...] &lt;dest&gt; # mv命令只能在hdfs文件系统中使用，不能跨系统。 hdfs dfs -mv tmp /tmp_home hdfs dfs -chmodhdfs dfs -chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; URI [URI ...] # -R 递归目录授权 hdfs dfs -chmod 700 temp # 给temp目录授权700~ hdfs dfs -chownhdfs dfs -chown [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; URI [URI ...] hdfs dfs -chown liqiang:liqiang temp # 更文件改用户组 hdfs dfs -tailhadoop fs -tail [-f] URI # 输出文件的末尾输出到控制台 # -f 动态输出 hdfs dfs -touchhdfs dfs -touch [-a] [-m] [-t TIMESTAMP] [-c] URI [URI ...] hdfs dfs -touchzhdfs dfs -touchz URI [URI ...] # 创建一个长度为0的文件","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hadoop","slug":"大数据/Hadoop","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"}],"author":"昱东"},{"title":"MySQL部署[CentOS7.2]","slug":"MySQL部署-CentOS7-2","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/MySQL部署-CentOS7-2/","permalink":"http://example.com/2024/09/15/MySQL%E9%83%A8%E7%BD%B2-CentOS7-2/","excerpt":"","text":"总结在前 设置mysql 跟随mysqladmin用户切换启动 su - mysqladmin -c &quot;/etc/init.d/mysql start --federated&quot; 解决切换用户丢失样式 cp /etc/skel/.* /usr/local/mysql 设置mysql允许外界以什么ip什么用户密码来访问 mysql&gt;grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;密码&#39;; mysql&gt;flush privileges; 修改登录mysql的密码 mysql&gt;update user set password=password(&#39;密码&#39;) where user = &#39;root&#39;; 查看当前mysql 版本 mysql -uroot -p 【登录的时候会显示版本号】 msyql&gt; select version() ; mysql&gt; \\s 【能显示当前database的详细信息】 MySql 部署准备 查看一下有没有其他的rpm包 [root@localhost ~]# rpm -qa|grep -i mysql 查看服务器是否已有MySql进程 [root@localhost ~]# ps -ef|grep mysqld root 2252 2234 0 19:55 pts/0 00:00:00 grep --color=auto mysqld 【代表还没有mysql】 完成部署后的样子： [mysqladmin@localhost etc]$ ps -ef|grep mysqld mysqlad+ 2697 1 0 01:05 ? 00:00:00 /bin/sh /usr/local/mysql/bin/mysqld_safe --datadir=/usr/local/mysql/data --pid-file=/usr/local/mysql/data/hostname.pid --federated mysqlad+ 3381 2697 1 01:05 ? 00:00:01 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data 【数据目录】 --plugin-dir=/usr/local/mysql/lib/plugin --federated --log-error=/usr/local/mysql/data/hostname.err 【启动时的错误日志】 --pid-file=/usr/local/mysql/data/hostname.pid 【存放进程号即3381】 --socket=/usr/local/mysql/data/mysql.sock 【socket目录】 --port=3306 【当前启动在3306端口号】 mysqlad+ 4118 3407 0 01:07 pts/0 00:00:00 grep --color=auto mysqld 准备安装包[root@localhost ~]# cd /usr/local 【按推荐安装在此目录下】 [root@localhost local]# rz -p 【或使用xftp 从windows上传mysql压缩包 到 /usr/local】 【rz -p 需要：yum install lrzsz】 将tar.gz 包解压缩 tar zxvf mysql-5.6.23-linux-glibc2.5-x86_64.tar.gz // 解压在当前目录生成文件夹 重命名 [不建议] mv mysql-5.6.23-linux-glibc2.5-x86_64.tar.gz mysql 软连接代替重命名 ln -s mysql-5.6.23-linux-glibc2.5-x86_64.tar.gz mysql // 软连接 mysql是一个快捷方式 环境变量 vi .bashrc 【增加：】 # User specific environment and startup programs export MYSQL_HOME=/usr/local/mysql export PATH=$MYSQL_HOME/bin:$PATH source .bashrc echo $MYSQL_HOME which mysql 创建 MySql 管理员用户groupadd -g 101 dba useradd -u 514 -g dba -G root -d /usr/local/mysql mysqladmin 当usradd 以前就已经存在家目录的时候，会出现样式丢失 ，报错如下： useradd: warning: the home directory already exists. Not copying any file from skel directory into it. 需要从 &#x2F;etc&#x2F;skel 将缺失的文件复制一份 cp /etc/skel/.* /usr/local/mysql 配置文件 &#x2F;etc&#x2F;my.cnf 在 /etc下创建my.cnf 【已存在就 vi /etc/my.cnf gg dG清空。已存在可能是因为预装了maria_DB】 touch /etc/my.cnf 从 Github 复制出参考配置文件 vi /etc/my.cnf gg dG 【切记：进入编辑模式再粘贴，命令行模式下粘贴会丢失内容】 修改默认端口号 vi /etc/my.cnf [client] port = 3306 [mysqld] port = 3306 其他配置说明 socket = /usr/local/mysql/data/mysql.sock #指定mysql启动和通信依赖的sock文件 basedir = /usr/local/mysql # mysql 安装的主目录，这也是为啥推荐安装mysql时都安装在 /usr/local/mysql ，不然就需要更改这几项 datadir = /usr/local/mysql/data # 数据目录，也就是表数据存在的物理地址 pid-file = /usr/local/mysql/data/hostname.pid # 每次启动时将进程号pid保存在这里，当停止mysql服务时根据这里面记录的pid号然后执行kill -9 &lt;pid&gt; log-error= /usr/local/mysql/data/hostname.err # 服务启动的错误日志 log-bin = /usr/local/mysql/arch/mysql-bin # binlog数据日志的目录，所以下文也提到要在启动服务前要创建 arch 目录，否则报错 配置文件修正权限chown mysqladmin:dba /etc/my.cnf chmod 640 /etc/my.cnf 安装目录 设置权限 chmod -R 755 /usr/loacl/mysql chmod -R 755 /usr/local/mysql/* chmod -R 755 /usr/local/mysql-5.6.23-linux-glibc2.5-x86_64 chown -R mysqladmin:dba /usr/local/mysql chown -R mysqladmin:dba /usr/local/mysql/* chown -R mysqladmin:dba /usr/local/mysql-5.6.23-linux-glibc2.5-x86_64 # 在mysql启动，自动完成创建如 /usr/local/mysql/data/hostname.pid 文件后， # 再检查这部分文件权限情况，可以再次使用 chmod 和 chown 将/usr/local/mysql/data/* 权限修正，否则以后启动仍可能报错 创建 binlog 日志文件的目录 [mysqladmin@localhost ~]# mkdir /usr/local/mysql/arch 【提前创建不然部署过程报错】 安装脚本 [mysqladmin@Gargantua ~]$ scripts/mysql_install_db \\ --user=mysqladmin \\ --basedir=/usr/local/mysql \\ --datadir=/usr/local/mysql/data 报错 yum install -y perl yum install -y autoconf yum install -y libaio yum 安装又报错：【Loaded plugins: fastestmirror】 vi /etc/yum/pluginconf.d/fastestmirror.conf enabled = 1 【由1改为0，禁用该插件】 vi /etc/yum.conf plugins = 1 【改为0，不使用插件】 【清除缓存并重新构建yum源】 yum clean all yum clean dbcache yum makecache 启动 MySql把服务文件拷贝到指定目录 【serivece启动的前提】 cp /usr/local/mysql/support-files/mysql.server /etc/rc.d/init.d/mysql chmod +x /etc/rc.d/init.d/mysql 删除已经部署过的服务 chkconfig --del mysql 添加服务 chkconfig --add mysql chkconfig --level 345 mysql on 设置开机自启动 vi &#x2F;etc&#x2F;rc.local 添加一句：su - mysqladmin -c &quot;/etc/init.d/mysql start --federated&quot; 切换到mysqladmin用户 把没用到的配置文件删掉 rm -rf ~/my.cnf # mysql默认是按 /etc/my.cnf 启动，所以~/my.cnf可以删掉，避免后续修改配置时产生误导 以service启动service mysql start # 其他命令 service mysql status 【查看状态】 service mysql restart 【重启】 service mysql stop 【停止】 ps -ef|grep mysqld 【查看mysql 进程】 netstat -nlp|grep 59308 【查看mysql端口号】 登录mysql -uroot -p # MySql 5.6 默认空密码可以登录 报错： Can&#39;t connect to local MySQL server through socket &#39;/tmp/mysql.sock&#39; (2) # mysql -uroot -h 127.0.0.1 -p 【可以登录，说明服务是成功部署的】 【检查 my.cnf文件中 socket &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql.sock 是否配置正确】 临时解决：在 &#x2F;tmp 下创建软连接 ln -s /usr/local/mysql/data/mysql.sock /tmp/mysql.sock 参考 https://blog.csdn.net/hjf161105/article/details/78850658 后解决长期未使用后还会报这个错误，因为linux会定期自动删除 &#x2F;tmp&#x2F;mysql.sock； 允许所有ip以root权限来访问mysql&gt;grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;密码&#39;; mysql&gt;flush privileges; 【解释】 GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;密码&#39; ; ALL PRIVILEGES：当前用户的所有权限 *.*：当前用户对所有数据库和表的相应操作权限 &#39;root&#39;@&#39;%&#39;：权限赋给root用户，所有ip都能连接 IDENTIFIED BY &#39;密码&#39;：连接时输入密码 修改 mysql 默认权限&#x2F;用户&#x2F;密码 mysql&gt;show databases; mysql&gt;use mysql mysql&gt;delete from user where user = &#39;&#39;; mysql&gt;update user set password=password(&#39;密码&#39;) where user = &#39;root&#39;; 新建数据库mysql&gt; create database test_db; 重新部署部署失败后重新部署 【只需要三步】： rm -rf arch/* binlog 文件：数据的二进制文件，可以解析成sql，自动保留一定时间内的binlog，超出的会自动删除 rm -rf data/* 服务启动的错误的日志可以在data/hostname.err scripts/mysql_install_db \\--user=mysqladmin \\--basedir=/usr/local/mysql \\--datadir=/usr/local/mysql/data &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;arch&#x2F;mysql-bin.0001 binlog文件会定期删除 使用可视化工具连接连接不上 ping ip 【通】 telnet ip 3306 【mysql 不通】 telnet ip 22 【ssh 是通的】 只能是因为端口被限制：云服务器需要在web端配置安全组，允许访问的端口。 顺利联接。 mysql 5.7 部署准备安装包：https://mirrors.aliyun.com/mysql/MySQL-5.7/下载的是：mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz 环境准备 登录服务器 &#x2F;usr&#x2F;local12[root@Gargantua local]# pwd/usr/local 上传压缩包到 &#x2F;usr&#x2F;local 后解压，再软连接到 .&#x2F;mysql 1[root@Gargantua local]# ln -s mysql-5.7.38-linux-glibc2.12-x86_64 mysql 检查是否自带数据库 MySQL、MariaDB12[root@Gargantua local]# rpm -qa|grep -i mysql[root@Gargantua local]# rpm -qa | grep mariadb 如果有类似 输出mysql-libs-5.1.52-1.el6_0.1.x86_64，就将它删除123456// 普通删除模式 rpm -e mysql-libs-5.1.52-1.el6_0.1.x86_64 // 强力删除模式，如果使用上面命令删除时，提示有依赖的其它文件，则用该命令可以对其进行强力删除 rpm -e --nodeps mysql-libs-5.1.52-1.el6_0.1.x86_64// 删除 mariadbrpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64 创建 MySql 管理员用户 12groupadd -g 101 dbauseradd -u 101 -g dba -G root -d /usr/local/mysql mysqladmin 123456# 创建用户到指定已存在的家目录，会出现样式丢失，报错useradd: warning: the home directory already exists.Not copying any file from skel directory into it.# 从/etc/skel复制一份过来即可[root@Gargantua local]# cp /etc/skel/.* /usr/local/mysql 环境变量 123[root@Gargantua local]# cd mysql[root@Gargantua mysql]# vi .bashrc 添加内容： 123# User specific environment and startup programsexport MYSQL_HOME=/usr/local/mysqlexport PATH=$MYSQL_HOME/bin:$PATH 记得生效确认一下.bashrc文件 12345[root@Gargantua mysql]# source .bashrc[root@Gargantua mysql]# echo $MYSQL_HOME/usr/local/mysql[root@Gargantua mysql]# which mysql/usr/local/mysql/bin/mysql 准备配置 创建目录，存放mysql启动运行时的bin-log、初始化数据、运行日志等…1[root@Gargantua mysql]# mkdir arch data logs 修改安装目录权限 修改为mysqladmin用户才能操作mysql安装目录 1234567[root@Gargantua local]# chown mysqladmin:dba mysql[root@Gargantua local]# chown mysqladmin:dba mysql-5.7.38-linux-glibc2.12-x86_64[root@Gargantua local]# chown -R mysqladmin:dba mysql-5.7.38-linux-glibc2.12-x86_64/*[root@Gargantua local]# chmod 755 mysql[root@Gargantua local]# chmod 755 mysql-5.7.38-linux-glibc2.12-x86_64[root@Gargantua local]# chmod -R 755 mysql-5.7.38-linux-glibc2.12-x86_64/* 创建 &#x2F;etc&#x2F;my.cnf系统默认会安装有MariaDB，如果没有卸载MariaDB的话，&#x2F;etc&#x2F;my.cnf 是已存在的文件，可以先将他清空。 [root@Gargantua mysql]# vi &#x2F;etc&#x2F;my.cnf 1234567891011121314151617181920212223242526272829303132333435363738394041[client]port = 23306socket = /usr/local/mysql/data/mysql.sock[mysqld]bind-address = 0.0.0.0basedir = /usr/local/mysqldatadir = /usr/local/mysql/dataport = 23306socket = /usr/local/mysql/data/mysql.sockcharacter-set-server=utf8log-bin = /usr/local/mysql/arch/mysql-binserver-id = 1# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html# *** DO NOT EDIT THIS FILE. It&#x27;s a template which will be copied to the# *** default location during install, and will be replaced if you# *** upgrade to a newer version of MySQL.log-error = /usr/local/mysql/data/mysqld.logpid-file = /usr/local/mysql/data/mysqld.pid[mysqldump]quickmax_allowed_packet = 16M[mysql]default-character-set = utf8no-auto-rehashsocket = /usr/local/mysql/data/mysql.sock[myisamchk]key_buffer_size = 256Msort_buffer_size = 256Mread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeout 记得权限也要修改： 12[root@Gargantua mysql]# chown mysqladmin:dba /etc/my.cnf [root@Gargantua mysql]# chmod 640 /etc/my.cnf 手动初始化数据目录 1[root@Gargantua mysql]# ./bin/mysqld --initialize --user=mysqladmin --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/ （首次初始化一般会报错）: 1./bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory yum安装以下内容后重新初始化即可。 12yum -y install numactlyum -y install libaio 可以确认一下是否成功初始化到指定的数据目录下，同时可以检查一下生成文件的权限，若不对就修改。 1[root@Gargantua mysql]# ls -l ./data 1234567891011121314151617-rw-r----- 1 mysqladmin dba 56 Nov 20 21:40 auto.cnf-rw------- 1 mysqladmin dba 1676 Nov 20 21:40 ca-key.pem-rw-r--r-- 1 mysqladmin dba 1112 Nov 20 21:40 ca.pem-rw-r--r-- 1 mysqladmin dba 1112 Nov 20 21:40 client-cert.pem-rw------- 1 mysqladmin dba 1680 Nov 20 21:40 client-key.pem-rw-r----- 1 mysqladmin dba 436 Nov 20 21:40 ib_buffer_pool-rw-r----- 1 mysqladmin dba 12582912 Nov 20 21:40 ibdata1-rw-r----- 1 mysqladmin dba 50331648 Nov 20 21:40 ib_logfile0-rw-r----- 1 mysqladmin dba 50331648 Nov 20 21:40 ib_logfile1drwxr-x--- 2 mysqladmin dba 4096 Nov 20 21:40 mysql-rw-r----- 1 mysqladmin dba 1108 Nov 20 21:40 mysqld.logdrwxr-x--- 2 mysqladmin dba 4096 Nov 20 21:40 performance_schema-rw------- 1 mysqladmin dba 1680 Nov 20 21:40 private_key.pem-rw-r--r-- 1 mysqladmin dba 452 Nov 20 21:40 public_key.pem-rw-r--r-- 1 mysqladmin dba 1112 Nov 20 21:40 server-cert.pem-rw------- 1 mysqladmin dba 1680 Nov 20 21:40 server-key.pemdrwxr-x--- 2 mysqladmin dba 12288 Nov 20 21:40 sys 初始化完成之后在日志中查看临时初始密码，日志mysqld.log就是在 &#x2F;etc&#x2F;my.cnf中的 log-error 项的内容。 1[root@Gargantua mysql]# vi ./data/mysqld.log 123# 最后一行会记录自动生成的临时初始密码，登录mysql会用到 [Note] A temporary password is generated for root@localhost: ih_vhugTz0hk 设置mysql以service启动 创建systemctl管理mysql的配置文件命令： 1[root@Gargantua mysql]# vi /usr/lib/systemd/system/mysql.service 12345678910111213141516171819202122[Unit]Description=MySQL ServerDocumentation=man:mysqld(8)Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.htmlAfter=network.targetAfter=syslog.target[Install]WantedBy=multi-user.target[Service]User=mysqladminGroup=dba# 本机mysql安装目录ExecStart=/usr/local/mysql/bin/mysqld --defaults-file=/etc/my.cnf# 使用$MYSQL_HOME会报错# ExecStart=$MYSQL_HOME/bin/mysqld --defaults-file=/etc/my.cnfLimitNOFILE = 5000#Restart=on-failure#RestartPreventExitStatus=1#PrivateTmp=false 切换到mysqladmin用户 12[root@Gargantua mysql]# su - mysqladmin[mysqladmin@Gargantua ~]$ 启动 MySQL 服务 1[mysqladmin@Gargantua ~]$ systemctl start mysql 输出密码后，显示 &#x3D;&#x3D;&#x3D;&#x3D; AUTHENTICATION COMPLETE &#x3D;&#x3D;&#x3D; 代表成功。 查看运行状态、停止、重启 123systemctl status mysql systemctl stop mysql systemctl restart mysql 设置mysql开机自启动1[mysqladmin@Gargantua ~]$ systemctl enable mysql 使用临时初始密码登录 MySQL 12[mysqladmin@Gargantua ~]$ mysql -uroot -pih_vhugTz0hk 若报错：1ERROR 2002 (HY000): Can&#x27;t connect to local MySQL server through socket &#x27;/tmp/mysql.sock 一般是 my.cnf 中遗漏了socket配置，所以它默认去tmp目录下找sock文件，发现也没有就会报错。注意在 [client]、[mysqld]、[mysql] 都要指定socket 若报错： 1ERROR 2003 (HY000): Can&#x27;t connect to MySQL server on &#x27;127.0.0.1&#x27; 一般是 my.cnf 中遗漏了 bind-address配置 12[mysqld]bind-address = 0.0.0.0 修改密码 1mysql&gt; set password=password(&#x27;123456&#x27;); 要求必须修改密码，否则会提示：ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement. 创建mysql用户 12# CREATE USER ‘用户名’@‘限制的IP地址’ IDENTIFIED BY ‘密码’;mysql&gt; CREATE USER &#x27;test&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;123456&#x27;; 设置与更改用户密码 1mysql&gt; SET PASSWORD FOR &#x27;test&#x27;@&#x27;localhost&#x27; = PASSWORD(&#x27;123456&#x27;); 允许所有ip以root来访问 123# GRANT ALL PRIVILEGES ON 有权限的库表 TO &#x27;用户&#x27;@&#x27;允许的ip&#x27; IDENTIFIED BY &#x27;密码&#x27; ;mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;密码&#x27; ;mysql&gt; flush privileges; 删除用户 1234mysql&gt; DROP USER &#x27;test&#x27;@&#x27;localhost&#x27;;# 或mysql&gt; delete from user where user = &#x27;test&#x27; and host = &#x27;localhost&#x27;;","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"mysql","slug":"数据库/mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}],"author":"昱东"},{"title":"Oracle为什么要用三层嵌套实现分页","slug":"Oracle为什么要用三层嵌套实现分页","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/Oracle为什么要用三层嵌套实现分页/","permalink":"http://example.com/2024/09/15/Oracle%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E4%B8%89%E5%B1%82%E5%B5%8C%E5%A5%97%E5%AE%9E%E7%8E%B0%E5%88%86%E9%A1%B5/","excerpt":"","text":"Oracle为什么要用三层嵌套实现分页 先说结论：嵌套出两层SELECT对应的两个原因： ROWNUM的取值是在数据库物理行号，不受ORDER BY 影响。如果存在同一趟SELECT中，order by排序后的ROWNUM不是有序的，不会和查询结果行号对应，所以不能做条件过滤。需要在一次select order by 后得到的虚拟表中，再获取ROWNUM这样order by才能生效。 ROWNUM 只能做小于，不能直接做大于范围取值。 项目中使用分页插件，控制台输出sql 为: 1. 首先发现最外层嵌套只是为了做 WHERE row_id &gt;0。 而 row_id 就是ROWNUM 别名。是否可以减少一层，让 where 0 &lt; ROWNUM &lt;&#x3D;10 会直接报错: ROWNUM 不能直接做大于范围取值。 解决办法: 套一层select , 在对rownum 取别名后, 可以进行大于范围取值 到此。解释了为什么要套第一层select 2. 接下来的问题： rownum 是在 order by 之前的排序 。先来看，没有使用order by 排序时, rownum的顺序就是行号顺序而同一趟SELECT 中同时取rownum 又 order by 时： 可以看出：ROWNUM的取值不受ORDER BY 影响,也就是先于ORDER BY之前, ROWNUM的值已经确定，是取得数据原本在数据库的行号。 看起来ROWNUM顺序混乱。如果此时再使用rownum进行分页范围取值, 取到的数据并不是期望的按order by 的排序得到的范围。order by 不起作用，而往往用户都会指定order by的。 解决思路: 让order by 先执行, 得到顺序后, 再生成顺序号rownum , 再用rownum分页时就是按 order by 的顺序了. 想法一： 内层select 做完order by 排序, 再在外层 取rownum 做范围截取 —- 报错rownum列不存在，没有在返回值列表显示写出rownum就不会返回rownum。而就算此时不会报错也嵌套了一层SELECT。 想法二:只能让rownum 和 order by 分别位于不同层级, 并保证 order by 先执行。再对order by 后得到的虚拟表取rownum就能拿到期望的顺序号了，再做 小于 范围取值。 注意：内层返回列表没有取rownum，如果取了rownum则仍然又拿到数据在数据库的物理行号。 还需注意：第三层对rownum 做大于范围取值时, 仍然要取别名（作为普通列）再做 大于 范围取值。 结合起来就实现了分页插件三层嵌套SELECT的效果。 总结：多嵌套了两层SELECT ，对应的两个原因： ROWNUM的取值是在数据库物理行号，不受ORDER BY 影响。如果存在同一趟SELECT中，order by排序后的ROWNUM不是有序的，不会和查询结果行号对应，所以不能做条件过滤。需要在一次select order by 后得到的虚拟表中，再获取ROWNUM这样order by才能生效。 ROWNUM 只能做小于，不能直接做大于范围取值。 三层SELECT分别的作用是： 第一层是为了做order_by (order_by 不能和ROWNUM范围取值一起使用) 第二层是为了做ROWNUM &lt;&#x3D;10，并且对ROWNUM取别名用于第三层(作普通列)做大于范围取值。 第三层做ROW__ID &gt;0 同时细心我的发现了一个疑问，在最里层的SELECT语句中没有对查询数量做任何限制，不会查出全表数据吗？假分页？对此的解答是： CBO优化模式下，Oracle可以将外层的查询条件推到内层查询中，以提高内层查询的执行效率。 对于第一个查询语句，第二层的查询条件WHERE ROWNUM &lt;= 40 就可以被Oracle推入到内层查询中。 这样Oracle查询的结果一旦超过了ROWNUM限制条件，就终止查询将结果返回了。 同理第三个SELECT 里的 WHERE row_id &gt;0 是否也推到第二层。 这样看来虽然在编写sql时嵌套子查询，但Oracle悄悄优化掉了。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Oracle","slug":"数据库/Oracle","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"http://example.com/tags/Oracle/"}],"author":"昱东"},{"title":"Spring注解式编程","slug":"Spring注解式编程","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/Spring注解式编程/","permalink":"http://example.com/2024/09/15/Spring%E6%B3%A8%E8%A7%A3%E5%BC%8F%E7%BC%96%E7%A8%8B/","excerpt":"","text":"spring注解编程-IOC 配置类&amp;Bean注解@Configuration123加了这个注解的类就相当于传统的一个applicationContext-xxx.xml ，告诉spring这是一个注解类 最初的Spring只支持xml方式配置Bean，从Spring 3.0起支持：基于Java类的配置方式，Java开发者可以从标签语法里解放了出来。 配置放在哪里 配置类要与启动类同包或者在其任意子包下，满足spring的扫描条件，配置才能被成功加载。 如果不满足上述同包或子包条件，需要如下办法：在resources目录下新建META-INF目录，并在该目录下创建spring.factories文件。spring.factories文件内容如下：12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.ft.xx.config.DruidConfig 第一行是spring自动配置的路径，第二行是我们自己要指定加载配置类的路径。 @Bean1234@Bean注解的作用与&lt;bean/&gt;标签相同在标注了@Configuration的类里面的方法上面打上@bean就相当于在applicationContext-xxx.xml配置的一个&lt;bean id=&quot;userDao&quot; class=&quot;cn.itsource.dao.UserDao&quot;&gt; 1简单粗暴理解：@Configuration标注的类等同于一个xml文件，@Bean标注的方法等同于xml文件里的一个&lt;bean/&gt;标签 Bean的名字默认就是方法名，如果想改方法名使用@Bean(“beanName”) 12345678@Configuration public class MainConfig &#123; @Bean(&quot;userDao&quot;) //指定bean的名字 public UserDao userDao()&#123; // 方法必须是public。 return new UserDao(); &#125;&#125; @Bean(initMethod&#x3D;”init”,destroyMethod&#x3D;”destroy”)定义，在构造之后执行init，在销毁之前执行destroy。 使用@Configuration和不使用@Configuration的区别通常来说，我们均会把@Bean标注的方法写在@Configuration标注的类里面来配合使用。但其实，没有@Configuration注解的类中的@Bean也会被扫描到，只是一般不这么用。是否通过@Configuration，官方管这两种模式分别叫：Full @Configuration和lite @Bean mode。 Full模式和Lite模式Full模式和Lite模式均是针对于Spring配置类而言的，和xml配置文件无关。 Full模式： 12运行时会给该类生成一个CGLIB子类放进容器，有一定的性能、时间开销（这个开销在Spring Boot这种拥有大量配置类的情况下是不容忽视的，这也是Spring 5.2新增了proxyBeanMethods属性的最直接原因）正因为被代理了，所以@Bean方法 不可以是private、不可以是final Lite模式：官方定义为：在没有标注@Configuration的类里面有@Bean方法就称为Lite模式的配置。透过源码再看这个定义是不完全正确的，而应该是有如下case均认为是Lite模式的配置类： 12345类上标注有@Component注解类上标注有@ComponentScan注解类上标注有@Import注解类上标注有@ImportResource注解若类上没有任何注解，但类内存在@Bean方法 以上case的前提均是类上没有被标注@Configuration，在Spring 5.2之后新增了一种case也算作Lite模式： 标注有@Configuration(proxyBeanMethods &#x3D; false)，注意：此值默认是true，需要显示改为false才算是Lite模式。自Spring5.2（对应Spring Boot 2.2.0）开始，内置的几乎所有的@Configuration配置类都被修改为了@Configuration(proxyBeanMethods &#x3D; false)，以此来降低启动时间，为Cloud Native继续做准备。 Lite模式下: 1234配置类本身不会被CGLIB代理，放进IoC容器内的就是本尊不能直接声明@Bean之间的依赖：配置类内部不能通过方法调用来处理依赖，每次生成的都是一个新实例而并非IoC容器内的单例。(与之对比的full 模式时，一个@Bean的方法调用了另一@Bean方法，被调用的bean并不会执行两次噢，会保证单例~~)配置类就是一普通类，所以@Bean方法可以使用private/final/static等进行修饰 下面以实际例子说明： Full模式： 123456789101112131415161718@Configurationpublic class UserConfiguration &#123; @Bean public UserService userService_1()&#123; return new UserService(orderService()); // 获取spring代理后的orderService bean &#125; @Bean public UserService userService_2()&#123; return new UserService(orderService()); // 获取spring代理后的orderService bean &#125; @Bean public OrderService orderService()&#123; return new OrderService(); &#125;&#125; 在使用@Configuration时，通过orderService()获取到的是被Spring代理对象，并且Spring保证单例。所以在userService_1、userService_2中持有的orderService是同一个，也可以说，被调用的orderService这个bean只执行一次。验证： 1234UserService userService_1 = (UserService) applicationContext.getBean(&quot;userService_1&quot;);UserService userService_2 = (UserService) applicationContext.getBean(&quot;userService_2&quot;);System.out.println(userService_1.getOrderService()); // com.xxx.OrderService@64e1dd11System.out.println(userService_2.getOrderService()); // com.xxx.OrderService@64e1dd11 Lite模式： 12345678910111213141516171819// @Component // 使用Component也是Lite@Configuration(proxyBeanMethods = false)public class UserConfiguration &#123; @Bean public UserService userService_1()&#123; return new UserService(orderService()); &#125; @Bean public UserService userService_2()&#123; return new UserService(orderService()); &#125; @Bean public OrderService orderService()&#123; return new OrderService(); &#125;&#125; 在使用@Configuration(proxyBeanMethods &#x3D; false)时，通过orderService()获取到的是java原生的对象，不经过代理，相当于同类中普通方法调用而已，那么每调用一次就会new 一个OrderService()对象。所以userService_1、userService_2中持有的orderService是不同的， 验证： 1234UserService userService_1 = (UserService) applicationContext.getBean(&quot;userService_1&quot;);UserService userService_2 = (UserService) applicationContext.getBean(&quot;userService_2&quot;);System.out.println(userService_1.getOrderService()); // com.xxx.OrderService@5a9800f8System.out.println(userService_2.getOrderService()); // com.xxx.OrderService@143d9a93 总结： 使用@Configuration的类会被代理，否则不会经过代理。 使用@Configuration或@Configuration(proxyBeanMethods &#x3D; true) 时，Spring会将这个配置也代理，其中的方法也被创建代理方法。并且由Spring保证单例。 所以当其中一个bean调用另一个bean时，是从Spring容器中获取这个代理后单例的bean。 不使用@Configuration，或使用@Configuration(proxyBeanMethods &#x3D; false)时，这就是一个普通的java类，虽然其中的@Bean会被扫描到并注册为Spring单例bean，但不经过代理。且类中的Bean之间调用就是普通的方法调用，也不会经过Spring代理。每一处的调用都会各自执行一遍方法本身所有的内容。 注入BeanAnnotationConfigApplicationContext基于applicationContext-xxx.xml创建的bean是通过 ClassPathXmlApplicationContext(“xxx.xml”)来获取。 基于注解配置类创建的bean，要通过 new AnnotationConfigApplicationContext(MainConfig.class);来获取。 123456789public class Application &#123; public static void main(String[] args) &#123; ApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); UserDao userDao = context.getBean(UserDao.class); &#125;&#125; 前提是容器中注入了这个bean，向容器中注入bean的方式： @Bean + @Configuration： 12345678@Configurationpublic class MainConfig &#123; @Bean public UserDao userDao() &#123; return new UserDao(); &#125;&#125; 此种方式常用于将第三方jar中的某个类，注册为当前项目的一个bean。 @Import： 12345@Import(UserDao.class)@Configurationpublic class MainConfig &#123;&#125; @Component： 1234@Componentpublic class userDao &#123;&#125; @Repository,@Service,@Controller,@Component使用注解的类会被创建出一个bean @ComponentScan使用 @Component等创建的bean，需要配合使用@ComponentScan扫描才能识别到这些bean。 @ComponentScan 其实就是： 1&lt;context:component-scan base-package=&quot;org.example.xxx&quot;/&gt;. @ComponentScan 可以指定多个路径，还可以指定路径下只包含部门类、排除部分类 @Lazy指定bean懒加载，容器创建时不加载，第一次使用时才加载 @Scope指定bean作用域 @Conditional-按照条件注册类和方法上都可以如：@Conditional(value &#x3D; WindowsCondition.class) 表示根据当前os.name的环境来判断是否创建bean @Import@Import(Class&lt;?&gt;[] value）可用于导入任意指定的如第三方jar中的类并自动创建bean到当前容器,也可以导入配置类，则配置类中所有@Bean的bean都能注册到当前容器。 对于第三方jar中的bean,并不能直接注册到当前容器，想要办到： 这个bean的包名是当前容器启动类的子包（哪怕在不同模块，只要编译后是子包就行） 不是子包的话，可以使用包扫描指定额外的包的范围，@ComponentScan()，如果有多个额外的包就要写很多。 不是子包的话，可以使用@Import指定具体的类，每一个想注册进容器的类都要单独写，也会很多。 由第三方jar提供一个@Enable开头的注解，这个注解就是对@Import(自己的类Class),的封装，对每一个想注册进当前容器的bean，都需要添加一个对应的@Enable开头的注解。 @EnableAutoConfig @Import(Class value)导入自定义的ImportSelector选择器，重写selectImports()方法，方法返回需要被导入的组件的类全限定名数组 -springboot底层用的多 1@Import(MyImportSelector.class) 123456789public class MyImportSelector implements ImportSelector &#123; @Override public String[] selectImports(Anno..) &#123; return new String[]&#123;&quot;com.example.User&quot;,&quot;com.example.Person&quot;&#125; &#125;&#125; Springboot 就是使用 ImportSelector 的方式，详细过程整理在 Spring Boot一篇中。 @Import(Class value)通过bean定义注册器手动项目spring中容器中注册。 也需要覆写方法registerBeanDefinitions(),其中第二个参数，可以用于向我们的IOC容器注册bean。 1@Import(MyImportBeanDefinitionRegistrar.class) 1234567891011public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar &#123; @Override public viod registerBeanDefinitions(Anno... anno, BeanDefinitionRegistry registry) &#123; BeanDefinition beanDefinition = BeanDefinitionBuilder.rootBeanDefinition(User.class).getBeanDefinition(); registry.registerBeanDefinition(&quot;user&quot;, beanDefinition) // (String beanName, BeanDefinition beanDefinition) &#125;&#125; 生命周期管理 方式一 ： @Bean(initMethod &#x3D; “init”,destroyMethod &#x3D; “destory”) 方式二 ： 实现InitializingBean和DisposableBean接口InitializingBean：afterPropertiesSet(), 设置完属性后调用DisposableBean：destroy(), 容器关闭时调用 12 方式三 ： 注解@PostConstruct @PreDestroy1234567891011121314151617@Componentpublic class Test &#123; public Test()&#123; System.out.println(&quot;Test ....create....&quot;); &#125; @PostConstruct public void init()&#123; System.out.println(&quot;Test ....init....&quot;); &#125; @PreDestroy public void destory()&#123; System.out.println(&quot;Test ....destory....&quot;); &#125;&#125; 方式四 ： BeanPostProcessor（接口），bean后置处理器 Object postProcessBeforeInitialization：初始化之前调用 Object postProcessAfterInitialization：初始化之后调用12345678910111213141516@Componentpublic class MyBeanPostProcessor implements BeanPostProcessor &#123; //初始化之前调用 @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;postProcessBeforeInitialization &quot;+beanName); return bean; &#125; //初始化之后调用 @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;postProcessAfterInitialization &quot;+beanName); return bean; &#125;&#125; BeanFactory 和 FactoryBean区别：BeanFactory是个Factory，也就是IOC容器或对象工厂，FactoryBean是个Bean。在Spring中，所有的Bean都是由BeanFactory(也就是IOC容器)来进行管理的。但对FactoryBean而言，这个Bean不是简单的Bean，而是一个能生产或者修饰对象生成的工厂Bean,它的实现与设计模式中的工厂模式和修饰器模式类似 最常用MVC注解@PathVariable 放置在参数前，用来接受路径参数。 @RequestBody 允许request的参数在request体中，而不是在直接链接在地址的后面。此注解放置在参数前。 @ResponseBody 将返回值放在response体内。返回的是数据而不是页面 @RestController 组合注解，组合了@Controller和@ResponseBody,当我们只开发一个和页面交互数据的控制层的时候可以使用此注解。 @RequestMapping 用来映射web请求（访问路径和参数）。可以注解在类和方法上，注解在方法上的路径会继承注解在类上的路径。同时支持Serlvet的request和response作为参数，也支持对request和response的媒体类型进行配置。其中有value(路径)，produces(定义返回的媒体类型和字符集)，method(指定请求方式)等属性。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"author":"昱东"},{"title":"java日志框架","slug":"java日志框架","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/java日志框架/","permalink":"http://example.com/2024/09/15/java%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/","excerpt":"","text":"日志打印 建议用{}占位而不是字符串拼接 打日志前先判断日志级别是否可用： 先根据等级过滤规则再决定写不写； 先往一个管道写了内容，但再经等级过滤丢弃，徒增开销。 日志框架Slf4JSlf4J 不是底层日志框架，只是门面框架（抽象），需要配合jul、log4j、logback、log4j2等底层框架(真正干活的)使用。 避免日志对代码的耦合，更换日志框架时也不需改动任何代码。不论使用哪种底层框架时，在代码层面都一样。 避免引入第三方jar而其中日志框架不一致时需要同时维护不同的日志框架对应的配置文件。 补充：更老的门面框架还有jcl， 所以会看到有程序应用 jcl + log4j 这种搭配。Slf4J 后采用 Slf4J + log4j，但一些 jcl + log4j 项目也想用Slf4J 时，可以通过引入 jcl-over-slf4j log桥接工具的依赖，将原本输出到jcl的日志输出重定向到 SLF4J。 如果只用了slf4j，而没有使用任何底层框架，就会出现以下错误： 123SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. log4jlog4j作为传统的日志框架，并没有提供占位符的支持，只能用String拼接并来进行输出信息。 依赖 12345&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 配置文件 log4j.properties 123456789 log4j.rootLogger=info, stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%nlog4j.appender.logfile=org.apache.log4j.FileAppenderlog4j.appender.logfile.File=target/spring.loglog4j.appender.logfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n 代码 123456789101112131415import org.apache.log4j.Logger;//更多请阅读：https://www.yiibai.com/log4j/log4j_sample_program.htmlpublic class log4jExample&#123; static Logger log = Logger.getLogger(log4jExample.class.getName()); public static void main(String[] args) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;### Hello this is an debug message&quot;); &#125; log.info(&quot;### Hello this is an info message&quot;); // 不支持占位符 &#125;&#125; 输出 12022-07-27 21:10:03,358 INFO [org.example.log4jExample] - ### Hello this is an info message logback （原生实现 SLF4J）Logback 旨在作为流行的 log4j 项目的继承者，在 log4j 1.x 停止的地方接手。 Logback 的架构非常通用，可以在不同的情况下应用。 目前，logback 分为三个模块，logback-core、logback-classic 和 logback-access。 logback-core 模块为其他两个模块奠定了基础。 logback-classic 模块可以同化为 log4j 1.x 的显着改进版本。 此外，logback-classic 原生实现了 SLF4J API。 logback-access 模块与 Tomcat 和 Jetty 等 Servlet 容器集成，以提供 HTTP 访问日志功能。 请注意，您可以轻松地在 logback-core 之上构建自己的模块。 依赖 12345&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; 默认配置 Logback 默认配置的步骤 参考：https://www.cnblogs.com/warking/p/5710303.html 尝试在 classpath下查找文件logback-test.xml； 如果文件不存在，则查找文件logback.xml； 如果两个文件都不存在，logback用BasicConfigurator自动对自己进行配置，这会导致记录输出到控制台。 logback.xml 12345678910111213 &lt;configuration&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg %n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt; &lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;DEBUG&quot;/&gt;&lt;/configuration&gt; 代码 123456789101112131415import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class LogbackExample &#123; static Logger log = LoggerFactory.getLogger(LogbackExample.class); public static void main(String[] args) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;### Hello this is an debug message&quot;); &#125; log.info(&quot;### Hello this is an info message&quot;); // 不支持占位符 &#125;&#125; 输出 1129 [main] INFO org.example.LogbackExample - ### Hello this is an info message 如果需要将日志按规则生成到文件，也可以在logback.xml中配置；logback.xml中各标签的含义，查阅上文。 如图可以配置将日志信息同时实时输出到终端和离线输出到日志文件。 @Slf4j 注解 能够少写两行代码，不用每次都在类的最前边写上： private static final Logger logger = LoggerFactory.getLogger(this.XXX.class); 需要 lombok依赖。如果是基于SpringBoot，因为默认加入了Slf4j-api和logback的依赖，所以只需要添加lombok的依赖即可。 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.10&lt;/version&gt;&lt;/dependency&gt; 代码123456789101112import lombok.extern.slf4j.Slf4j;@Slf4jpublic class SLF4JExample &#123; public static void main(String[] args) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;### Hello this is an debug message&quot;); &#125; log.info(&quot;### Hello this is an info message&quot;); // log 由lombok提供，如报错是idea的问题 &#125;&#125; log4j 适配 Slf4j 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.28&lt;/version&gt;&lt;/dependency&gt; 只需要依赖 slf4j-log4j12，它自身依赖log4j 和 slf4j-api 两个包。 配置由于底层框架仍然使用的是log4j，仍然需要 配置文件： log4j.properties 123456789log4j.rootLogger=info, stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%nlog4j.appender.logfile=org.apache.log4j.FileAppenderlog4j.appender.logfile.File=target/spring.loglog4j.appender.logfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n 代码 123456789101112131415import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class LogSlf4jExample &#123; static Logger log = LoggerFactory.getLogger(LogSlf4jExample.class); public static void main(String[] args) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;### Hello this is an debug message&quot;); &#125; log.info(&quot;### Hello this is an info message&quot;); // 不支持占位符 &#125;&#125; 在代码层面已经实现和使用logback时一样了，都是从 org.slf4j.LoggerFactory 这个包下 getLogger来获取 Logger 对象。当然也可以使用 @Slf4j 注解的方法。代码是一样的，无法看出底层框架是log4j还是logback。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"log4j","slug":"log4j","permalink":"http://example.com/tags/log4j/"},{"name":"logback","slug":"logback","permalink":"http://example.com/tags/logback/"},{"name":"slf4j","slug":"slf4j","permalink":"http://example.com/tags/slf4j/"}],"author":"昱东"},{"title":"linux入门+常用命令","slug":"linux入门-常用命令","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/linux入门-常用命令/","permalink":"http://example.com/2024/09/15/linux%E5%85%A5%E9%97%A8-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"初识 linux~：家目录 root 用户~规定为 &#x2F;root [root@localhost ~]$ pwd&#x2F;root 普通用户~默认 &#x2F;home&#x2F;username [liqiang@localhost ~]$ pwd&#x2F;home&#x2F;liqiang pwd 显示当前光标所在路径 ~ 与 &#x2F; 的区别 ~ 代表家目录， 对于root用户来讲就是： &#x2F;root ， &#x2F; 是根目录。**&#x2F;root** 只是 &#x2F; 下的其中一个子文件夹。 [root@localhost &#x2F;]# lsbin dev home root etc usr var 切换路径 # windows 也是使用cd切换路径，但win有盘符，切换到c盘只需要 D:\\&gt; c: # 简写 D:\\&gt; cd /d c: # 也是cd命令，不过要用加上 /d 区别于切换盘符和路径 去到家目录： cdcd ~ 去到根目录 ## 所有用户同一个根目录 cd &#x2F; 回退到上一次停留目录 cd - 去到上一层、上两层目录 cd ../ cd ../../ .&#x2F; 是当前目录，相对路径 绝对路径： 以根目录为起始 [root@localhost local]$ cd &#x2F;usr&#x2F;local&#x2F;mysql 相对路径： 以当前目录为起始 [root@localhost local]$ cd mysql[root@localhost local]$ cd .&#x2F;mysql 文件查看当前目录下文件&#x2F;文件夹 lsll –&gt; ls -l 的别名，列出文件&#x2F;文件夹详细信息ll -a –&gt; ls -l -a 查看包括隐藏文件在内的所有文件&#x2F;文件夹ll -h 查看文件大小 【du -sh 可看文件&#x2F;文件夹大小,小于4k的文件&#x2F;夹只会显示4.0k】ll -rt 按时间并排展示，一般 -rt 一起使用ls –help 更多命令查看命令帮助ll -R 查看当前目录和子目录下文件 统计文件&#x2F;文件夹大小12ll -h （ls -lh）列表输出该目录下文件大小信息。对文件夹不适应。du -sh 当前目录下文件/夹总量大小，也可指定查单独某个文件/夹 du -sh xxx.txt 统计文件内容wc -l 统计当前目录下所有文件各自的行数，总行数也可以指定统计某个文件 统计当前目录下文件（递归子文件夹、过滤掉文件夹） 1ls -lR | grep &quot;^-&quot; | wc -l 统计当前目录下文件夹（递归子文件夹、过滤掉文件） 1ls -lR | grep &quot;^d&quot; | wc -l mkdir 创建文件夹单个创建 mkdir a （相对路径创建在当前目录下） mkdir /xxx/xxx （绝对路径可以往任意路径创建） 级联创建 mkdir -p 1/2/3 并联创建 mkdir a b c 复制和移动文件cp /xxx/xx ./xxxx [源文件] [目标文件] mv /xxx/xx xxxx [源文件] [目标文件] ln -s mysql-5.6.23 mysql [源文件] [快捷方式] ## 代替mv重命名，便于上线后版本变更，存储位置变更 上传文件# cd 到使用目录 # rz 从windows资源管理器选中文件上传到linux当前目录 【或使用xftp工具】 # sz filename 将文件下载到windows [yum install -y lrzsz] 解压文件tar -zxvf file.tar.gz -C ../app 【-C指定解压目录 】 # 其他压缩格式 # unzip file.zip 解压zip [yum install -y unzip] # tar -xzvf file.tar.gz 解压tar.gz [yum install -y lrzsz] # tar Jxvf file.tar.xz 解压tar.xz # tar –xvf file.tar 解压tar # unrar e file.rar 解压rar **需要安装工具包** # 压缩文件 zip -r test.zip test.txt zip -r test.zip ./* 【将当前目录下的所有文件和文件夹，压缩成test.zip,-r表示递归压缩子目录下所有文件】 创建空文件 touch xxx.xx cat &#x2F;dev&#x2F;null &gt; xxx.xx echo &quot;&quot; &gt; xxx.xx （空字符串并不完全空）回显 vi xxx.xx （前提xxx.xx不存在，vi后不编辑，保存退出） 将已有内容的文件清空内容 cat &#x2F;dev&#x2F;null &gt; xxx.xx echo &quot;&quot; &gt; xxx.xx （空字符串并不完全空） vi gg dG 【gg 第一行；dG删除光标所在及以后行；更多命令参考一下内容(命令行模式的快捷命令)】 rm -rf 后再 touch 将文件追加至另一个文件 cat wc2.txt &gt;&gt; wc.data 查看文件的内容 cat &#x2F; more &#x2F; less cat 一次全部展示 （小文件） more 按空格往下翻页，不能往上，按q退出 （大文件）–和cat一样一次加载全部，只是可以分页查看 less 按上下箭头往上下，按q退出 （大文件）– 不是一开始加载文件全部 具备查找功能，按&#x2F; 然后输入要找的字串，再按 Enter 即可，按 n(next) 会继续找，大写的 N 则是往回(上)找，按 q(quit)或者ZZ离开 《more和less的用法》：https://www.cnblogs.com/aijianshi/p/5750911.html cat xxx.xx | grep -C 20 ERROR【过滤出关键字 ERROR 出现的前20行+后20行的内容】【管道符：第一个命令的输出为第二个命令的输入】【grep：按关键字过滤 】【- A 后20行；-B 前20行；-C 前后20行 -after&#x2F;-before】 cat xxx.xx | awk ‘{print $1,$2}’ 【awk ：可以将文本格式化，即按指定的格式输出】 【print $1,$2 ： 只会输出 默认以空格分隔的第一和第二列的内容】指定#作为分割符号：cat awk_test.txt | awk -F# ‘{print $1,$2}’ awk更多用法参考：https://cloud.tencent.com/developer/article/1533669 生成到log文件，再用sz命令 下载到windows来查看（一般在download目录下） cat xxx.xx | grep -C 30 ERROR &gt; error.log 【&gt; 新建/覆盖】 【把过滤出来的文件输出到新的文件】 cat xxx.xx| grep -C 30 ERROR &gt;&gt; error.log 【&gt;&gt; 追加】 tail -f 【实时查看】 tail -200f xxx.xx 实时查看文件最新200行【没有-200F的，一般脚本里用F，自己操作时f】 tail -F xxx.xx 【F &#x3D; f + retry，文件消失后会不停尝试重新获取文件】 全局搜索一个文件的名称 find &#x2F; -name ‘*mysql*‘ [*:模糊搜索；&#x2F; 根路径：全局会很慢，能确定部分目录就用&#x2F;xxx 替换&#x2F;] vi 编辑文件的过程 vi xxx.xx 打开进入命令行模式i 进入编辑模式esc 进入命令行模式shift+: 进入尾行模式wq 保存退出；q退出；q!不保存；wq!强制保存退出 命令行模式的快捷命令12345678910gg：光标移动至第一行dd：删除游标所在的一整行(常用)ndd：n为数字。删除光标所在的向下n行，如20dd则是删除光标所在的向下20行；不是从开始行删除哦；dG：删除光标所在到最后一行的所有数据d$：删除光标所在处，到该行的最后一个字符d1G：删除光标所在到第一行的所有数据d0：那个是数字0,删除光标所在到该行的最前面的一个字符x,X：x向后删除一个字符(相当于[del]按键),X向前删除一个字符(相当于[backspace]即退格键)nx：n为数字，连续向后删除n个字符 123:set nu 显示行号:set nonu 取消显示输入永久显示行号：vi /etc/virc 在最后一行添加 set nu 12:set fileencoding 显示编码格式:set fileencoding=utf-8 设置编码格式 Window 和 Linux 文件&amp;编码格式 在win创建的问题，可能导致linux进程不识别。 在linux上 vi 打开后，文件内容看起来一摸一样，但左下角显示 [dos] 代表是win创建的文件。 123~~[&quot;address.txt&quot; [dos] 14L, 214C ] 将win文件转unix 1234$ sudo yum install dos2unix $ dos2unix address.txt dos2unix: converting file address.txt to Unix format ... 再次打开后，就没有 [dos] 凡是win创建的文件都留意一下编码格式（是否UTF-8） 123$ file address.txt address.txt: UTF-8 Unicode text, with CRLF line terminators 环境变量和PATH 全局环境变量：&#x2F;etc&#x2F;profile个人环境变量： (~自己家目录) ~&#x2F;.bashrc~&#x2F;.bash_profile 最好配置在 .bashrc。【切换用户 su 不会执行.bash_profile；su - 才会】可能存在其他不会生效情况 修改配置文件后：刷新、执行配置文件 [source 或 .] （只会在当前会话，其他已经连接的会话也需要source） source /etc/profile . .bashrc 【第一个. 与 source同样效果，代表执行】 which java 【检查修改有没有生效】echo $JAVA_HOME –&gt;能输出 &#x2F;usr&#x2F;java&#x2F;jdk1.8.0_121 是因为在&#x2F;etc&#x2F;profile里添加了JAVA_HOME vi ~/.bashrc 【额外的tips】 PS1=`uname -n`&quot;:&quot;&#39;$USER&#39;&quot;:&quot;&#39;$PWD&#39;&quot;:&gt;&quot;; export PS1 于是得到了： localhost:mysqladmin:/usr/local/mysql:&gt; which 和 whereis 的区别 which 是直接查找可执行命令；whereis 不仅可以查找命令还可以查找文件位置。 别名[root@localhost ~]# alias jk=&#39;pwd&#39; ## 当前会话生效 【注意=前后不能有空格】 如果要永久生效需要配置在 &#x2F;etc&#x2F;profile 中 vi /etc/profile 添加一句 ：alias jdk=&#39;echo $JAVA_HOME&#39; 【注意=前后不能有空格】 source /etc/profile 用户列出所有用户1cat /etc/passwd|grep -v nologin|grep -v halt|grep -v shutdown|awk -F&quot;:&quot; &#x27;&#123; print $1&quot;|&quot;$3&quot;|&quot;$4 &#125;&#x27;|more 添加用户 [root@localhost ~]# useradd liqiang[root@localhost ~]# id liqianguid&#x3D;1002(liqiang) gid&#x3D;1002(liqiang) groups&#x3D;1002(liqiang)【 gid:主组； groups：所在的所有用户组】 查看用户、用户组 id liqiang 如果创建用户时，家目录空文件夹提前存在但没有配置文件，会报错： useradd: warning: the home directory already exists. Not copying any file from skel directory into it. 处理办法（把缺少的文件从 [/etc/skel/.*] 复制一份过来） [root@localhost ~]# cp /etc/skel/.* /home/liqiang/ 设置密码 [root@localhost ~]# passwd liqiang 删除用户 [root@localhost ~]# userdel liqiang【用户组下唯一用户删除时，用户组也会删】 创建用户组 [root@localhost ~]# group -g 101 dba[root@localhost ~]# useradd -u 514 -g dba -G root -d &#x2F;usr&#x2F;local&#x2F;mysql mysqladmin 将用户 liqiang 添加到另外一个用户组 bigdata [root@localhost ~]# usermod -a -G bigdata liqiang[root@localhost ~]# id liqianguid&#x3D;1002(liqiang) gid&#x3D;1002(liqiang) groups&#x3D;1002(liang),1003(bigdata) 修改主组【修改gid后groups也只剩主组这一个，需要添加原来的组到groups】 [root@localhost ~]# usermod –gid bigdata liqiang[root@localhost ~]# id liqianguid&#x3D;1002(liqiang) gid&#x3D;1003(bigdata) groups&#x3D;1003(bigdata)[root@localhost ~]# usermod -a -G liqiang liqianguid&#x3D;1002(liqiang) gid&#x3D;1003(bigdata) groups&#x3D;1003(bigdata),1002(liang) 权限 r4 w2 x1rwxr-xr-x 代表 755 第一组 rwx代表用户的权限 [读、写、执行] 第二组 r-x代表同用户组下其他用户的权限 [读、执行] 第三组 r-x代表其他用户组的权限 [读、执行] chown -R 用户:用户组 文件夹&#x2F;文件路径chmod -R 777 文件夹&#x2F;文件路径 [root@localhost ~]# chown -R mysqladmin:dba /usr/local/mysql [root@localhost ~]# chmod -R 755 /usr/loacl/mysql [root@localhost ~]# chmod +x /etc/rc.d/init.d/mysql 切换用户su ruoze 切换到用户，但pwd在切换前的目录（临时） su - ruoze 切换到该用户的家目录，且执行环境变量文件 .bash_profile su 不会执行;su - 都执行 .bashrc su 执行 ;su - 都执行 配置普通用户获取root的最大权限 [sudo] [root@localhost ~]# vi &#x2F;etc&#x2F;sudoers liqiang ALL=(ALL) NOPASSWD:ALL -rw-r–r– 1 root root 3 Jan 7 21:47 tmpdata.data [liqiang @localhost ~]# vi &#x2F;tmp&#x2F;tmpdata.data 【会发现编辑后无法保存】 [liqiang @localhost ~]# sudo vi &#x2F;tmp&#x2F;tmpdata.data 【获取root权限打开后就可以保存】 sudo su 一起使用的场景 [liqiang@Gargantua ~]$ su - mysqladminsu: Authentication failure 【liqiang用户是没有权限去切换到其他普通用户的】[liqiang@Gargantua ~]$ sudo su - mysqladmin 【需要sudo su - 一起使用】 服务查看服务进程号，端口号[root@localhost ~]# ps -ef|grep mysql # jps 查看java进程的pid [root@localhost ~]# netstat -nlp|grep pid # 查看当前活跃的所有端口 sudo netstat -nlp 防火墙云主机不需要 // 关闭 和 查看当前状态 service ipstables stop service ipstables status 检查ip &#x2F; 端口号通不通ping ip telnet ip:端口号 【yum install telnet】 查看系统磁盘，内存的命令df -h free -m # 内存剩余大小 free，Top，df的相关命令参考：https://blog.csdn.net/alawaka2018/article/details/80352216 查看机器负载 top 列表显示CPU占用 htop 详细显示CPU核心数占用&#x2F;内存占用【需要yum install -y htop】 iotop 磁盘读写消耗 iftop 网络传输，网卡消耗 PID USER PR NI VIRI RES SHR %CPU TIME+ COMMAND 进程强制结束 kill -9 [PID] PS 命令ps命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵尸、哪些进程占用了过多的资源等。常用的方法是ps -aux,然后再利用一个管道符号导向到grep去查找特定的进程,然后再对特定的进程进行操作。参考：https://www.cnblogs.com/abc8023/p/5459724.html ps a 显示现行终端机下的所有程序，包括其他用户的程序。 ps -A 显示所有程序。 ps c 列出程序时，显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示。 ps -e 此参数的效果和指定&quot;A&quot;参数相同。 ps e 列出程序时，显示每个程序所使用的环境变量。 ps f 用ASCII字符显示树状结构，表达程序间的相互关系。 ps -H 显示树状结构，表示程序间的相互关系。 ps -N 显示所有的程序，除了执行ps指令终端机下的程序之外。 ps s 采用程序信号的格式显示程序状况。 ps S 列出程序时，包括已中断的子程序资料。 ps u 以用户为主的格式来显示程序状况。 ps x 显示所有程序，不以终端机来区分。 查找僵尸进程 ps -ef | grep defunct # defunct 代表进程成为僵尸进程 或 获取stat状态为z&#x2F;Z的进程。【zombie prosess】 ps -A -ostat,ppid,pid,cmd | grep -e &#39;^[Zz]&#39; -A 参数列出所有进程 -o 自定义输出字段 我们设定显示字段为 stat（状态）, ppid（进程父id）, pid(进程id)，cmd（命令） # 可以使用 kill -HUP \\&lt;pid&gt; 指定杀死僵尸进程，确认kill不掉，则 kill -HUP \\&lt;ppid&gt; 或top 命令中状态为zombie Tasks: 95 total, 1 running, 94 sleeping, 0 stopped, 0 zombie 参考：https://cloud.tencent.com/developer/article/1804818https://cloud.tencent.com/developer/article/1114512 netstat命令参考：https://www.runoob.com/linux/linux-comm-netstat.html# 历史命令记录 查看&#x2F;清空history ; history -c ; date 命令使用“date -s”命令来修改系统时间 date -s 06/10/96 # 系统时间设定成1996年6月10日 date -s 13:12:00 # 将系统时间设定成下午1点12分0秒 快捷键12ctrl + a 将光标移动到当前命令头部ctrl + e 将光标移动到当前命令末尾 linux的 &#x2F;tmp 目录超过30天没有访问会自动删除关于部署服务的任何东西不要配置在&#x2F;tem下&#x2F;tmp 的权限是777，可以放一下需要传送的文件，不用考虑权限问题","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"昱东"},{"title":"【Vim】模式的切换、常用命令总结","slug":"【Vim】模式的切换、常用命令总结","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/【Vim】模式的切换、常用命令总结/","permalink":"http://example.com/2024/09/15/%E3%80%90Vim%E3%80%91%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%88%87%E6%8D%A2%E3%80%81%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/","excerpt":"","text":"参考总结自：https://blog.csdn.net/qq_39147299/article/details/108972206https://www.cnblogs.com/mabingxue/p/10281132.htmlhttps://zhidao.baidu.com/question/277761048.html 使用vi 打开文件时，默认是命令行模式（普通），编辑模式、尾行模式的切换都需要经过命令行模式。 命令行模式默认打开文件是为命令行模式，从其他模式按一次或多次ESC返回到命令行模式。进入vi的命令 12345vi filename :打开或新建文件,并将光标置于第一行首vi n filename ：打开文件,并将光标置于第n行首vi /pattern filename：打开文件,并将光标置于第一个与pattern匹配的串处vi -r filename ：在上次正用vi编辑时发生系统崩溃,恢复filenamevi filename....filename ：打开多个文件,依次进行编辑 在命令模式下，从键盘上输入的任何字符都被当作编辑命令来解释，如果输入的字符是合法的vi命令，则vi就会完成相应的动作；否则vi会响铃警告。 命令行模式光标移动 12H J K L左 下 上 右 命令行模式下的快捷命令 gg、G gg是回到第一行，G是回到最后一行，nG是去到指定的第n行。如果想要回到第20行，那就 “ 20G “ dd 剪切（删除）光标所在行如果想要删除20行，那就 “ 20dd “ d1G、dG d1G是删除当前行前面的所有数据，dG是删除当前行之后的全部数据 x、Xx是删除下一个字符，X是删除上一个字符如果想删除10个字符，那就” 10x “ yy 复制光标所在行如果想要复制20行，那就 “ 20yy “ y1G、yG y1G是复制当前行前面的所有数据，yG是复制当前行之后的全部数据 p、P p是粘贴到下一行，P是粘贴到上一行。3p就是重复粘贴三次。 u 撤销上一步操作，uuu撤销三步操作… Ctrl+r 反撤销 w 光标移动到下一个单词首部（每个标点符号算一个单词）。w可以结合其他命令一起使用，如yw复制单词，dw、cw e 光标移动到下一个单词尾部 b 光标回到上一次停留的单词处 dw 删除光标所在的一个单词 cw 改变一个单词 .(小数点) 重复上一个动作 编辑模式从命令行进入编辑模式: i, I （或insert键）i 为『在光标前的位置输入』， I 为『在光标所在行的最前输入』 a, Aa 为『在光标后的位置输入』， A 为『在光标所在行的末尾输入』 o, Oo 为『在光标所在行的下一行输入』； O 为『在光标所在行的上一行输入』 r, R 进入取代模式(或两次insert键)r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止 s从当前光标位置处开始,以输入的文本替代指定数目的字符 从编辑模式回到命令行模式只需要一次ESC。 尾行模式从命令行模式进入尾行模式需要按 shift+冒号&#x2F;分号。可以使用命令保存、替换、退出、显示行号等等；也可以使用&#x2F; 进入尾行模式并搜索内容。 尾行模式的操作命令： :w 将编辑过的文本保存:w! 强制保存:q 退出vim:q! 不保存退出。 （或直接命令行模式下的 ZQ）:wq 保存并退出 。（或直接命令行模式下的 ZZ）:w [filename] 文档另存为filename:r [filename] 在当前光标所在行的下面读入filename文档的内容 :n1,n2 w [filename] 将n1到n2的内容另存为filename这个文档 :e! 放弃所有修改，从上次保存文件开始再编辑 :! [command] 暂时离开vim并运行某个linux命令 :set nu 显示行号 (也可以在vim永久配置set number):set relativenumber 显示相对行号:set nonu 取消显示行号 :&#x2F;搜索的文本 ，搜索到的内容会高亮显示:%s&#x2F;要替换的字符&#x2F;替换后的字符&#x2F;g ，全局替换文本 tips：实现将文件的最后一行删除，可以不经过编辑模式：全程在命令行模式下，按G去到最后一行，按dG是删除当前行以及之后行，按 ZZ保存并退出。 在尾行模式执行完命令，或两次ESC就能回到命令行模式。 视觉模式从命令行模式进入视觉模式命令行模式输入v、V、Ctrl+v 就进入视觉模式，同时移动光标（方向键或hjkl都可以）就能选中对应的区域 v 是光标起始和结束之间的文本会被选中 V 是光标起始和结束之间的所有行被选中 Ctrl+v 是光标起始和结束之间构成的矩形区域被选中 选中的文本可以使用d删除。 恢复文件：vi在编辑某一个文件时，会生成一个临时文件，这个文件以 . 开头并以 .swp结尾。正常退出该文件自动删除，如果意外退出例如忽然断电，该文件不会删除，我们在下次编辑时可以选择一下命令处理： O只读打开，不改变文件内容 E继续编辑文件，不恢复.swp文件保存的内容 R将恢复上次编辑以后未保存文件内容 Q退出vi D删除.swp文件 或者使用vi －r 文件名来恢复未保存的内容","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"昱东"},{"title":"从加载数据库驱动包，理解java SPI","slug":"从加载数据库驱动包，理解java SPI","date":"2024-09-15T07:15:00.000Z","updated":"2024-09-15T07:15:00.000Z","comments":true,"path":"2024/09/15/从加载数据库驱动包，理解java SPI/","permalink":"http://example.com/2024/09/15/%E4%BB%8E%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E9%A9%B1%E5%8A%A8%E5%8C%85%EF%BC%8C%E7%90%86%E8%A7%A3java%20SPI/","excerpt":"","text":"SPI（Service Provider Interface）从1.6引入，基于ClassLoader 来加载并发现服务的机制 对于msyql驱动引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.27&lt;/version&gt;&lt;/dependency&gt; 在mysql:mysql-connector-java:8.0.27.jar中，可以找到META-INF&#x2F;services&#x2F;java.sql.Driver文件：java.sql.Drive 文件内容： 1com.mysql.cj.jdbc.Driver 找到com.mysql.cj.jdbc.Driver源码： 1234567891011121314151617package com.mysql.cj.jdbc;import java.sql.DriverManager;import java.sql.SQLException;public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; public Driver() throws SQLException &#123; &#125; static &#123; try &#123; DriverManager.registerDriver(new Driver()); &#125; catch (SQLException var1) &#123; throw new RuntimeException(&quot;Can&#x27;t register driver!&quot;); &#125; &#125;&#125; 它实现了java.sql.Driver 静态代码块中，向DriverManager注册了自己。 对于oracle驱动引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.hynnet&lt;/groupId&gt; &lt;artifactId&gt;oracle-driver-ojdbc6&lt;/artifactId&gt; &lt;version&gt;12.1.0.1&lt;/version&gt;&lt;/dependency&gt; 在com.hynnet:oracle-driver-ojdbc6-12.1.0.1.jar中，可以找到META-INF&#x2F;services&#x2F;java.sql.Driver文件： 1oracle.jdbc.OracleDriver 找到oracle.jdbc.OracleDriver源码： 1234567891011public class OracleDriver implements Driver &#123; // static &#123; try &#123; if (defaultDriver == null) &#123; defaultDriver = new oracle.jdbc.OracleDriver(); DriverManager.registerDriver(defaultDriver); &#125; &#125; catch // ... &#125;&#125; 它实现了java.sql.Driver 静态代码块中，向DriverManager注册了自己。 从DriverManager跟踪源码对于 DriverManager：1234567891011121314151617181920212223242526public class DriverManager &#123; static &#123; loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;); &#125; private static void loadInitialDrivers() &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); while(driversIterator.hasNext()) &#123; // 断点进到这里 driversIterator.next(); &#125; &#125; &#125;); // 最后还是根据拿到了从META-INF/services/java.sql.Driver里的Driver // 如com.mysql.cj.jdbc.Driver，并传入Class.forName() Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125;&#125; 在ServiceLoader里：1234567891011121314151617public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt; &#123; private static final String PREFIX = &quot;META-INF/services/&quot;; public boolean hasNext() &#123; // 进入driversIterator.hasNext() 后追到这里 if (acc == null) &#123; return hasNextService(); &#125; &#125; private boolean hasNextService() &#123; String fullName = PREFIX + service.getName(); configs = ClassLoader.getSystemResources(fullName); // 断点没有进 configs = loader.getResources(fullName); // 断点进到这里 &#125;&#125; 是在某个时机，触发DriverManager静态代码块，且只会执行这一次，紧接着一系列调用：–&gt; loadInitialDrivers()–&gt; ServiceLoader.load()、driversIterator.hasNext()–&gt; hasNextService()–&gt; loader.getResources(fullName) 最后使用classLoader.getResources() 加载所有包下”META-INF&#x2F;services&#x2F;java.sql.Driver”文件，得到当前所需数据库驱动包全限定名。 获取连接测试当使用Class.forName时12Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;); // 断点由此进入DriverManager静态代码块断点Connection conn = DriverManager.getConnection(&quot;***&quot;, &quot;root&quot;, &quot;123456&quot;); Class.forName() 中有一个本地方法 1private static native Class&lt;?&gt; forName0(String name, boolean initialize, ClassLoader loader, Class&lt;?&gt; caller) throws ClassNotFoundException; 经过这个本地方法后，断点进入DriverManager静态代码块断点，本地方法里做了啥？ 如何会触发DriverManager的类加载，不知道。。 但DriverManager静态代码确实只会执行一次，即便再次使用 Class.forName(“com.mysql.cj.jdbc.Driver”)时， 不会进入DriverManager静态代码块断点了 当不使用Class.forName，而直接DriverManager.getConnection时1Connection conn = DriverManager.getConnection(&quot;***&quot;, &quot;root&quot;, &quot;123456&quot;); // 断点由此进入DriverManager静态代码块断点 getConnection() 是静态方法，会触发执行DriverManager静态代码块，接着也是一系列的调用，加载所有包下”META-INF&#x2F;services&#x2F;java.sql.Driver”文件。 总结通过 DriverManager、ServiceLoader，在第一次获取连接前，总会去执行一次loader.getResources(fullName)，加载所有包下”META-INF&#x2F;services&#x2F;java.sql.Driver”文件中指定的类。 过程都由DriverManager、ServiceLoader设计好，获取驱动包名的目录“META-INF&#x2F;services”也由ServiceLoader定义为常量。 所以实现一个驱动，需要按照约定，在META-INF&#x2F;services&#x2F;java.sql.Driver中准备好驱动所在的全 限定名。便会有ClassLoader来发现和加载相应驱动。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"}],"author":"昱东"},{"title":"JVM结构、JVM参数、JVM垃圾回收","slug":"JVM结构、JVM参数、JVM垃圾回收","date":"2024-09-15T07:10:00.000Z","updated":"2024-09-15T07:10:00.000Z","comments":true,"path":"2024/09/15/JVM结构、JVM参数、JVM垃圾回收/","permalink":"http://example.com/2024/09/15/JVM%E7%BB%93%E6%9E%84%E3%80%81JVM%E5%8F%82%E6%95%B0%E3%80%81JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"JVM：Java Virtual Machine java虚拟机虚拟机：使用软件技术模拟出与具有完整硬件系统功能、运行在一个隔离环境中的计算机系统。JVM官方文档：https://docs.oracle.com/javase/specs/jvms/se8/html/index.html java 一些命令javac 将文件编译成.class文件java 执行 .class文件，若类中没有main函数，则不能执行。如 java -cp User.jar User 运行User.jarjavap 反编译器，显示编译类中可以访问的方法和数据。 如 javap -c 打开.class jar cvf User.jar User.class ：将User.class打jar包 ， 全部打包： jar -cvf xx.jar *jar xvf 解压jar JVM内存结构 类加载器子系统 执行引擎 本地方法库 运行时数据区： 程序计数器(program counter register –pc)：记录每个线程指令执行顺序、当前位置等。线程私有。 java虚拟机栈stack：每个线程有自己的栈，栈的创建同线程创建一起。栈有一系列栈帧组成，帧可以描述当前线程的一个方法的执行过程（每一个方法从调用直至执行完成的过程, 就对应着一个栈帧在虚拟机栈中入栈和出栈的过程），方法执行完就释放这个帧，也就释放了局部变量(基本数据类型、对象引用)的内存地址。 堆heap：存放对象实例和数组，线程共享。gc的区域，新生代和老年代。 方法区：已被加载的类信息(类的元数据)，常量，静态变量，静态代码块，编译器编译后的代码等。 1.8以后字符串常量池和静态变量移到堆；运行时常量池留在方法区中；删除永久代，替换为元空间(存数据的数据)。 本地方法栈(native method –底层其他语言，如C++)：执行本地方法需要的栈。 堆与方法区为线程共享，栈和程序计数器为线程私有。程序计数器标记了线程执行到哪儿了，线程切换了也可以回到它本来运行中断的地方；每个线程都要有个独立的程序计数器。 栈内存与堆内存数据结构的栈 ≠ jvm栈内存；数据结构的堆 ≠ jvm堆内存。数据结构：队列（Queue）和栈（Stack） 、链表、线性表、Map、Tree 数据结构：队列先进先出（排队）、栈先进后出 栈（Stack）：执行程序用，比如：基本类型的变量和对象的引用变量。堆（Heap）：存储java中的对象和数组, 存取速度较慢。gc的区域，新生代和老年代。 栈的空间大小远远小于堆。栈内存线程私有 （局部变量存在于栈内存）；堆内存所有线程共有（成员变量存在于堆内存所以有线程安全一说）。 栈：内存溢出 StackOverFlowError、OutofMemoryError堆：内存溢出 OutofMemoryError方法区：也会有 OutofMemoryError 常量池静态常量池（class文件常量池）存储在.class文件中。 每一份class文件都有一份自己的静态常量池。类和接口名字，字段名，和其他一些在class中引用的常量，如 CONSTANT_Class_info、CONSTANT_Utf8、CONSTANT_String、CONSTANT_Integer….. 静态常量池是在编译时就存入且不变更。 Class对象是存放在堆区的，不是方法区。而类的元数据（元数据并不是类的Class对象），即类的方法代码，变量名，方法名，访问权限，返回值等等都是在方法区的，存在方法区。 运行时常量池是方法区的一部分。 在类加载完成之后，将每个class常量池中的符号引用值转存到运行时常量池中。每个class都对应有一个运行时常量池，类在解析之后将符号引用替换成直接引用。具备动态性，运行期间也可能将新的常量放入池中。 字符串常量池存放字符串对象的实例(堆)。在每个JVM中都只会维护一份，所有类共享。 字符串常量池保存的是“字符”的实例，供运行时常量池引用。 -XX:StringTableSize&#x3D;1009 这个参数可以指定字符串常量池的容量。（JDK1.6默认为1009，JDK1.7之后默认为60013，字符串常量池底层为HashTable，合理增大常量池大小会解决Hash冲突问题，JDK1.8开始1009是可以设置的最小值） 字符串常量池、运行时常量池：关系、位置演化JDK1.7之前，字符串常量池是运行时常量池的一部分，一起存在方法区中。JDK1.7，字符串常量池和静态变量，移到堆中。运行时常量池还在方法区。字符串常量池不属于运行时常量池的一部分。JDK1.8，字符串常量池和静态变量还在堆中。但运行时常量池跟随方法区一起变成元空间，进入主内存。 验证字符串常量池的位置，是在heap堆中： 12345ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();for (int i = 0; i &lt; 100000000; i++) &#123; String temp = String.valueOf(i).intern(); list.add(temp);&#125; 12Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space ... JVM内存模型（JMM）Java线程之间的通信由Java内存模型控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见，线程私有内存和主内存之间的抽象关系。 JMM主要围绕可见性、原子性和有序性这三个特性而建立。具体来说： 可见性与共享变量在Java程序中，多个线程可能同时访问和修改共享变量。为了确保每个线程都能看到其他线程对共享变量所做的修改，Java内存模型提供了一系列规则。例如，volatile关键字可以确保变量的可见性，即当一个线程修改了一个volatile变量的值后，其他线程能够立即看到这个修改。此外，synchronized块也可以保证可见性，它确保在进入和退出synchronized块时，线程对共享变量的操作对其他线程是可见的。 有序性为了优化程序性能，编译器和处理器可能会对指令进行重排序。然而，这种重排序可能会导致多线程程序出现意想不到的结果。为了解决这个问题，Java内存模型定义了happens-before规则来确保多线程之间的操作顺序符合预期。简单来说，如果一个操作happens-before另一个操作，那么第一个操作的结果将对第二个操作可见。 原子性Java内存模型还规定了某些操作具有原子性。原子性意味着这些操作在执行过程中不会被其他线程中断（不发生线程上下文切换）。对于非原子性操作，我们需要使用锁等机制来保证线程安全。 垃圾回收机制 之 如何判断对象已“死” 引用计数法 给对象增加一个引用计数器，每当有一个地方引用它时，计数器就+1；当引用失效时，计数器就-1；任何时刻计数器为0的对象就是不能再被使用的，即对象已“死”。 但是, 对象之间存在相互引用, 就不会被回收. JAVA并没有采用此算法. 可达性分析算法 通过一系列称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索走过的路径称为“引用链”，当一个对象到 GC Roots 没有任何的引用链相连时(从 GC Roots 到这个对象不可达)时，证明此对象不可用。 当一个对象 与 GC Roots 没有任何引用链项链, 证明此对象不可用. 可作为GC Root的对象包含以下几种： - 虚拟机栈(栈帧中的本地变量表)中的引用 - 方法区中静态属性 - 方法区中常量 - 本地方法栈中(Native方法)引用的对象 垃圾回收机制 之 垃圾回收算法标记-清除算法算法分为标记和清除两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。后续的收集算法都是基于这种思路并对其不足加以改进而已。 标记和清除这两个过程的效率都不高 标记清除后会产生大量不连续的内存碎片，以后需要分配较大对象时，无法找到足够连续内存而不得不提前触发另一次垃圾收集。 复制算法(新生代回收算法)它将可用内存按容量划分为两块，每次只使用其中一块(并不是50%).当这块内存需要进行垃圾回收时，会将此区域还存活着的对象复制到另一块上面，然后再把已经使用过的内存区域一次清理掉。 现在的商用虚拟机(包括HotSpot)都是采用这种收集算法来回收新生代。 新生代中98%的对象很快就需要回收, 经过一次 复制活着的对象后, 只需要少量的空间来存放这部分活着的对象, 所以不需要1:1 ,而是将内存(新生代内存)分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor, 当回收时，将Eden和Survivor中还存活的对象一次性复制到另一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。默认Eden与Survivor的大小比例是8 : 2 (8:1:1) （两个Survivor是一叫From区，另一个To区） 部分对象会在From区域和To区域中复制来复制去，如此交换15次(默认)，最终如果还存活，就存入老年代。 复制收集算法在对象存活率较高时会进行比较多的复制操作，效率会变低。因此在老年代一般不能使用复制算法, 要使用标记-整理算法 标记-整理算法(老年代回收算法)标记过程仍与“标记-清除”过程一致，但后续步骤不是直接对可回收对象进行清理，而是让所有存活对象向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法不是指某种特定算法。是说针对新生代合老年代采用不同GC算法,(用不同的垃圾收集器) Minor GC又称为新生代GC :指的是发生在新生代的垃圾收集。因为Java对象大多都具备朝生夕灭的特性，因此Minor GC(采用复制算法)非常频繁，一般回收速度也比较快。 Full GC 又称为老年代GC或者Major GC : 指发生在老年代的垃圾收集。出现了Major GC，经常会伴随至少一次的Minor GC(并非绝对，在Parallel Scavenge收集器中就有直接进行Full GC的策略选择过程)。Major GC的速度一般会比Minor GC慢10倍以上。 new Object() 申请堆内存空间过程先在 Eden 申请，可用就创建对象；不够 MinorGC(新生代-复制算法)。GC后再次判断Eden，可用就创建, 不够再判断Survivor(from) 还有空间? 有就创建，否则判断 Old，可用就在 Old创建，不够 FullGC。 再次判断Old，可用就创建，否则GC。 垃圾收集器语义： serial 【串行】 启用的时候会暂停所有线程 只有一个线程来GC 不适用服务器环境 Parallel 【并行】 启用的时候会暂停所有线程 多个线程来GC CMS（Concurrent Mark Sweep） 【并发】 一部分线程GC, 其他线程继续运行 （初始标记的时候也会stw，只是收集的过程中并发） G1 （Garbage-First）指定垃圾收集 ： -XX:+UseSerialGC 新生代 + 老年代 都是串行，即Serial + Serial old（新是复制，老是整理） -XX:+UsePerNewGC PerNew + Serial old -XX:+UseParalleGC Parallel Sce + Parallel Old 【jdk8的默认] -XX:+UseConcMarkSweepGC 老年代开启CMS。新生代开启PerNew -XX:+UseG1GC G1 同时适用 young 和 old 适用大内存，多core。追求更短的stw的时间，在jdk1.7u4支持。在jdk1.9的默认收集器 把整个Heap都重新分配了，划分成很多Region，2048个，每个大小范围[1M,32M] 所以Heap最大64G。 Region： Eden、Servivor、Old、Humongous(巨大的：超过region一半大小) 没有碎片 其他的收集器：ZGC(jdk11)、Shenandoan（openJDK） 新生代和老年代大小默认比例大约1：2新生代中eden：s0：s1 的比例也和垃圾收集器有关，通常说的是 8：1：1 其实是 SerialGC 的时候而Java8默认Parallel GC 的话，比例大约是 4：1：1也可以手动改比例：-XX:ServivorRatio&#x3D;8 垃圾收集器如何选择对1.8来说，CMS&#x2F;G1中选一个。 程序很小，单进程：串行就行 多核、高吞吐：ps 多核、少暂停时间：cms 多核、内存连续：G1 CMS 收集器Concurrent Mark Sweep：可并发的标记-清除 （也有碎片） 1-XX:+UseConcMarkSweepGC # 老年代开启CMS。新生代开启PerNew CMS参考：https://plumbr.io/handbook/garbage-collection-algorithms-implementations/concurrent-mark-and-sweep Phase 1: Initial Mark. （会stw）mark all the objects in the Old Generation that are either direct GC roots or are referenced from some live object in the Young Generation.会在old中标记直接由GC root 可达对象、和由young中存活对象引用的old 中的对象 Phase 2: Concurrent Mark. （不会stw）在根据上阶段标记的对象，沿着引用链标记 Phase 3: Concurrent Preclean.（不会stw）清除 Phase 4: Concurrent Abortable Preclean. （不会stw） Phase 5: Final Remark.（会 stw）最后标记，因为是上一阶段的标记是并发的，标记的过程中可能同时发生新的引用变更，最后需要stw，再标记一次。 Phase 6: Concurrent Sweep.(不会 stw) Phase 7: Concurrent Reset. 合并步骤为5步：（三次Mark，一次Sweep） Initial Mark. Concurrent Mark. Final Remark. Concurrent Sweep. Reset. G1 收集器Garbage-First 1-XX:+UseG1GC G1 同时适用 young 和 old适用大内存，多core。追求更短的stw的时间，在jdk1.7u4支持。在jdk1.9的默认收集器把整个Heap都重新分配了，划分成很多Region，2048个，每个大小范围[1M,32M] 所以Heap最大64G。Region： Eden、Servivor、Old、Humongous(巨大的：超过region一半大小)没有碎片 G1如何做到可预测停顿时间：通过自己管理的大小不一的region，判断可回收的空间，以及回收的开销大小，做到优先回收回收效率最高的部分region（如 region1 10M，500ms，region2 50M，100ms,优先回收region2） GC 日志解析日志中语义:DefNew：新生代串行 （Serial ）Tenured：老年代串行 （Serial old） PerNew： 新生代并行 （PerNew ） PSYoungGen：新生代并行 （Parallel Sce）ParOldGen：老年代并行 （Parallel Old ） JVM参数 X 参数java -Xmixed -version 【# 开启 mixed mode 】java -Xint -version 【# 开启 interpreted mode (解释模式，字节码直接执行)】 XX 参数-XX:[+&#x2F;-] 属性名 （启用&#x2F;禁用某属性）如： -XX:+UseG1GC-XX:name&#x3D;value (为某属性设置值) 如：-XX:MaxTenuringThreshold&#x3D;10 举例：设置最大、最小堆内存-Xmx -XX:MaxHeapSize 的简写，设置最大堆内存，默认为物理内存的1&#x2F;4 1-Xms1024m -Xms -XX:InitialHeapSize 的简写，设置最小堆内存。默认为物理内存的1&#x2F;64 123-Xms1024k# 或-Xms2m 举例：设置栈的大小-Xss -XX:ThreadStackSize 的简写。（不写单位就默认单位字节） 1-Xss1024k 举例：查看这个进程是否开启了GC明细输出的开关jinfo -flag 命令可以查看JVM参数 1jinfo -flag PrintGCDetails &lt;pid&gt; 如果输出： 1-XX:-PrintGCDetails # 代表没打开 所以在启动前，可以设置开启GC日志输出 1-XX:+PrintGCDetails 举例：开启类加载过程日志1-XX:+TraceClassLoading 会发现先从 jre&#x2F;lib&#x2F;rt.jar 加载依赖包，再从当前项目target&#x2F;classes下加载自己创建的类","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"jvm","slug":"Java/jvm","permalink":"http://example.com/categories/Java/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://example.com/tags/jvm/"},{"name":"jvm垃圾回收","slug":"jvm垃圾回收","permalink":"http://example.com/tags/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"}],"author":"昱东"},{"title":"java8函数式接口，以及stream流中map、peek、foreach区别","slug":"java8函数式接口，以及stream流中map、peek、foreach区别","date":"2024-09-15T07:05:00.000Z","updated":"2024-09-15T07:05:00.000Z","comments":true,"path":"2024/09/15/java8函数式接口，以及stream流中map、peek、foreach区别/","permalink":"http://example.com/2024/09/15/java8%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3%EF%BC%8C%E4%BB%A5%E5%8F%8Astream%E6%B5%81%E4%B8%ADmap%E3%80%81peek%E3%80%81foreach%E5%8C%BA%E5%88%AB/","excerpt":"","text":"java8常用函数式接口12345import java.util.function.Supplier;import java.util.function.Consumer;import java.util.function.Function;import java.util.function.BiConsumer;import java.util.function.BiFunction; Supplier12345@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get(); // 无参，有返&#125; Consumer123456@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; void accept(T t); // 有参，无返 // 默认方法&#125; Function123456@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; R apply(T t); // 有参，有返 // 默认方法、static方法&#125; BiConsumer123456@FunctionalInterfacepublic interface BiConsumer&lt;T, U&gt; &#123; void accept(T t, U u); // 默认方法&#125; BiFunction123456@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; &#123; R apply(T t, U u); // 默认方法&#125; Predicate123456@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; boolean test(T t); // 默认方法&#125; &#x2F;&#x2F; Bi开头的，BiConsumer和 BiFunction，都至少接受两个参数。而Consumer和 Function都是一个参数。 java8常用stream API filter stream().filter(Predicate p); 要求传入 Predicate，有参数，且返回布尔值，并生成原类型的stream流。 map stream().map(Function mapper); 要求传入Function, 有参数，有返回值。 map会对每一个元素映射为另一个返回值，并生成新类型的stream流。 peek stream().peek(Consumer action); 要求传入Consumer，有参数，无返回值。 peek会操作每一个元素，但返回原来的流。 forEach stream().forEach(Consumer action)；要求传入Consumer，有参数，无返回值。但forEach不再返回流了，是一个流结束函数。 collect stream().collect(); 有两个重载方法参数列表，都不再返回流，而是返回某种集合类型。 123&lt;R&gt; R collect(Supplier supplier, BiConsumer accumulator, BiConsumer combiner);&lt;R, A&gt; R collect(Collector collector); // Collector接口中，也规范了supplier(),accumulator(),combiner()方法，本质和上面差不多 toMap stream().collect(Collectors.toMap());Collectors.toMap(), 有三个重载方法参数列表 12345678910111213// 两个Function类型参数 key，value, 实际上是去调用另一个重载方法，throwingMerger()：当key相同时，会抛出异常；Collector toMap(Function keyMapper, Function valueMapper) &#123; return toMap(keyMapper, valueMapper, throwingMerger(), HashMap::new);&#125;// 两个Function类型参数 key，value + 一个父类为BiFunction的mergeFunction，BiFunction接收两个参数，聚合后一个返回值：当key相同时，如何合并。Collector toMap(Function keyMapper, Function valueMapper, BinaryOperator mergeFunction) &#123; return toMap(keyMapper, valueMapper, mergeFunction, HashMap::new);&#125;// 实际上他们都是调用四个参数的重载方法，对传入的mergeFunction，也是使用java.util.Map中的merge方法来合并Collector toMap(Function keyMapper,Function valueMapper,BinaryOperator mergeFunction,Supplier&lt;M&gt; mapSupplier) &#123; BiConsumer accumulator = (map, element) -&gt; map.merge(keyMapper.apply(element), valueMapper.apply(element), mergeFunction); return new CollectorImpl&lt;&gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);&#125; 其他stream流常用APIstream().distinct()stream().count()stream().sorted()stream().findFirst()stream().findAny()stream().anyMatch()stream().allMatch()stream().noneMatch()stream().max()stream().min().stream().toArray(IntFunction&lt;A[]&gt; generator) &#x2F;&#x2F; 返回指定类型的数组 A[] toArray(IntFunction&lt;A[]&gt; generator)12345String[] split = &quot;0,0,1,1,2,2,3,3,4,5,5,6,7,9,9,11,17,18,18,19&quot;.split(&quot;,&quot;);Integer[] integers = Arrays.stream(split).map(Integer::parseInt).toArray(size-&gt;new Integer[size]);Integer[] integers = Arrays.stream(split).map(Integer::parseInt).toArray(Integer[]::new); int[] integers = Arrays.stream(split).mapToInt(Integer::parseInt).toArray(); 12.stream(split).map(Integer::parseInt) // 返回的是 Stream&lt;R&gt;.stream(split).mapToInt(Integer::parseInt) // 返回的是 IntStream，通过流结束函数最终可以直接返回int、int[] Optional中filter、map、ifPresent map1Optional.ofNullable(customer).map(Function mapper) 在Optional中，map也是要求传入Function，有参数，有返回值，map返回一个新类型的Optional。 filter1Optional.ofNullable(customer).filter(Predicate p) filter也是要求传入 Predicate，有参数，且返回布尔值，返回原类型的Optional。 ifPresent1Optional.ofNullable(customer).ifPresent(Consumer action); 而ifPresent与forEach类似，要求传入Consumer，有参数，无返回值，且结束后不再返回Optional，结束这个Optional。 Runnable、Closeable 也是函数式接口（无参数，无返回值） Runnable1234@FunctionalInterfacepublic interface Runnable &#123; public abstract void run();&#125; Closeable123public interface Closeable extends AutoCloseable &#123; public void close() throws IOException;&#125; 匿名内部类在不熟悉Runnable、Function、Consumer、BiFunction、BiConsumer区别时，可以new Runnable()并按提示生成匿名内部类例如： 123456 new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;hello word！&quot;); &#125;&#125;); 再按提示转成lambda，但明确这几项函数式接口的参数和返回值后，可以直接写lambda 直接写lambda表达式 Runnable: 无参数，无返回值。直接写出lambda： 1()-&gt;&#123;System.out.println(&quot;hello word！&quot;);&#125; 方法体只有一行省略掉大括号：()-&gt;System.out.println(“hello word！”) Predicate：有参数，需要返回值（布尔）。直接写出lambda： 1(e)-&gt;&#123;return e.getId() &gt; 0;&#125; 参数只有一个可以省略括号，方法体加返回只有一行又可以省略大括号和return关键字：e-&gt; e.getId() &gt; 0 Function：有参数，有返回值。直接写出lambda： 1(e)-&gt;&#123;return e.getId();&#125; 参数只有一个可以省略括号，方法体加返回只有一行又可以省略大括号和return关键字：e-&gt;e.getId() e是上一步函数的返回值作为当前函数参数，又可省略掉参数声明，做方法引用：Customer::getId Consumer：有参数，无返回值。直接写出lambda： 1(e)-&gt;&#123;system.out.println(e);&#125; 参数只有一个可以省略括号，但方法体只有一行又可以省略大括号：e-&gt;System.out.println(e) e是上一步函数的返回值作为当前函数参数并又作为参数传入sout，又可省略掉参数声明，做方法引用：System.out::println BiConsumer：有两个参数，无返回值。直接写出lambda： 1(k1, k2)-&gt;&#123;System.out.println(k1 + k2);&#125; 参数数量大于1不能省略小括号，但方法体只有一行又可以省略大括号：(k1, k2)-&gt;System.out.println(k1 + k2) BiFunction：有两个参数，有返回值。直接写出lambda： 1(k1, k2)-&gt;&#123;return k1 + k2;&#125; 参数大于1不能省略小括号，但方法体加返回只有一行又可以省略大括号和return关键字：(k1, k2)-&gt;k1 + k2","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"}],"author":"昱东"},{"title":"云主机部署TiDB测试集群","slug":"云主机部署TiDB测试集群","date":"2024-09-15T07:00:00.000Z","updated":"2024-09-15T07:00:00.000Z","comments":true,"path":"2024/09/15/云主机部署TiDB测试集群/","permalink":"http://example.com/2024/09/15/%E4%BA%91%E4%B8%BB%E6%9C%BA%E9%83%A8%E7%BD%B2TiDB%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4/","excerpt":"","text":"环境准备购买了4台按量付费云主机 主机名称 公网ip 局域网ip tidb0 47.109.27.111 172.16.69.205 tidb1 47.108.114.70 172.16.69.207 tidb2 47.108.213.190 172.16.69.206 tidb3 47.109.183.173 172.16.69.208 tidb0 将用于部署PD server ， TiDB server 和 其他监控组件。tidb1、tidb2、tidb3 将组成TiKV server集群。 4台主机都设置了相同SSH登录账号root和相同密码，这个SSH密码除了在首次进入中控机要使用，更会在配置集群时用于与集群中其他主机通信。 文章发出时，以上所有实例已经释放。 SSH到tidb0，接下来所有操作都在这台中控机上完成，由tidb0自动完成tidb1、2、3的部署。 看一下系统情况： 1234567891011[root@tidb0 ~]# hostnamectl Static hostname: tidb0 Icon name: computer-vm Chassis: vm Machine ID: 20190711105006363114529432776998 Boot ID: 73cbbc178f38445c96e86df65e3663ca Virtualization: kvm Operating System: CentOS Linux 7 (Core) CPE OS Name: cpe:/o:centos:centos:7 Kernel: Linux 3.10.0-957.21.3.el7.x86_64 Architecture: x86-64 参考官网https://docs.pingcap.com/zh/tidb/v5.4/production-deployment-using-tiup#%E7%AC%AC-2-%E6%AD%A5%E5%9C%A8%E4%B8%AD%E6%8E%A7%E6%9C%BA%E4%B8%8A%E9%83%A8%E7%BD%B2-tiup-%E7%BB%84%E4%BB%B6 本次也采用在线部署。部署TIDB版本为5.4.1。 在线安装 执行如下命令安装 TiUP 工具curl –proto ‘&#x3D;https’ –tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh 123456789101112131415[root@tidb0 ~]# curl --proto &#x27;=https&#x27; --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 5149k 100 5149k 0 0 3341k 0 0:00:01 0:00:01 --:--:-- 3341kWARN: adding root certificate via internet: https://tiup-mirrors.pingcap.com/root.jsonYou can revoke this by remove /root/.tiup/bin/7b8e153f2e2d0928.root.jsonSuccessfully set mirror to https://tiup-mirrors.pingcap.comDetected shell: bashShell profile: /root/.bash_profile/root/.bash_profile has been modified to add tiup to PATHopen a new terminal or source /root/.bash_profile to use itInstalled path: /root/.tiup/bin/tiup===============================================Have a try: tiup playground=============================================== 使用source命令重新生效环境变量，是为了能在当前会话使用 tiup工具命令 1source /root/.bash_profile 验证tiup命令可用 &#x2F; 确认 TiUP 工具是否安装 1which tiup 安装 TiUP cluster 组件 1tiup cluster 会开始下载，直到出现：Use “tiup cluster help [command]” for more information about a command. 不管三七二十一，更新 TiUP cluster 组件至最新版本： 1tiup update --self &amp;&amp; tiup update cluster 预期输出 “Update successfully!” 字样。 验证当前 TiUP cluster 版本信息。执行如下命令查看 TiUP cluster 组件版本12[root@tidb0 ~]# tiup --binary cluster/root/.tiup/components/cluster/v1.16.0/tiup-cluster 初始化集群拓扑文件 使用命令生成一个topology.yaml文件 tiup cluster template &gt; topology.yaml 123[root@tidb0 ~]# tiup cluster template &gt; topology.yaml[root@tidb0 ~]# lstopology.yaml vim打开topology.yaml后，修改对应的ip。 其中tiflash是优化查询缓存用，测试环境时可以去掉这一项。 修改后的文件： 12345678910111213141516171819202122global: user: &quot;tidb&quot; ssh_port: 22 deploy_dir: &quot;/tidb-deploy&quot; data_dir: &quot;/tidb-data&quot;server_configs: &#123;&#125;pd_servers: - host: 172.16.69.205tidb_servers: - host: 172.16.69.205tikv_servers: - host: 172.16.69.207 - host: 172.16.69.206 - host: 172.16.69.208monitoring_servers: - host: 172.16.69.205grafana_servers: - host: 172.16.69.205alertmanager_servers: - host: 172.16.69.205 保存并退出. 检查集群存在的潜在风险：命令模板：tiup cluster check .&#x2F;topology.yaml –user root [-p] [-i &#x2F;home&#x2F;root&#x2F;.ssh&#x2F;gcp_rsa] 其中： 123topology.yaml 就是刚才初始化的配置文件--user root 表示通过 root 用户登录到目标主机完成集群部署，该用户需要有 ssh 到目标机器的权限，并且在目标机器有 sudo 权限。也可以用其他有 ssh 和 sudo 权限的用户完成部署。[-i] 及 [-p] 为可选项，如果已经配置免密登录目标机，则不需填写。否则选择其一即可，[-i] 为可登录到目标机的 root 用户（或 --user 指定的其他用户）的私钥，也可使用 [-p] 交互式输入该用户的密码。 实际执行命令： 1tiup cluster check ./topology.yaml --user root -p 提示输入密码就是上述连接SSH时用到的密码。 检查结果中，有很多Warn和Fail。 由于只是测试环境，就不管这些了。生产环境需要处理。 尝试自动修复集群存在的潜在风险： 1tiup cluster check ./topology.yaml --apply --user root -p 修复命令可能是起不了作用的。 准备部署 TiDB 集群 先看以下没有部署成功时，执行tiup cluster list的结果： 123[root@tidb0 ~]# tiup cluster listName User Version Path PrivateKey---- ---- ------- ---- ---------- 部署 TiDB 集群1tiup cluster deploy tidb-test v5.4.1 ./topology.yaml --user root -p 其中：12345tidb-test 为部署的集群名称，v5.4.1 为部署的集群版本，topology.yaml 就是刚才初始化的配置文件--user root 表示通过 root 用户登录到目标主机完成集群部署，该用户需要有 ssh 到目标机器的权限，并且在目标机器有 sudo 权限。也可以用其他有 ssh 和 sudo 权限的用户完成部署。[-i] 及 [-p] 为可选项，如果已经配置免密登录目标机，则不需填写。否则选择其一即可，[-i] 为可登录到目标机的 root 用户（或 --user 指定的其他用户）的私钥，也可使用 [-p] 交互式输入该用户的密码。 提示输入密码就是上述连接SSH时用到的密码。执行后会去到集群中目标主机自动完成部署操作。 预期日志结尾输出 Cluster tidb-test deployed successfully, you can start it with command: tiup cluster start tidb-test --init表示部署成功。 tiup cluster start tidb-test --init 就是后面用于启动集群的命令；但在此之前，可以再通过tiup cluster list看看集群情况。 1234[root@tidb0 ~]# tiup cluster listName User Version Path PrivateKey---- ---- ------- ---- ----------tidb-test tidb v5.4.1 /root/.tiup/storage/cluster/clusters/tidb-test /root/.tiup/storage/cluster/clusters/tidb-test/ssh/id_rsa 检查 tidb-test 集群情况123456789101112131415161718[root@tidb0 ~]# tiup cluster display tidb-testCluster type: tidbCluster name: tidb-testCluster version: v5.4.1Deploy user: tidbSSH type: builtinGrafana URL: http://172.16.69.205:3000ID Role Host Ports OS/Arch Status Data Dir Deploy Dir-- ---- ---- ----- ------- ------ -------- ----------172.16.69.205:9093 alertmanager 172.16.69.205 9093/9094 linux/x86_64 Down /tidb-data/alertmanager-9093 /tidb-deploy/alertmanager-9093172.16.69.205:3000 grafana 172.16.69.205 3000 linux/x86_64 Down - /tidb-deploy/grafana-3000172.16.69.205:2379 pd 172.16.69.205 2379/2380 linux/x86_64 Down /tidb-data/pd-2379 /tidb-deploy/pd-2379172.16.69.205:9090 prometheus 172.16.69.205 9090/12020 linux/x86_64 Down /tidb-data/prometheus-9090 /tidb-deploy/prometheus-9090172.16.69.205:4000 tidb 172.16.69.205 4000/10080 linux/x86_64 Down - /tidb-deploy/tidb-4000172.16.69.206:20160 tikv 172.16.69.206 20160/20180 linux/x86_64 N/A /tidb-data/tikv-20160 /tidb-deploy/tikv-20160172.16.69.207:20160 tikv 172.16.69.207 20160/20180 linux/x86_64 N/A /tidb-data/tikv-20160 /tidb-deploy/tikv-20160172.16.69.208:20160 tikv 172.16.69.208 20160/20180 linux/x86_64 N/A /tidb-data/tikv-20160 /tidb-deploy/tikv-20160Total nodes: 8 预期输出包括 tidb-test 集群中实例 ID、角色、主机、监听端口和状态（由于还未启动，所以状态为 Down&#x2F;inactive）、目录信息。 启动集群 普通启动。可通过无密码的 root 用户登录数据库。 1tiup cluster start tidb-test 预期结果输出 Started cluster tidb-test successfully，表示启动成功 安全启动。必须使用米姆登录数据库，所以启动时需要记录命令行返回的密码。自动生成的密码只会返回一次。 1tiup cluster start tidb-test --init 预期结果如下，表示启动成功。 1234567891011... Start 172.16.69.206 success Start 172.16.69.205 success Start 172.16.69.208 success Start 172.16.69.207 success...Started cluster `tidb-test` successfullyThe root password of TiDB database has been changed.The new password is: &#x27;U719-^8@FHGM0Ln4*p&#x27;.Copy and record it to somewhere safe, it is only displayed once, and will not be stored.The generated password can NOT be get and shown again. 上述临时密码U719-^8@FHGM0Ln4*p就用于登录tidb。（文章发出时此密码已经不可用） 再次检查 tidb-test 集群状态时， 可以看到状态不再是Down而是Up，代表集群已经在正常运行了。 1tiup cluster display tidb-test 12345678910111213141516171819[root@tidb0 ~]# tiup cluster display tidb-testCluster type: tidbCluster name: tidb-testCluster version: v5.4.1Deploy user: tidbSSH type: builtinDashboard URL: http://172.16.69.205:2379/dashboardGrafana URL: http://172.16.69.205:3000ID Role Host Ports OS/Arch Status Data Dir Deploy Dir-- ---- ---- ----- ------- ------ -------- ----------172.16.69.205:9093 alertmanager 172.16.69.205 9093/9094 linux/x86_64 Up /tidb-data/alertmanager-9093 /tidb-deploy/alertmanager-9093172.16.69.205:3000 grafana 172.16.69.205 3000 linux/x86_64 Up - /tidb-deploy/grafana-3000172.16.69.205:2379 pd 172.16.69.205 2379/2380 linux/x86_64 Up|L|UI /tidb-data/pd-2379 /tidb-deploy/pd-2379172.16.69.205:9090 prometheus 172.16.69.205 9090/12020 linux/x86_64 Up /tidb-data/prometheus-9090 /tidb-deploy/prometheus-9090172.16.69.205:4000 tidb 172.16.69.205 4000/10080 linux/x86_64 Up - /tidb-deploy/tidb-4000172.16.69.206:20160 tikv 172.16.69.206 20160/20180 linux/x86_64 Up /tidb-data/tikv-20160 /tidb-deploy/tikv-20160172.16.69.207:20160 tikv 172.16.69.207 20160/20180 linux/x86_64 Up /tidb-data/tikv-20160 /tidb-deploy/tikv-20160172.16.69.208:20160 tikv 172.16.69.208 20160/20180 linux/x86_64 Up /tidb-data/tikv-20160 /tidb-deploy/tikv-20160Total nodes: 8 tidb的端口 4000 需要云主机上开启安全组。 简单做个连接测试 123456Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);Connection conn = DriverManager.getConnection(&quot;jdbc:mysql://47.109.27.111:4000/test?useSSL=false&amp;allowPublicKeyRetrieval=true&amp;serverTimezone=Asia/Shanghai&quot;, &quot;root&quot;, &quot;U719-^8@FHGM0Ln4*p&quot;);System.out.println(&quot;获取mysql连接成功&quot;);conn.close(); 获取mysql连接成功 全部部署过程和命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627shell 6 (Build 0204)Copyright (c) 2002 NetSarang Computer, Inc. All rights reserved.Type `help&#x27; to learn how to use Xshell prompt.[C:\\~]$ Connecting to 47.109.27.111:22...Connection established.To escape to local shell, press &#x27;Ctrl+Alt+]&#x27;.WARNING! The remote SSH server rejected X11 forwarding request.Last login: Sat Aug 17 17:27:46 2024 from 118.112.72.89Welcome to Alibaba Cloud Elastic Compute Service ![root@tidb0 ~]# hostnamectl Static hostname: tidb0 Icon name: computer-vm Chassis: vm Machine ID: 20190711105006363114529432776998 Boot ID: 73cbbc178f38445c96e86df65e3663ca Virtualization: kvm Operating System: CentOS Linux 7 (Core) CPE OS Name: cpe:/o:centos:centos:7 Kernel: Linux 3.10.0-957.21.3.el7.x86_64 Architecture: x86-64[root@tidb0 ~]# curl --proto &#x27;=https&#x27; --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 5149k 100 5149k 0 0 3341k 0 0:00:01 0:00:01 --:--:-- 3341kWARN: adding root certificate via internet: https://tiup-mirrors.pingcap.com/root.jsonYou can revoke this by remove /root/.tiup/bin/7b8e153f2e2d0928.root.jsonSuccessfully set mirror to https://tiup-mirrors.pingcap.comDetected shell: bashShell profile: /root/.bash_profile/root/.bash_profile has been modified to add tiup to PATHopen a new terminal or source /root/.bash_profile to use itInstalled path: /root/.tiup/bin/tiup===============================================Have a try: tiup playground===============================================[root@tidb0 ~]# source /root/.bash_profile[root@tidb0 ~]# which tiup/root/.tiup/bin/tiup[root@tidb0 ~]# tiup clusterChecking updates for component cluster... Timedout (after 2s)The component `cluster` version is not installed; downloading from repository.download https://tiup-mirrors.pingcap.com/cluster-v1.16.0-linux-amd64.tar.gz 8.83 MiB / 8.83 MiB 100.00% 55.35 MiB/s Deploy a TiDB cluster for productionUsage: tiup cluster [command]Available Commands: check Perform preflight checks for the cluster. deploy Deploy a cluster for production start Start a TiDB cluster stop Stop a TiDB cluster restart Restart a TiDB cluster scale-in Scale in a TiDB cluster scale-out Scale out a TiDB cluster destroy Destroy a specified cluster clean (EXPERIMENTAL) Cleanup a specified cluster upgrade Upgrade a specified TiDB cluster display Display information of a TiDB cluster prune Destroy and remove instances that is in tombstone state list List all clusters audit Show audit log of cluster operation import Import an exist TiDB cluster from TiDB-Ansible edit-config Edit TiDB cluster config show-config Show TiDB cluster config reload Reload a TiDB cluster&#x27;s config and restart if needed patch Replace the remote package with a specified package and restart the service rename Rename the cluster enable Enable a TiDB cluster automatically at boot disable Disable automatic enabling of TiDB clusters at boot replay Replay previous operation and skip successed steps template Print topology template tls Enable/Disable TLS between TiDB components meta backup/restore meta information rotatessh rotate ssh keys on all nodes help Help about any command completion Generate the autocompletion script for the specified shellFlags: -c, --concurrency int max number of parallel tasks allowed (default 5) --format string (EXPERIMENTAL) The format of output, available values are [default, json] (default &quot;default&quot;) -h, --help help for tiup --ssh string (EXPERIMENTAL) The executor type: &#x27;builtin&#x27;, &#x27;system&#x27;, &#x27;none&#x27;. --ssh-timeout uint Timeout in seconds to connect host via SSH, ignored for operations that don&#x27;t need an SSH connection. (default 5) -v, --version version for tiup --wait-timeout uint Timeout in seconds to wait for an operation to complete, ignored for operations that don&#x27;t fit. (default 120) -y, --yes Skip all confirmations and assumes &#x27;yes&#x27;Use &quot;tiup cluster help [command]&quot; for more information about a command.[root@tidb0 ~]# tiup update --self &amp;&amp; tiup update clusterdownload https://tiup-mirrors.pingcap.com/tiup-v1.16.0-linux-amd64.tar.gz 5.03 MiB / 5.03 MiB 100.00% 36.52 MiB/s Updated successfully!component cluster version v1.16.0 is already installedUpdated successfully![root@tidb0 ~]# tiup --binary cluster/root/.tiup/components/cluster/v1.16.0/tiup-cluster[root@tidb0 ~]# tiup cluster template &gt; topology.yaml[root@tidb0 ~]# lstopology.yaml[root@tidb0 ~]# vim topology.yaml [root@tidb0 ~]# tiup cluster check ./topology.yaml --user root -pInput SSH password: + Detect CPU Arch Name - Detecting node 172.16.69.205 Arch info ... Done - Detecting node 172.16.69.207 Arch info ... Done - Detecting node 172.16.69.206 Arch info ... Done - Detecting node 172.16.69.208 Arch info ... Done+ Detect CPU OS Name - Detecting node 172.16.69.205 OS info ... Done - Detecting node 172.16.69.207 OS info ... Done - Detecting node 172.16.69.206 OS info ... Done - Detecting node 172.16.69.208 OS info ... Done+ Download necessary tools - Downloading check tools for linux/amd64 ... Done+ Collect basic system information - Getting system info of 172.16.69.205:22 ... ⠼ CopyComponent: component=insight, version=, remote=172.16.69.205:/tmp/ti...+ Collect basic system information+ Collect basic system information+ Collect basic system information - Getting system info of 172.16.69.205:22 ... Done - Getting system info of 172.16.69.207:22 ... Done - Getting system info of 172.16.69.206:22 ... Done - Getting system info of 172.16.69.208:22 ... Done+ Check time zone - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.207 ... Done - Checking node 172.16.69.206 ... Done - Checking node 172.16.69.208 ... Done+ Check system requirements - Checking node 172.16.69.205 ... ⠦ CheckSys: host=172.16.69.205 type=exist+ Check system requirements - Checking node 172.16.69.205 ... Done+ Check system requirements+ Check system requirements - Checking node 172.16.69.205 ... Done+ Check system requirements+ Check system requirements+ Check system requirements+ Check system requirements+ Check system requirements+ Check system requirements - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.207 ... Done - Checking node 172.16.69.206 ... Done - Checking node 172.16.69.208 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.207 ... Done - Checking node 172.16.69.206 ... Done - Checking node 172.16.69.208 ... Done+ Cleanup check files - Cleanup check files on 172.16.69.205:22 ... Done - Cleanup check files on 172.16.69.207:22 ... Done - Cleanup check files on 172.16.69.206:22 ... Done - Cleanup check files on 172.16.69.208:22 ... DoneNode Check Result Message---- ----- ------ -------172.16.69.207 timezone Pass time zone is the same as the first PD machine: Asia/Shanghai172.16.69.207 memory Pass memory size is 8192MB172.16.69.207 disk Warn mount point / does not have &#x27;noatime&#x27; option set172.16.69.207 selinux Pass SELinux is disabled172.16.69.207 thp Fail THP is enabled, please disable it for best performance172.16.69.207 service Fail service irqbalance is not running172.16.69.207 cpu-cores Pass number of CPU cores / threads: 4172.16.69.207 disk Fail mount point / does not have &#x27;nodelalloc&#x27; option set172.16.69.207 sysctl Fail net.core.somaxconn = 128, should be greater than 32768172.16.69.207 sysctl Fail net.ipv4.tcp_syncookies = 1, should be 0172.16.69.207 sysctl Fail fs.file-max = 763803, should be greater than 1000000172.16.69.207 command Fail numactl not usable, bash: numactl: command not found172.16.69.207 os-version Pass OS is CentOS Linux 7 (Core) 7.6.1810172.16.69.207 cpu-governor Warn Unable to determine current CPU frequency governor policy172.16.69.207 limits Fail soft limit of &#x27;stack&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.207 limits Fail soft limit of &#x27;nofile&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.207 limits Fail hard limit of &#x27;nofile&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.206 cpu-cores Pass number of CPU cores / threads: 4172.16.69.206 cpu-governor Warn Unable to determine current CPU frequency governor policy172.16.69.206 limits Fail soft limit of &#x27;nofile&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.206 limits Fail hard limit of &#x27;nofile&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.206 limits Fail soft limit of &#x27;stack&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.206 sysctl Fail fs.file-max = 763803, should be greater than 1000000172.16.69.206 sysctl Fail net.core.somaxconn = 128, should be greater than 32768172.16.69.206 sysctl Fail net.ipv4.tcp_syncookies = 1, should be 0172.16.69.206 timezone Pass time zone is the same as the first PD machine: Asia/Shanghai172.16.69.206 thp Fail THP is enabled, please disable it for best performance172.16.69.206 os-version Pass OS is CentOS Linux 7 (Core) 7.6.1810172.16.69.206 command Fail numactl not usable, bash: numactl: command not found172.16.69.206 memory Pass memory size is 8192MB172.16.69.206 disk Fail mount point / does not have &#x27;nodelalloc&#x27; option set172.16.69.206 disk Warn mount point / does not have &#x27;noatime&#x27; option set172.16.69.206 selinux Pass SELinux is disabled172.16.69.206 service Fail service irqbalance is not running172.16.69.208 selinux Pass SELinux is disabled172.16.69.208 os-version Pass OS is CentOS Linux 7 (Core) 7.6.1810172.16.69.208 cpu-cores Pass number of CPU cores / threads: 4172.16.69.208 service Fail service irqbalance is not running172.16.69.208 thp Fail THP is enabled, please disable it for best performance172.16.69.208 command Fail numactl not usable, bash: numactl: command not found172.16.69.208 cpu-governor Warn Unable to determine current CPU frequency governor policy172.16.69.208 disk Warn mount point / does not have &#x27;noatime&#x27; option set172.16.69.208 limits Fail soft limit of &#x27;nofile&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.208 limits Fail hard limit of &#x27;nofile&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.208 limits Fail soft limit of &#x27;stack&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.208 sysctl Fail fs.file-max = 763803, should be greater than 1000000172.16.69.208 sysctl Fail net.core.somaxconn = 128, should be greater than 32768172.16.69.208 sysctl Fail net.ipv4.tcp_syncookies = 1, should be 0172.16.69.208 timezone Pass time zone is the same as the first PD machine: Asia/Shanghai172.16.69.208 memory Pass memory size is 8192MB172.16.69.208 disk Fail mount point / does not have &#x27;nodelalloc&#x27; option set172.16.69.205 thp Fail THP is enabled, please disable it for best performance172.16.69.205 service Fail service irqbalance is not running172.16.69.205 os-version Pass OS is CentOS Linux 7 (Core) 7.6.1810172.16.69.205 cpu-cores Pass number of CPU cores / threads: 4172.16.69.205 cpu-governor Warn Unable to determine current CPU frequency governor policy172.16.69.205 memory Pass memory size is 8192MB172.16.69.205 disk Warn mount point / does not have &#x27;noatime&#x27; option set172.16.69.205 sysctl Fail fs.file-max = 763803, should be greater than 1000000172.16.69.205 sysctl Fail net.core.somaxconn = 128, should be greater than 32768172.16.69.205 sysctl Fail net.ipv4.tcp_syncookies = 1, should be 0172.16.69.205 command Fail numactl not usable, bash: numactl: command not found172.16.69.205 disk Fail mount point / does not have &#x27;nodelalloc&#x27; option set172.16.69.205 limits Fail soft limit of &#x27;stack&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.205 limits Fail soft limit of &#x27;nofile&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.205 limits Fail hard limit of &#x27;nofile&#x27; for user &#x27;tidb&#x27; is not set or too low172.16.69.205 selinux Pass SELinux is disabled[root@tidb0 ~]# tiup cluster check ./topology.yaml --apply --user root -pInput SSH password: + Detect CPU Arch Name - Detecting node 172.16.69.205 Arch info ... Done - Detecting node 172.16.69.207 Arch info ... Done - Detecting node 172.16.69.206 Arch info ... Done - Detecting node 172.16.69.208 Arch info ... Done+ Detect CPU OS Name - Detecting node 172.16.69.205 OS info ... Done - Detecting node 172.16.69.207 OS info ... Done - Detecting node 172.16.69.206 OS info ... Done - Detecting node 172.16.69.208 OS info ... Done+ Download necessary tools - Downloading check tools for linux/amd64 ... Done+ Collect basic system information+ Collect basic system information - Getting system info of 172.16.69.205:22 ... ⠴ CopyComponent: component=insight, version=, remote=172.16.69.205:/tmp/ti...+ Collect basic system information+ Collect basic system information - Getting system info of 172.16.69.205:22 ... Done - Getting system info of 172.16.69.207:22 ... Done - Getting system info of 172.16.69.206:22 ... Done - Getting system info of 172.16.69.208:22 ... Done+ Check time zone - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.207 ... Done - Checking node 172.16.69.206 ... Done - Checking node 172.16.69.208 ... Done+ Check system requirements - Checking node 172.16.69.205 ... ⠦ CheckSys: host=172.16.69.205 type=exist+ Check system requirements+ Check system requirements+ Check system requirements - Checking node 172.16.69.205 ... Done+ Check system requirements - Checking node 172.16.69.205 ... Done+ Check system requirements+ Check system requirements+ Check system requirements+ Check system requirements+ Check system requirements - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.207 ... Done - Checking node 172.16.69.206 ... Done - Checking node 172.16.69.208 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.205 ... Done - Checking node 172.16.69.207 ... Done - Checking node 172.16.69.206 ... Done - Checking node 172.16.69.208 ... Done+ Cleanup check files - Cleanup check files on 172.16.69.205:22 ... Done - Cleanup check files on 172.16.69.207:22 ... Done - Cleanup check files on 172.16.69.206:22 ... Done - Cleanup check files on 172.16.69.208:22 ... DoneNode Check Result Message---- ----- ------ -------172.16.69.205 memory Pass memory size is 8192MB172.16.69.205 disk Fail mount point / does not have &#x27;nodelalloc&#x27; option set, auto fixing not supported172.16.69.205 disk Warn mount point / does not have &#x27;noatime&#x27; option set, auto fixing not supported172.16.69.205 limits Fail will try to set &#x27;tidb hard nofile 1000000&#x27;172.16.69.205 limits Fail will try to set &#x27;tidb soft stack 10240&#x27;172.16.69.205 limits Fail will try to set &#x27;tidb soft nofile 1000000&#x27;172.16.69.205 thp Fail will try to disable THP, please check again after reboot172.16.69.205 service Fail will try to &#x27;start irqbalance.service&#x27;172.16.69.205 command Fail numactl not usable, bash: numactl: command not found, auto fixing not supported172.16.69.205 cpu-cores Pass number of CPU cores / threads: 4172.16.69.205 cpu-governor Warn Unable to determine current CPU frequency governor policy, auto fixing not supported172.16.69.205 sysctl Fail will try to set &#x27;fs.file-max = 1000000&#x27;172.16.69.205 sysctl Fail will try to set &#x27;net.core.somaxconn = 32768&#x27;172.16.69.205 sysctl Fail will try to set &#x27;net.ipv4.tcp_syncookies = 0&#x27;172.16.69.205 selinux Pass SELinux is disabled172.16.69.205 os-version Pass OS is CentOS Linux 7 (Core) 7.6.1810172.16.69.207 cpu-cores Pass number of CPU cores / threads: 4172.16.69.207 cpu-governor Warn Unable to determine current CPU frequency governor policy, auto fixing not supported172.16.69.207 memory Pass memory size is 8192MB172.16.69.207 limits Fail will try to set &#x27;tidb soft nofile 1000000&#x27;172.16.69.207 limits Fail will try to set &#x27;tidb hard nofile 1000000&#x27;172.16.69.207 limits Fail will try to set &#x27;tidb soft stack 10240&#x27;172.16.69.207 sysctl Fail will try to set &#x27;fs.file-max = 1000000&#x27;172.16.69.207 sysctl Fail will try to set &#x27;net.core.somaxconn = 32768&#x27;172.16.69.207 sysctl Fail will try to set &#x27;net.ipv4.tcp_syncookies = 0&#x27;172.16.69.207 disk Fail mount point / does not have &#x27;nodelalloc&#x27; option set, auto fixing not supported172.16.69.207 disk Warn mount point / does not have &#x27;noatime&#x27; option set, auto fixing not supported172.16.69.207 service Fail will try to &#x27;start irqbalance.service&#x27;172.16.69.207 os-version Pass OS is CentOS Linux 7 (Core) 7.6.1810172.16.69.207 thp Fail will try to disable THP, please check again after reboot172.16.69.207 command Fail numactl not usable, bash: numactl: command not found, auto fixing not supported172.16.69.207 timezone Pass time zone is the same as the first PD machine: Asia/Shanghai172.16.69.207 selinux Pass SELinux is disabled172.16.69.206 timezone Pass time zone is the same as the first PD machine: Asia/Shanghai172.16.69.206 cpu-cores Pass number of CPU cores / threads: 4172.16.69.206 cpu-governor Warn Unable to determine current CPU frequency governor policy, auto fixing not supported172.16.69.206 limits Fail will try to set &#x27;tidb soft nofile 1000000&#x27;172.16.69.206 limits Fail will try to set &#x27;tidb hard nofile 1000000&#x27;172.16.69.206 limits Fail will try to set &#x27;tidb soft stack 10240&#x27;172.16.69.206 service Fail will try to &#x27;start irqbalance.service&#x27;172.16.69.206 memory Pass memory size is 8192MB172.16.69.206 sysctl Fail will try to set &#x27;fs.file-max = 1000000&#x27;172.16.69.206 sysctl Fail will try to set &#x27;net.core.somaxconn = 32768&#x27;172.16.69.206 sysctl Fail will try to set &#x27;net.ipv4.tcp_syncookies = 0&#x27;172.16.69.206 thp Fail will try to disable THP, please check again after reboot172.16.69.206 disk Warn mount point / does not have &#x27;noatime&#x27; option set, auto fixing not supported172.16.69.206 os-version Pass OS is CentOS Linux 7 (Core) 7.6.1810172.16.69.206 disk Fail mount point / does not have &#x27;nodelalloc&#x27; option set, auto fixing not supported172.16.69.206 selinux Pass SELinux is disabled172.16.69.206 command Fail numactl not usable, bash: numactl: command not found, auto fixing not supported172.16.69.208 selinux Pass SELinux is disabled172.16.69.208 timezone Pass time zone is the same as the first PD machine: Asia/Shanghai172.16.69.208 cpu-cores Pass number of CPU cores / threads: 4172.16.69.208 disk Fail mount point / does not have &#x27;nodelalloc&#x27; option set, auto fixing not supported172.16.69.208 memory Pass memory size is 8192MB172.16.69.208 limits Fail will try to set &#x27;tidb soft nofile 1000000&#x27;172.16.69.208 limits Fail will try to set &#x27;tidb hard nofile 1000000&#x27;172.16.69.208 limits Fail will try to set &#x27;tidb soft stack 10240&#x27;172.16.69.208 os-version Pass OS is CentOS Linux 7 (Core) 7.6.1810172.16.69.208 cpu-governor Warn Unable to determine current CPU frequency governor policy, auto fixing not supported172.16.69.208 command Fail numactl not usable, bash: numactl: command not found, auto fixing not supported172.16.69.208 service Fail will try to &#x27;start irqbalance.service&#x27;172.16.69.208 disk Warn mount point / does not have &#x27;noatime&#x27; option set, auto fixing not supported172.16.69.208 sysctl Fail will try to set &#x27;fs.file-max = 1000000&#x27;172.16.69.208 sysctl Fail will try to set &#x27;net.core.somaxconn = 32768&#x27;172.16.69.208 sysctl Fail will try to set &#x27;net.ipv4.tcp_syncookies = 0&#x27;172.16.69.208 thp Fail will try to disable THP, please check again after reboot+ Try to apply changes to fix failed checks - Applying changes on 172.16.69.205 ... ⠙ Sysctl: host=172.16.69.205 net.ipv4.tcp_syncookies = 0 - Applying changes on 172.16.69.207 ... ⠙ Sysctl: host=172.16.69.207 net.ipv4.tcp_syncookies = 0 - Applying changes on 172.16.69.206 ... ⠙ Sysctl: host=172.16.69.206 net.ipv4.tcp_syncookies = 0+ Try to apply changes to fix failed checks - Applying changes on 172.16.69.205 ... ⠹ Shell: host=172.16.69.205, sudo=true, command=`if [ -d /sys/kernel/mm/transpar... - Applying changes on 172.16.69.207 ... ⠹ Sysctl: host=172.16.69.207 net.ipv4.tcp_syncookies = 0 - Applying changes on 172.16.69.206 ... ⠹ Shell: host=172.16.69.206, sudo=true, command=`if [ -d /sys/kernel/mm/transpar...+ Try to apply changes to fix failed checks - Applying changes on 172.16.69.205 ... Done - Applying changes on 172.16.69.207 ... Done - Applying changes on 172.16.69.206 ... Done - Applying changes on 172.16.69.208 ... Done[root@tidb0 ~]# tiup cluster listName User Version Path PrivateKey---- ---- ------- ---- ----------[root@tidb0 ~]# tiup cluster deploy tidb-test v5.4.1 ./topology.yaml --user root -pInput SSH password: + Detect CPU Arch Name - Detecting node 172.16.69.205 Arch info ... Done - Detecting node 172.16.69.207 Arch info ... Done - Detecting node 172.16.69.206 Arch info ... Done - Detecting node 172.16.69.208 Arch info ... Done+ Detect CPU OS Name - Detecting node 172.16.69.205 OS info ... Done - Detecting node 172.16.69.207 OS info ... Done - Detecting node 172.16.69.206 OS info ... Done - Detecting node 172.16.69.208 OS info ... DonePlease confirm your topology:Cluster type: tidbCluster name: tidb-testCluster version: v5.4.1Role Host Ports OS/Arch Directories---- ---- ----- ------- -----------pd 172.16.69.205 2379/2380 linux/x86_64 /tidb-deploy/pd-2379,/tidb-data/pd-2379tikv 172.16.69.207 20160/20180 linux/x86_64 /tidb-deploy/tikv-20160,/tidb-data/tikv-20160tikv 172.16.69.206 20160/20180 linux/x86_64 /tidb-deploy/tikv-20160,/tidb-data/tikv-20160tikv 172.16.69.208 20160/20180 linux/x86_64 /tidb-deploy/tikv-20160,/tidb-data/tikv-20160tidb 172.16.69.205 4000/10080 linux/x86_64 /tidb-deploy/tidb-4000prometheus 172.16.69.205 9090/12020 linux/x86_64 /tidb-deploy/prometheus-9090,/tidb-data/prometheus-9090grafana 172.16.69.205 3000 linux/x86_64 /tidb-deploy/grafana-3000alertmanager 172.16.69.205 9093/9094 linux/x86_64 /tidb-deploy/alertmanager-9093,/tidb-data/alertmanager-9093Attention: 1. If the topology is not what you expected, check your yaml file. 2. Please confirm there is no port/directory conflicts in same host.Do you want to continue? [y/N]: (default=N) y+ Generate SSH keys ... Done+ Download TiDB components - Download pd:v5.4.1 (linux/amd64) ... Done - Download tikv:v5.4.1 (linux/amd64) ... Done - Download tidb:v5.4.1 (linux/amd64) ... Done - Download prometheus:v5.4.1 (linux/amd64) ... Done - Download grafana:v5.4.1 (linux/amd64) ... Done - Download alertmanager: (linux/amd64) ... Done - Download node_exporter: (linux/amd64) ... Done - Download blackbox_exporter: (linux/amd64) ... Done+ Initialize target host environments - Prepare 172.16.69.205:22 ... Done - Prepare 172.16.69.207:22 ... Done - Prepare 172.16.69.206:22 ... Done - Prepare 172.16.69.208:22 ... Done+ Deploy TiDB instance - Copy pd -&gt; 172.16.69.205 ... Done - Copy tikv -&gt; 172.16.69.207 ... Done - Copy tikv -&gt; 172.16.69.206 ... Done - Copy tikv -&gt; 172.16.69.208 ... Done - Copy tidb -&gt; 172.16.69.205 ... Done - Copy prometheus -&gt; 172.16.69.205 ... Done - Copy grafana -&gt; 172.16.69.205 ... Done - Copy alertmanager -&gt; 172.16.69.205 ... Done - Deploy node_exporter -&gt; 172.16.69.205 ... Done - Deploy node_exporter -&gt; 172.16.69.207 ... Done - Deploy node_exporter -&gt; 172.16.69.206 ... Done - Deploy node_exporter -&gt; 172.16.69.208 ... Done - Deploy blackbox_exporter -&gt; 172.16.69.205 ... Done - Deploy blackbox_exporter -&gt; 172.16.69.207 ... Done - Deploy blackbox_exporter -&gt; 172.16.69.206 ... Done - Deploy blackbox_exporter -&gt; 172.16.69.208 ... Done+ Copy certificate to remote host+ Init instance configs - Generate config pd -&gt; 172.16.69.205:2379 ... Done - Generate config tikv -&gt; 172.16.69.207:20160 ... Done - Generate config tikv -&gt; 172.16.69.206:20160 ... Done - Generate config tikv -&gt; 172.16.69.208:20160 ... Done - Generate config tidb -&gt; 172.16.69.205:4000 ... Done - Generate config prometheus -&gt; 172.16.69.205:9090 ... Done - Generate config grafana -&gt; 172.16.69.205:3000 ... Done - Generate config alertmanager -&gt; 172.16.69.205:9093 ... Done+ Init monitor configs - Generate config node_exporter -&gt; 172.16.69.206 ... Done - Generate config node_exporter -&gt; 172.16.69.208 ... Done - Generate config node_exporter -&gt; 172.16.69.205 ... Done - Generate config node_exporter -&gt; 172.16.69.207 ... Done - Generate config blackbox_exporter -&gt; 172.16.69.205 ... Done - Generate config blackbox_exporter -&gt; 172.16.69.207 ... Done - Generate config blackbox_exporter -&gt; 172.16.69.206 ... Done - Generate config blackbox_exporter -&gt; 172.16.69.208 ... DoneEnabling component pd Enabling instance 172.16.69.205:2379 Enable instance 172.16.69.205:2379 successEnabling component tikv Enabling instance 172.16.69.208:20160 Enabling instance 172.16.69.206:20160 Enabling instance 172.16.69.207:20160 Enable instance 172.16.69.206:20160 success Enable instance 172.16.69.208:20160 success Enable instance 172.16.69.207:20160 successEnabling component tidb Enabling instance 172.16.69.205:4000 Enable instance 172.16.69.205:4000 successEnabling component prometheus Enabling instance 172.16.69.205:9090 Enable instance 172.16.69.205:9090 successEnabling component grafana Enabling instance 172.16.69.205:3000 Enable instance 172.16.69.205:3000 successEnabling component alertmanager Enabling instance 172.16.69.205:9093 Enable instance 172.16.69.205:9093 successEnabling component node_exporter Enabling instance 172.16.69.208 Enabling instance 172.16.69.207 Enabling instance 172.16.69.206 Enabling instance 172.16.69.205 Enable 172.16.69.205 success Enable 172.16.69.206 success Enable 172.16.69.208 success Enable 172.16.69.207 successEnabling component blackbox_exporter Enabling instance 172.16.69.208 Enabling instance 172.16.69.205 Enabling instance 172.16.69.207 Enabling instance 172.16.69.206 Enable 172.16.69.205 success Enable 172.16.69.206 success Enable 172.16.69.207 success Enable 172.16.69.208 successCluster `tidb-test` deployed successfully, you can start it with command: `tiup cluster start tidb-test --init`[root@tidb0 ~]# tiup cluster listName User Version Path PrivateKey---- ---- ------- ---- ----------tidb-test tidb v5.4.1 /root/.tiup/storage/cluster/clusters/tidb-test /root/.tiup/storage/cluster/clusters/tidb-test/ssh/id_rsa[root@tidb0 ~]# tiup cluster display tidb-testCluster type: tidbCluster name: tidb-testCluster version: v5.4.1Deploy user: tidbSSH type: builtinGrafana URL: http://172.16.69.205:3000ID Role Host Ports OS/Arch Status Data Dir Deploy Dir-- ---- ---- ----- ------- ------ -------- ----------172.16.69.205:9093 alertmanager 172.16.69.205 9093/9094 linux/x86_64 Down /tidb-data/alertmanager-9093 /tidb-deploy/alertmanager-9093172.16.69.205:3000 grafana 172.16.69.205 3000 linux/x86_64 Down - /tidb-deploy/grafana-3000172.16.69.205:2379 pd 172.16.69.205 2379/2380 linux/x86_64 Down /tidb-data/pd-2379 /tidb-deploy/pd-2379172.16.69.205:9090 prometheus 172.16.69.205 9090/12020 linux/x86_64 Down /tidb-data/prometheus-9090 /tidb-deploy/prometheus-9090172.16.69.205:4000 tidb 172.16.69.205 4000/10080 linux/x86_64 Down - /tidb-deploy/tidb-4000172.16.69.206:20160 tikv 172.16.69.206 20160/20180 linux/x86_64 N/A /tidb-data/tikv-20160 /tidb-deploy/tikv-20160172.16.69.207:20160 tikv 172.16.69.207 20160/20180 linux/x86_64 N/A /tidb-data/tikv-20160 /tidb-deploy/tikv-20160172.16.69.208:20160 tikv 172.16.69.208 20160/20180 linux/x86_64 N/A /tidb-data/tikv-20160 /tidb-deploy/tikv-20160Total nodes: 8[root@tidb0 ~]# tiup cluster start tidb-test --initStarting cluster tidb-test...+ [ Serial ] - SSHKeySet: privateKey=/root/.tiup/storage/cluster/clusters/tidb-test/ssh/id_rsa, publicKey=/root/.tiup/storage/cluster/clusters/tidb-test/ssh/id_rsa.pub+ [Parallel] - UserSSH: user=tidb, host=172.16.69.205+ [Parallel] - UserSSH: user=tidb, host=172.16.69.206+ [Parallel] - UserSSH: user=tidb, host=172.16.69.205+ [Parallel] - UserSSH: user=tidb, host=172.16.69.208+ [Parallel] - UserSSH: user=tidb, host=172.16.69.205+ [Parallel] - UserSSH: user=tidb, host=172.16.69.205+ [Parallel] - UserSSH: user=tidb, host=172.16.69.207+ [Parallel] - UserSSH: user=tidb, host=172.16.69.205+ [ Serial ] - StartClusterStarting component pd Starting instance 172.16.69.205:2379 Start instance 172.16.69.205:2379 successStarting component tikv Starting instance 172.16.69.208:20160 Starting instance 172.16.69.207:20160 Starting instance 172.16.69.206:20160 Start instance 172.16.69.206:20160 success Start instance 172.16.69.208:20160 success Start instance 172.16.69.207:20160 successStarting component tidb Starting instance 172.16.69.205:4000 Start instance 172.16.69.205:4000 successStarting component prometheus Starting instance 172.16.69.205:9090 Start instance 172.16.69.205:9090 successStarting component grafana Starting instance 172.16.69.205:3000 Start instance 172.16.69.205:3000 successStarting component alertmanager Starting instance 172.16.69.205:9093 Start instance 172.16.69.205:9093 successStarting component node_exporter Starting instance 172.16.69.207 Starting instance 172.16.69.206 Starting instance 172.16.69.208 Starting instance 172.16.69.205 Start 172.16.69.206 success Start 172.16.69.205 success Start 172.16.69.208 success Start 172.16.69.207 successStarting component blackbox_exporter Starting instance 172.16.69.207 Starting instance 172.16.69.205 Starting instance 172.16.69.208 Starting instance 172.16.69.206 Start 172.16.69.206 success Start 172.16.69.205 success Start 172.16.69.208 success Start 172.16.69.207 success+ [ Serial ] - UpdateTopology: cluster=tidb-testStarted cluster `tidb-test` successfullyThe root password of TiDB database has been changed.The new password is: &#x27;U719-^8@FHGM0Ln4*p&#x27;.Copy and record it to somewhere safe, it is only displayed once, and will not be stored.The generated password can NOT be get and shown again.[root@tidb0 ~]# tiup cluster display tidb-testCluster type: tidbCluster name: tidb-testCluster version: v5.4.1Deploy user: tidbSSH type: builtinDashboard URL: http://172.16.69.205:2379/dashboardGrafana URL: http://172.16.69.205:3000ID Role Host Ports OS/Arch Status Data Dir Deploy Dir-- ---- ---- ----- ------- ------ -------- ----------172.16.69.205:9093 alertmanager 172.16.69.205 9093/9094 linux/x86_64 Up /tidb-data/alertmanager-9093 /tidb-deploy/alertmanager-9093172.16.69.205:3000 grafana 172.16.69.205 3000 linux/x86_64 Up - /tidb-deploy/grafana-3000172.16.69.205:2379 pd 172.16.69.205 2379/2380 linux/x86_64 Up|L|UI /tidb-data/pd-2379 /tidb-deploy/pd-2379172.16.69.205:9090 prometheus 172.16.69.205 9090/12020 linux/x86_64 Up /tidb-data/prometheus-9090 /tidb-deploy/prometheus-9090172.16.69.205:4000 tidb 172.16.69.205 4000/10080 linux/x86_64 Up - /tidb-deploy/tidb-4000172.16.69.206:20160 tikv 172.16.69.206 20160/20180 linux/x86_64 Up /tidb-data/tikv-20160 /tidb-deploy/tikv-20160172.16.69.207:20160 tikv 172.16.69.207 20160/20180 linux/x86_64 Up /tidb-data/tikv-20160 /tidb-deploy/tikv-20160172.16.69.208:20160 tikv 172.16.69.208 20160/20180 linux/x86_64 Up /tidb-data/tikv-20160 /tidb-deploy/tikv-20160Total nodes: 8[root@tidb0 ~]# free -h total used free shared buff/cache availableMem: 7.4G 605M 5.1G 508K 1.7G 6.5GSwap: 0B 0B 0B[root@tidb0 ~]#","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"TiDB","slug":"数据库/TiDB","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/TiDB/"}],"tags":[{"name":"TiDB","slug":"TiDB","permalink":"http://example.com/tags/TiDB/"}]},{"title":"旧电脑改NAS（黑群晖DS3622XS+42218）过程回顾和问题记录","slug":"旧电脑改NAS（黑群晖DS3622XS-42218）过程回顾和问题记录","date":"2024-09-15T07:00:00.000Z","updated":"2024-09-15T07:00:00.000Z","comments":true,"path":"2024/09/15/旧电脑改NAS（黑群晖DS3622XS-42218）过程回顾和问题记录/","permalink":"http://example.com/2024/09/15/%E6%97%A7%E7%94%B5%E8%84%91%E6%94%B9NAS%EF%BC%88%E9%BB%91%E7%BE%A4%E6%99%96DS3622XS-42218%EF%BC%89%E8%BF%87%E7%A8%8B%E5%9B%9E%E9%A1%BE%E5%92%8C%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","excerpt":"","text":"硬件：1、大学时购买的华硕笔记本，CPU奔腾2117U，4G内存。（第一台电脑，不舍得扔，期望继续发光发热）2、闲置MSATA硬盘一张，SSD，容量32G。内置硬盘引导安装黑群晖。3、闲置机械盘弱干，用于存储。 安装过程参考了两个UP主的视频： 【轻松玩NAS！黑群晖7.1&#x2F;7.2保姆级安装、上手教程，打造属于自己的个人NAS和家庭影音中心】https://www.bilibili.com/video/BV1sV4y1d7xH?vd_source&#x3D;adfbf546aac6679622e2f4c43d399aa0 这个教程相当详细，镜像的来源，如何引导，以及安装成功后的各项设置都有。我大多参考这套教程完成的搭建。up使用rufus工具，将镜像文件写入到U盘，再由U盘启动。我的问题是，如果采用U盘做引导，后续使用中这个U盘需要一直挂载，拖着个小尾巴。我期望是直接使用内置SSD的。 于是寻找其他使用内置硬盘的教程。 【旧电脑变NAS，超简单的黑群晖DSM7.2安装指南】https://www.bilibili.com/video/BV1e94y1W7GP?vd_source&#x3D;adfbf546aac6679622e2f4c43d399aa0 这个教程使用PE工具，将镜像虚拟磁盘克隆到内置SSD上，并在BIOS中设置SSD启动。 结果我这儿不知道是BIOS的问题，还是这块硬盘的问题，总之BIOS并不识别这个引导，开机提示： GRUB _ 转换思路，寻找其他的镜像刷机工具，能直接将镜像写入到内置SSD上。 于是搜索到这个工具：Roadkil’s DiskImage 【下载地址：http://blog.ryjer.com/posts/a1b6b4e50c.html】 可以直接将上述arpl-1.1-beta2a.img写入到这块MSATA接口的SSD上。（这台华硕笔记本原本的win10系统还在，所以直接在win10就能运行Roadkil’s DiskImage。 如果没有系统了，可以在PE工具中打开Roadkil’s DiskImage，也能完成。） 重新开机，顺利进入引导。其他过程就都参考视频1一步步完成。 有个插曲： 开机进入引导后，遇到过一个这样的报错：Loader disk not found!后来终于找到了原因： https://github.com/fbelavenuto/arpl/issues/618“I’ve figured out why, one of my other sata drives is already an aprl boot drive.Having two boot disks at the same time caused the problem.” 好好好，我U盘里有一份镜像，ssd上也有一份镜像。两块硬盘一起插上后，在引导阶段重新读取硬盘时发现有两个镜像，就会报这个错。拔掉一个后重启，问题解决。","categories":[{"name":"杂记","slug":"杂记","permalink":"http://example.com/categories/%E6%9D%82%E8%AE%B0/"}],"tags":[{"name":"NAS","slug":"NAS","permalink":"http://example.com/tags/NAS/"}]},{"title":"个人博客&主页搭建过程简要记录","slug":"个人博客主页搭建过程简要记录","date":"2024-09-15T04:00:00.000Z","updated":"2024-09-15T04:00:00.000Z","comments":true,"path":"2024/09/15/个人博客主页搭建过程简要记录/","permalink":"http://example.com/2024/09/15/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A1%B5%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E7%AE%80%E8%A6%81%E8%AE%B0%E5%BD%95/","excerpt":"","text":"本站借助Hexo搭建，并托管在GitHub。作为本站搭建过程的记录，遂成为本站发表的第一篇文章。 环境准备篇幅有限，安装Git、注册GitHub、生成ssh密钥并配置到GitHub，这些基础步骤本文不再说明。 安装nodejs下载地址：https://nodejs.org/en/在本地磁盘D新建了一个文件夹 nodejs，安装在这个文件夹里。检验是否安装成功：可以用 node -v 和 npm -v 命令检查版本。 设置npm在安装全局模块时的路径 在 nodejs 文件夹下新建文件夹 node_cache、node_global。并在cmd中执行命令： 12npm config set prefix &quot;D:\\nodejs\\node_global&quot;npm config set cache &quot;D:\\nodejs\\node_cache&quot; 设置环境变量: 新建一个变量名为“NODE_PATH”，值为“D:\\nodejs\\node_global\\node_modules” 编辑Path，新建一个“D:\\nodejs\\node_global” 安装Hexo安装Hexo之前，先在本地建立一个文件夹 Blog（名称任意），作为站点根目录，以后的文章都在这个Blog目录中创建和暂存，并发布到GitHub中托管。 进入 Blog 文件夹，打开 Git Bush Here，输入npm命令安装Hexo： 1npm install -g hexo-cli 安装完成后，输入 hexo init 命令初始化博客： 1hexo init 然后输入 hexo g 本地静态部署 1hexo g 输入 hexo s 命令可以查看部署在本地的端口 1hexo s 可以看到输出了：http://localhost:4000进入 http://localhost:4000 就能看到一个默认的、初始的网页。 但这样仅仅是本机上部署成功，接下来需要发布到GitHub，以及对这个网页更换主题、编写文章并发布。 在后文中，都会将上述命令组合使用，节省篇幅。 这里补充一下各条命令的作用： 清除旧数据 1hexo clean 这个命令会清除掉之前旧的网页数据，即站点根目录下的public文件夹 生成新的网页 1hexo g 注意：每次修改文章后，都要执行上述两条命令，清除掉旧的数据，然后重新生成页面。 本地开启服务器，预览一下文章（可选） 1hexo s 部署到Github 1hexo d 创建Github仓库在GitHub上创立一个仓库，名称格式为：xxx.github.io。 其中xxx必须是当前Github账号的用户名。如我的用户名是： liqiang995，那么仓库名：liqiang995.github.io 将Hexo初始静态网页部署到GitHub关联GitHub进入Blog 文件夹，打开 _config.yml 文件，填上如下内容： 123456# 注意yml语法，键和值之间除了冒号，还有一个空格deploy: type: git repository: git@github.com:liqiang995/liqiang995.github.io.git #自己的仓库地址，可以是ssh、https branch: main #自己仓库的分支，注意默认主分支是main，不再是master 安装Hexo发布Git插件还是Blog 文件夹，打开 Git Bash Here，安装Hexo发布Git插件： 1npm install hexo-deployer-git --save Hexo生成网站静态文件、发布到GitHub仍然是在Git Bash 窗口中，分别输入以下三条命令： 123hexo clean #清除缓存文件 db.json 和已生成的静态文件 publichexo g #生成网站静态文件到默认设置的 public 文件夹(hexo generate 的缩写)hexo d #部署到设定的远程仓库(hexo deploy 的缩写) 完成以后，（会有几分钟内的延迟）打开浏览器，输入 https://liqiang995.github.io 就可以打开和上述相同的默认的网页，不过现在发布在公网，而不是在本地。 设置主题由 hexo init 初始化出来的网页，主题是默认的。但其实Hexo开源主题非常多。 Hexo 10款好看的主题｜新手建站必备！ 不管使用哪个主题，都需要找到这个主题的仓库地址，将它clone到我们的博客文件夹中。 在此之前 检查并安装Hexo 搜索依赖： 1npm i hexo-generator-json-content 安装 Stylus 渲染器： 1npm i hexo-renderer-stylus 以本站使用 volantis 主题为例，找到由volantis提供的文档：开始使用 - Volantis，提供了两种方式： 直接使用npm命令安装(要求 Hexo 5.0.2 及以上)1npm i hexo-theme-volantis 通过GitHub地址拉取（本文采用的方式）1git clone https://github.com/volantis-x/hexo-theme-volantis themes/volantis 还是在Blog文件夹，打开Git Bash，输入上述GitHub地址，拉取到目录 Blog&#x2F;themes&#x2F;volantis 还是在Blog文件夹，打开 _config.yml 文件，修改主题为volantis 12345678910111213# Sitetitle: &#x27;&#x27; #标题subtitle: &#x27;&#x27;description: &#x27;&#x27; #简介keywords:author: &#x27;&#x27; #作者language: zh-CN #主题语言timezone: Asia/Shanghai #时区# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: volantis #主题改为volantis 确定主题后，还是需要对这主题做一些个性化修改，如背景、标题、个人联系方式及链接…… 这些内容，就要去到这个主题下的 _config.yml 文件做修改了。如 themes\\volantis\\_config.yml。 但也可以在Blog目录下创建 _config.volantis.yml（命令格式都是 _config.{theme_name}.yml），它会和themes\\volantis\\_config.yml文件中内容互补，但_config.volantis.yml优先级更高。 完成修改后，重新发布 12# 本地预览hexo clean &amp;&amp; hexo g &amp;&amp; hexo s 12# 发布到远程hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 添加导航栏分类和标签发布后，当点击导航栏里的分类、标签、友链、关于 时，都会报错404 not found. 因为默认是没有创建对应页面的。 进入站点根目录Blog，使用如下命令创建新页面 1hexo new page &lt;page_name&gt; categories分类创建categories分类 1hexo new page categories 找到 Blog&#x2F;source&#x2F;categories&#x2F;index.md 打开后默认内容： 1234---title: categoriesdate: 2034-09-15 00:00:00--- 添加一项 type: “categories”到内容中： 12345---title: 文章分类date: 2024-09-15 00:00:00type: categories--- 找到 Blog\\scaffolds\\post.md 打开后默认内容： 12345---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:--- 这个就是使用 hexo new 创建文章时的模板。添加一项 categories: 123456---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;categories: tags: --- 当下文使用 hexo new &lt;title&gt; 创建的文章，才会在配置项中增加一项categories，通过对文章中categories设置值，hexo便会创建对应的分类，以及提供检索。 保存退出后，重新生成预览。 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo s 执行完命令，会在 Blog\\public\\categories\\下创建index.html。 实际上，当点击导航栏里的分类，就是会打开这个index.html；找不到的话就会报错404。 tags标签同样的步骤 1hexo new page tags 找到 Blog&#x2F;source&#x2F;tags&#x2F;index.md 并打开，修改为 12345---title: 文章标签date: 2024-09-15 00:00:00type: tags--- 保存退出后，重新生成预览 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo s 执行完命令，会在 Blog\\public\\tags\\下创建index.html 同理创建 friends 和 about12hexo new page friendshexo new page about 执行完hexo clean &amp;&amp; hexo g &amp;&amp; hexo s，会分别创建 public\\friends\\index.html 和 public\\about\\index.html再点击导航栏里的友链、关于 都不会再报错了。 分类和标签增加内容已经创建categories、tags对应的页面了，但是从导航栏访问分类、标签时，没有具体的分类内容、标签内容。 解决办法： 找到 Blog\\themes\\volantis\\layout\\ 目录下，会有 tag.ejs 文件。但是刚才创建的标签是 tags，对应不上。将 tag.ejs 复制一份为 tags.ejs同理，将 category.ejs 复制一份为 categories.ejs 但本站参考了：好好学Hexo：Hexo添加categories页面 在主题目录volantis下新建了 layout&#x2F;categories.ejs 和 source&#x2F;css&#x2F;_partial&#x2F;categories.styl，再在 source&#x2F;css&#x2F;style.styl中引入categories.styl并实现了分类按层级展示。 也有其他的办法：https://www.npmjs.com/package/hexo-auto-category 安装 hexo-auto-category1npm install hexo-auto-category --save 在 _config.yml中开启1234auto_category: enable: true multiple: true depth: 保存退出后，重新发布 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 创建文章并发布创建新文章进入站点根目录Blog，使用如下命令创建新文章： 1hexo new &lt;title&gt; 执行后，Hexo会在 Blog&#x2F;source&#x2F;_posts目录下创建一篇以 &lt;title&gt;命名新的文章，接下来在这篇文章里使用 MarkDown 语法编写文章即可。 编辑文章内容打开 Hexo 创建的文章可以看到，注意开头有一段以”- - -“包括起来的内容，这是前置信息，用于给 Hexo 渲染该 md 文档，除了这三项，还有很多的配置项可以自己添加 配置项 含义 title 文章标题 date 文章创建日期 updated 更新日期 comments 文章评论[true 表示开启评论] tags 文章标签 categories 文章分类 keywords 文章关键字 参数“categories”表示分类，一篇文章只能属于一个分类，如果添加了多个分类，则下一个分类为子分类。添加分类的格式如下： 123categories:- 分类- 子分类 参数“tags”表示标签，一篇文章可以有多个标签。添加标签的格式如下： 123tags:- 标签1- 标签2 在”- - -“以后的区域，都可以支持大多数Markdown 语法，编写正文。 重新发布1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 开启图片准备完上述步骤后，我兴致勃勃地将发表在其他平台的文章一顿copy过来，按理来说不用对文章做任何改动，但发布后发现，文章中引用的网络图片全都不显示。搜索了好久，大多数博文都是讲引用本地图片不显示的问题。而引用网络图片，需要按这一篇：解决Hexo博客引用网络图片无法显示的问题解决办法，在文章标题与正文之间，加入标签： 1&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt; 嫌每篇文章创建后都需要手动添加麻烦，于是考虑将这个标签添加到模板 Blog\\scaffolds\\post.md 文件中。前文增加分类时，也在这个模板中添加了”categories:”。 123456789---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;categories: tags: ---&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt; 重新发布 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 开启评论按前文创建好后，浏览文章到最后的评论区，会发现是不可用的，Error。 评论功能需要借助评论系统，评论系统有很多，其中 Giscus是基于 Github Discussions的，本站也是放托管在 Github的，本文就选择 Giscus吧。 使用Giscus后，访客想要发表评论，必须登录GitHub，按 GitHub OAuth流程授权 Giscus app代表他发帖。或者访客也可以直接在 GitHub Discussion里评论，作者可以在 GitHub上管理评论。 安装 giscus app点击 https://github.com/apps/giscus 进入 giscus app 的 安装界面.点右侧 Install。会提示选择一个仓库，这里选择 Only select repositories，再选择博客本身这个仓库[liqiang995&#x2F;liqiang995.github.io]就好，后续 giscus 就会从该仓库读取数据。 仓库要开启 Discussions去到GitHub中刚才选择的仓库，进入Settings设置界面，勾选上 Discussions 以开启该仓库的 Discussions。 从 giscus 官网创建配置文件 访问 giscus 官网 创建配置信息，具体如下： 选择仓库：填入刚才指定的仓库地址。 经过校验后会“成功，该仓库满足所有条件” 在页面 与 discussion 映射关系中，选择（默认已选）Discussion 的标题包含页面的 pathname。 在 Discussion 分类中，选择 Announcements, 并勾选”只搜索该分类的 discussion” 在 特性 中，可以勾选 “启用主帖子上的反应(reaction)” 其他选项都不需要配置，配置完成后，页面往下滑，会生成一个配置文件： 12345678910&lt;script src=&quot;https://giscus.app/client.js&quot; data-repo=&quot;liqiang995/liqiang995.github.io&quot; data-repo-id=&quot;***&quot; data-category=&quot;Announcements&quot; data-category-id=&quot;****&quot; data-mapping=&quot;pathname&quot; data-reactions-enabled=&quot;1&quot; data-emit-metadata=&quot;0&quot; async&gt;&lt;/script&gt; 将上述配置到博客 打开 _config.volantis.yml。搜索 Comments，大概在385行左右就能找到： 12345678910111213141516############################### Comments ############################### &gt; startcomments: service: giscus giscus: # 以下配置按照 yml 格式增删填写即可 # repo: xxx/xxx.github.io # repo-id: xxxx # category: Announcements # category-id: xxxxx # mapping: &quot;pathname&quot; # reactions-enabled: &quot;1&quot; # emit-metadata: &quot;0&quot; # lang: &quot;zh-CN&quot; ....############################### Comments ############################### &gt; end 将注释符号”# “去掉，再将从giscus 官网获取来的配置对应填上就好。 最后，回到 Blog 文件夹，打开Git Bash， 重新部署到远程GitHub 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 绑定域名托管在GitHub后，地址一般是 xxx.github.io，并不容易记住，所以绑定到已购买的域名上。 添加域名解析 在所购买域名的网站上，添加一条解析记录，解析到 xxx.github.io 对应的ip地址。 ip地址使用 ping xxx.github.io获取，经测试目前ping出来的地址为ipv6。那么添加解析时要指定ipv6。 添加CNAME文件 找到Blog 文件夹里的 source 文件夹，添加CNAME文件。（不要用windows直接创建文件） 可以在 Git Bash 中使用命令touch CNAME 创建，再vim CNAME打开后写上域名，如本站地址： 1blog.revali.site 回到 Blog 文件夹，打开Git Bash， 重新部署到远程GitHub 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 打开GitHub，检查CNAME文件是否已经在项目中、是否创建了 Customer domain。 创建成功，以后就能通过新的域名访问了。","categories":[{"name":"杂记","slug":"杂记","permalink":"http://example.com/categories/%E6%9D%82%E8%AE%B0/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://example.com/tags/node-js/"},{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"}],"author":"昱东"}],"categories":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://example.com/categories/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"Spring Boot","slug":"Spring/Spring-Boot","permalink":"http://example.com/categories/Spring/Spring-Boot/"},{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"大数据/Hive","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/"},{"name":"Hadoop","slug":"大数据/Hadoop","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/"},{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"},{"name":"maven","slug":"maven","permalink":"http://example.com/categories/maven/"},{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"},{"name":"编码","slug":"编码","permalink":"http://example.com/categories/%E7%BC%96%E7%A0%81/"},{"name":"杂记","slug":"杂记","permalink":"http://example.com/categories/%E6%9D%82%E8%AE%B0/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"mysql","slug":"数据库/mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/"},{"name":"Oracle","slug":"数据库/Oracle","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/"},{"name":"jvm","slug":"Java/jvm","permalink":"http://example.com/categories/Java/jvm/"},{"name":"TiDB","slug":"数据库/TiDB","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/TiDB/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://example.com/tags/Hadoop/"},{"name":"类加载","slug":"类加载","permalink":"http://example.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"},{"name":"双亲委派","slug":"双亲委派","permalink":"http://example.com/tags/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE/"},{"name":"kill -9","slug":"kill-9","permalink":"http://example.com/tags/kill-9/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"rpm","slug":"rpm","permalink":"http://example.com/tags/rpm/"},{"name":"yum","slug":"yum","permalink":"http://example.com/tags/yum/"},{"name":"shell","slug":"shell","permalink":"http://example.com/tags/shell/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Junit","slug":"Junit","permalink":"http://example.com/tags/Junit/"},{"name":"ASCII","slug":"ASCII","permalink":"http://example.com/tags/ASCII/"},{"name":"Unicode","slug":"Unicode","permalink":"http://example.com/tags/Unicode/"},{"name":"UTF-8","slug":"UTF-8","permalink":"http://example.com/tags/UTF-8/"},{"name":"磁盘RAID","slug":"磁盘RAID","permalink":"http://example.com/tags/%E7%A3%81%E7%9B%98RAID/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"juc","slug":"juc","permalink":"http://example.com/tags/juc/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"Oracle","slug":"Oracle","permalink":"http://example.com/tags/Oracle/"},{"name":"log4j","slug":"log4j","permalink":"http://example.com/tags/log4j/"},{"name":"logback","slug":"logback","permalink":"http://example.com/tags/logback/"},{"name":"slf4j","slug":"slf4j","permalink":"http://example.com/tags/slf4j/"},{"name":"jvm","slug":"jvm","permalink":"http://example.com/tags/jvm/"},{"name":"jvm垃圾回收","slug":"jvm垃圾回收","permalink":"http://example.com/tags/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"TiDB","slug":"TiDB","permalink":"http://example.com/tags/TiDB/"},{"name":"NAS","slug":"NAS","permalink":"http://example.com/tags/NAS/"},{"name":"node.js","slug":"node-js","permalink":"http://example.com/tags/node-js/"},{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"}]}